{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Importing libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from category_encoders import HashingEncoder \n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "import optuna\n",
    "\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from catboost import CatBoostClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Reading data from csv files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data = pd.read_csv('data/train.csv')\n",
    "test_data = pd.read_csv('data/test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Age</th>\n",
       "      <th>Height</th>\n",
       "      <th>Weight</th>\n",
       "      <th>family_history_with_overweight</th>\n",
       "      <th>FAVC</th>\n",
       "      <th>FCVC</th>\n",
       "      <th>NCP</th>\n",
       "      <th>CAEC</th>\n",
       "      <th>SMOKE</th>\n",
       "      <th>CH2O</th>\n",
       "      <th>SCC</th>\n",
       "      <th>FAF</th>\n",
       "      <th>TUE</th>\n",
       "      <th>CALC</th>\n",
       "      <th>MTRANS</th>\n",
       "      <th>NObeyesdad</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Male</td>\n",
       "      <td>24.443011</td>\n",
       "      <td>1.699998</td>\n",
       "      <td>81.669950</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.983297</td>\n",
       "      <td>Sometimes</td>\n",
       "      <td>no</td>\n",
       "      <td>2.763573</td>\n",
       "      <td>no</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.976473</td>\n",
       "      <td>Sometimes</td>\n",
       "      <td>Public_Transportation</td>\n",
       "      <td>Overweight_Level_II</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Female</td>\n",
       "      <td>18.000000</td>\n",
       "      <td>1.560000</td>\n",
       "      <td>57.000000</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>Frequently</td>\n",
       "      <td>no</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>no</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>no</td>\n",
       "      <td>Automobile</td>\n",
       "      <td>Normal_Weight</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Female</td>\n",
       "      <td>18.000000</td>\n",
       "      <td>1.711460</td>\n",
       "      <td>50.165754</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>1.880534</td>\n",
       "      <td>1.411685</td>\n",
       "      <td>Sometimes</td>\n",
       "      <td>no</td>\n",
       "      <td>1.910378</td>\n",
       "      <td>no</td>\n",
       "      <td>0.866045</td>\n",
       "      <td>1.673584</td>\n",
       "      <td>no</td>\n",
       "      <td>Public_Transportation</td>\n",
       "      <td>Insufficient_Weight</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Female</td>\n",
       "      <td>20.952737</td>\n",
       "      <td>1.710730</td>\n",
       "      <td>131.274851</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>Sometimes</td>\n",
       "      <td>no</td>\n",
       "      <td>1.674061</td>\n",
       "      <td>no</td>\n",
       "      <td>1.467863</td>\n",
       "      <td>0.780199</td>\n",
       "      <td>Sometimes</td>\n",
       "      <td>Public_Transportation</td>\n",
       "      <td>Obesity_Type_III</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Male</td>\n",
       "      <td>31.641081</td>\n",
       "      <td>1.914186</td>\n",
       "      <td>93.798055</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>2.679664</td>\n",
       "      <td>1.971472</td>\n",
       "      <td>Sometimes</td>\n",
       "      <td>no</td>\n",
       "      <td>1.979848</td>\n",
       "      <td>no</td>\n",
       "      <td>1.967973</td>\n",
       "      <td>0.931721</td>\n",
       "      <td>Sometimes</td>\n",
       "      <td>Public_Transportation</td>\n",
       "      <td>Overweight_Level_II</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  Gender        Age    Height      Weight family_history_with_overweight  \\\n",
       "0   0    Male  24.443011  1.699998   81.669950                            yes   \n",
       "1   1  Female  18.000000  1.560000   57.000000                            yes   \n",
       "2   2  Female  18.000000  1.711460   50.165754                            yes   \n",
       "3   3  Female  20.952737  1.710730  131.274851                            yes   \n",
       "4   4    Male  31.641081  1.914186   93.798055                            yes   \n",
       "\n",
       "  FAVC      FCVC       NCP        CAEC SMOKE      CH2O SCC       FAF  \\\n",
       "0  yes  2.000000  2.983297   Sometimes    no  2.763573  no  0.000000   \n",
       "1  yes  2.000000  3.000000  Frequently    no  2.000000  no  1.000000   \n",
       "2  yes  1.880534  1.411685   Sometimes    no  1.910378  no  0.866045   \n",
       "3  yes  3.000000  3.000000   Sometimes    no  1.674061  no  1.467863   \n",
       "4  yes  2.679664  1.971472   Sometimes    no  1.979848  no  1.967973   \n",
       "\n",
       "        TUE       CALC                 MTRANS           NObeyesdad  \n",
       "0  0.976473  Sometimes  Public_Transportation  Overweight_Level_II  \n",
       "1  1.000000         no             Automobile        Normal_Weight  \n",
       "2  1.673584         no  Public_Transportation  Insufficient_Weight  \n",
       "3  0.780199  Sometimes  Public_Transportation     Obesity_Type_III  \n",
       "4  0.931721  Sometimes  Public_Transportation  Overweight_Level_II  "
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Preprocessing data with HashEncoder and Standard Scaler."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessing(train: pd.DataFrame, test: pd.DataFrame) -> pd.DataFrame:\n",
    "    '''\n",
    "    Function for preparing data for classification. \n",
    "    '''\n",
    "    \n",
    "    # clearing data of duplicates and NaNs.\n",
    "    train = train.dropna()\n",
    "    train = train.drop_duplicates().reset_index(drop=True)\n",
    "\n",
    "    # splitting data to features and target.\n",
    "    train, target = train.drop([\"id\", \"NObeyesdad\"], axis=1), train[\"NObeyesdad\"]\n",
    "\n",
    "    le = LabelEncoder()\n",
    "    target = le.fit_transform(target)\n",
    "\n",
    "    # split df on numerical and categorical features.\n",
    "    num_cols = list(set(train.select_dtypes(\"number\").columns))\n",
    "    cat_cols = list(set(train.select_dtypes(\"object\").columns))\n",
    "\n",
    "    # encoding categorical columns with WOE.\n",
    "    hash_encoder = HashingEncoder(cols=cat_cols) \n",
    "    train[cat_cols] = hash_encoder.fit_transform(train[cat_cols], target)\n",
    "    test[cat_cols] = hash_encoder.transform(test[cat_cols])\n",
    "\n",
    "    # scaling numerical features.\n",
    "    scaler = StandardScaler()\n",
    "    train[num_cols] = scaler.fit_transform(train[num_cols])\n",
    "    test[num_cols] = scaler.transform(test[num_cols])\n",
    "\n",
    "    return train, target, test, le.classes_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, target, test, classes = preprocessing(train=training_data, test=test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Gender</th>\n",
       "      <th>Age</th>\n",
       "      <th>Height</th>\n",
       "      <th>Weight</th>\n",
       "      <th>family_history_with_overweight</th>\n",
       "      <th>FAVC</th>\n",
       "      <th>FCVC</th>\n",
       "      <th>NCP</th>\n",
       "      <th>CAEC</th>\n",
       "      <th>SMOKE</th>\n",
       "      <th>CH2O</th>\n",
       "      <th>SCC</th>\n",
       "      <th>FAF</th>\n",
       "      <th>TUE</th>\n",
       "      <th>CALC</th>\n",
       "      <th>MTRANS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.105699</td>\n",
       "      <td>-0.002828</td>\n",
       "      <td>-0.235713</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>-0.836279</td>\n",
       "      <td>0.314684</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.206594</td>\n",
       "      <td>2</td>\n",
       "      <td>-1.171141</td>\n",
       "      <td>0.597438</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>-1.027052</td>\n",
       "      <td>-1.606291</td>\n",
       "      <td>-1.170931</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.836279</td>\n",
       "      <td>0.338364</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.048349</td>\n",
       "      <td>3</td>\n",
       "      <td>0.021775</td>\n",
       "      <td>0.636513</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>-1.027052</td>\n",
       "      <td>0.128451</td>\n",
       "      <td>-1.430012</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>-1.060332</td>\n",
       "      <td>-1.913423</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.195644</td>\n",
       "      <td>2</td>\n",
       "      <td>-0.138022</td>\n",
       "      <td>1.755239</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>-0.507929</td>\n",
       "      <td>0.120090</td>\n",
       "      <td>1.644770</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1.039171</td>\n",
       "      <td>0.338364</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.584035</td>\n",
       "      <td>2</td>\n",
       "      <td>0.579896</td>\n",
       "      <td>0.271455</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>1.371197</td>\n",
       "      <td>2.450367</td>\n",
       "      <td>0.224054</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0.438397</td>\n",
       "      <td>-1.119801</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.081469</td>\n",
       "      <td>2</td>\n",
       "      <td>1.176486</td>\n",
       "      <td>0.523111</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Gender       Age    Height    Weight  family_history_with_overweight  FAVC  \\\n",
       "0       0  0.105699 -0.002828 -0.235713                               2     2   \n",
       "1       0 -1.027052 -1.606291 -1.170931                               4     0   \n",
       "2       0 -1.027052  0.128451 -1.430012                               4     1   \n",
       "3       0 -0.507929  0.120090  1.644770                               3     2   \n",
       "4       0  1.371197  2.450367  0.224054                               2     2   \n",
       "\n",
       "       FCVC       NCP  CAEC  SMOKE      CH2O  SCC       FAF       TUE  CALC  \\\n",
       "0 -0.836279  0.314684     0      0  1.206594    2 -1.171141  0.597438     1   \n",
       "1 -0.836279  0.338364     0      0 -0.048349    3  0.021775  0.636513     1   \n",
       "2 -1.060332 -1.913423     0      0 -0.195644    2 -0.138022  1.755239     1   \n",
       "3  1.039171  0.338364     0      0 -0.584035    2  0.579896  0.271455     1   \n",
       "4  0.438397 -1.119801     0      0 -0.081469    2  1.176486  0.523111     1   \n",
       "\n",
       "   MTRANS  \n",
       "0       1  \n",
       "1       0  \n",
       "2       0  \n",
       "3       0  \n",
       "4       1  "
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Age</th>\n",
       "      <th>Height</th>\n",
       "      <th>Weight</th>\n",
       "      <th>family_history_with_overweight</th>\n",
       "      <th>FAVC</th>\n",
       "      <th>FCVC</th>\n",
       "      <th>NCP</th>\n",
       "      <th>CAEC</th>\n",
       "      <th>SMOKE</th>\n",
       "      <th>CH2O</th>\n",
       "      <th>SCC</th>\n",
       "      <th>FAF</th>\n",
       "      <th>TUE</th>\n",
       "      <th>CALC</th>\n",
       "      <th>MTRANS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20758</td>\n",
       "      <td>0</td>\n",
       "      <td>0.537644</td>\n",
       "      <td>1.695675</td>\n",
       "      <td>1.241770</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0.924049</td>\n",
       "      <td>0.338364</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.308584</td>\n",
       "      <td>2</td>\n",
       "      <td>-0.150721</td>\n",
       "      <td>-1.024344</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20759</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.499620</td>\n",
       "      <td>-1.148152</td>\n",
       "      <td>-0.829748</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>-0.836279</td>\n",
       "      <td>-2.497077</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.595165</td>\n",
       "      <td>2</td>\n",
       "      <td>0.021775</td>\n",
       "      <td>-1.024344</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>20760</td>\n",
       "      <td>0</td>\n",
       "      <td>0.379434</td>\n",
       "      <td>-0.651587</td>\n",
       "      <td>0.898933</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1.039171</td>\n",
       "      <td>0.338364</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.973714</td>\n",
       "      <td>2</td>\n",
       "      <td>-1.171141</td>\n",
       "      <td>-0.608296</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>20761</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.503267</td>\n",
       "      <td>-1.685011</td>\n",
       "      <td>0.598259</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>-0.836279</td>\n",
       "      <td>0.307045</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.244138</td>\n",
       "      <td>2</td>\n",
       "      <td>-1.057992</td>\n",
       "      <td>-1.024344</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20762</td>\n",
       "      <td>0</td>\n",
       "      <td>0.379434</td>\n",
       "      <td>-0.834373</td>\n",
       "      <td>0.642469</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1.039171</td>\n",
       "      <td>0.338364</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.025738</td>\n",
       "      <td>2</td>\n",
       "      <td>-1.171141</td>\n",
       "      <td>0.206466</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      id  Gender       Age    Height    Weight  \\\n",
       "0  20758       0  0.537644  1.695675  1.241770   \n",
       "1  20759       0 -0.499620 -1.148152 -0.829748   \n",
       "2  20760       0  0.379434 -0.651587  0.898933   \n",
       "3  20761       0 -0.503267 -1.685011  0.598259   \n",
       "4  20762       0  0.379434 -0.834373  0.642469   \n",
       "\n",
       "   family_history_with_overweight  FAVC      FCVC       NCP  CAEC  SMOKE  \\\n",
       "0                               2     2  0.924049  0.338364     0      0   \n",
       "1                               3     2 -0.836279 -2.497077     0      0   \n",
       "2                               3     2  1.039171  0.338364     0      0   \n",
       "3                               2     2 -0.836279  0.307045     0      0   \n",
       "4                               3     2  1.039171  0.338364     0      0   \n",
       "\n",
       "       CH2O  SCC       FAF       TUE  CALC  MTRANS  \n",
       "0  1.308584    2 -0.150721 -1.024344     1       1  \n",
       "1  1.595165    2  0.021775 -1.024344     1       0  \n",
       "2  0.973714    2 -1.171141 -0.608296     1       0  \n",
       "3  1.244138    2 -1.057992 -1.024344     1       1  \n",
       "4  1.025738    2 -1.171141  0.206466     1       0  "
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Hyperparameter tuning for CatBoost with Optuna."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(trial, data=train, target=target):\n",
    "    '''\n",
    "    Objective function for hyperparam-tuning.\n",
    "    '''\n",
    "    train_x, test_x, train_y, test_y = train_test_split(data, target, test_size=0.15,random_state=42)\n",
    "    param = {\n",
    "        'iterations': trial.suggest_int('iterations', 100, 1500),\n",
    "        'depth': trial.suggest_int('depth', 3, 15),\n",
    "        'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.5),\n",
    "        'eval_metric': 'Accuracy',\n",
    "        'random_seed': 42,\n",
    "        'task_type': 'GPU',        \n",
    "    }\n",
    "    model = CatBoostClassifier(**param)  \n",
    "    \n",
    "    model.fit(train_x,train_y, eval_set=[(test_x,test_y)], early_stopping_rounds=200, verbose=False)\n",
    "    \n",
    "    preds = model.predict(test_x)\n",
    "    \n",
    "    f1 = f1_score(test_y, preds, average='weighted')\n",
    "    \n",
    "    return f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-02-13 15:47:59,053] A new study created in memory with name: Catboost_study\n",
      "[I 2024-02-13 15:52:46,634] Trial 0 finished with value: 0.8927525004727773 and parameters: {'iterations': 676, 'depth': 14, 'learning_rate': 0.010628444782045178}. Best is trial 0 with value: 0.8927525004727773.\n",
      "[I 2024-02-13 15:53:00,875] Trial 1 finished with value: 0.9004790763899027 and parameters: {'iterations': 1440, 'depth': 6, 'learning_rate': 0.05299323004022556}. Best is trial 1 with value: 0.9004790763899027.\n",
      "[I 2024-02-13 15:54:55,455] Trial 2 finished with value: 0.8915988824239701 and parameters: {'iterations': 1174, 'depth': 14, 'learning_rate': 0.08906597448038002}. Best is trial 1 with value: 0.9004790763899027.\n",
      "[I 2024-02-13 15:55:25,719] Trial 3 finished with value: 0.8964756590375865 and parameters: {'iterations': 630, 'depth': 10, 'learning_rate': 0.011193803359304052}. Best is trial 1 with value: 0.9004790763899027.\n",
      "[I 2024-02-13 15:55:36,609] Trial 4 finished with value: 0.8977793245327192 and parameters: {'iterations': 786, 'depth': 3, 'learning_rate': 0.06166725875298259}. Best is trial 1 with value: 0.9004790763899027.\n",
      "[I 2024-02-13 15:56:12,281] Trial 5 finished with value: 0.90064133670773 and parameters: {'iterations': 1184, 'depth': 9, 'learning_rate': 0.012137526676440545}. Best is trial 5 with value: 0.90064133670773.\n",
      "[I 2024-02-13 15:56:41,169] Trial 6 finished with value: 0.8990511190190413 and parameters: {'iterations': 1032, 'depth': 9, 'learning_rate': 0.013912658421560607}. Best is trial 5 with value: 0.90064133670773.\n",
      "[I 2024-02-13 15:57:04,242] Trial 7 finished with value: 0.8965710497465122 and parameters: {'iterations': 1223, 'depth': 11, 'learning_rate': 0.06068642195251188}. Best is trial 5 with value: 0.90064133670773.\n",
      "[I 2024-02-13 15:58:47,886] Trial 8 finished with value: 0.8881971031877478 and parameters: {'iterations': 1353, 'depth': 14, 'learning_rate': 0.15381341433703746}. Best is trial 5 with value: 0.90064133670773.\n",
      "[I 2024-02-13 15:59:09,576] Trial 9 finished with value: 0.8966346549236424 and parameters: {'iterations': 1418, 'depth': 7, 'learning_rate': 0.01841424675872347}. Best is trial 5 with value: 0.90064133670773.\n",
      "[I 2024-02-13 15:59:14,497] Trial 10 finished with value: 0.8985433503651368 and parameters: {'iterations': 195, 'depth': 4, 'learning_rate': 0.4767665963928692}. Best is trial 5 with value: 0.90064133670773.\n",
      "[I 2024-02-13 15:59:30,427] Trial 11 finished with value: 0.898443835927824 and parameters: {'iterations': 1005, 'depth': 6, 'learning_rate': 0.029809392578304283}. Best is trial 5 with value: 0.90064133670773.\n",
      "[I 2024-02-13 15:59:49,604] Trial 12 finished with value: 0.8989468147943855 and parameters: {'iterations': 1465, 'depth': 7, 'learning_rate': 0.033632093355513426}. Best is trial 5 with value: 0.90064133670773.\n",
      "[I 2024-02-13 15:59:58,385] Trial 13 finished with value: 0.8982481006303301 and parameters: {'iterations': 1043, 'depth': 5, 'learning_rate': 0.23805749550185268}. Best is trial 5 with value: 0.90064133670773.\n",
      "[I 2024-02-13 16:00:14,934] Trial 14 finished with value: 0.8985010160381145 and parameters: {'iterations': 1265, 'depth': 8, 'learning_rate': 0.032166370883123546}. Best is trial 5 with value: 0.90064133670773.\n",
      "[I 2024-02-13 16:01:03,345] Trial 15 finished with value: 0.8959025753002183 and parameters: {'iterations': 331, 'depth': 12, 'learning_rate': 0.022495726453566563}. Best is trial 5 with value: 0.90064133670773.\n",
      "[I 2024-02-13 16:01:18,664] Trial 16 finished with value: 0.8987245815424454 and parameters: {'iterations': 1500, 'depth': 9, 'learning_rate': 0.11065982319928962}. Best is trial 5 with value: 0.90064133670773.\n",
      "[I 2024-02-13 16:02:08,301] Trial 17 finished with value: 0.8969367448666682 and parameters: {'iterations': 903, 'depth': 12, 'learning_rate': 0.05465695364512318}. Best is trial 5 with value: 0.90064133670773.\n",
      "[I 2024-02-13 16:02:22,247] Trial 18 finished with value: 0.8997945285244202 and parameters: {'iterations': 1158, 'depth': 6, 'learning_rate': 0.043330566372550866}. Best is trial 5 with value: 0.90064133670773.\n",
      "[I 2024-02-13 16:02:29,288] Trial 19 finished with value: 0.8979407753084474 and parameters: {'iterations': 1325, 'depth': 3, 'learning_rate': 0.23775100849694797}. Best is trial 5 with value: 0.90064133670773.\n",
      "[I 2024-02-13 16:02:46,218] Trial 20 finished with value: 0.8965153216668317 and parameters: {'iterations': 501, 'depth': 8, 'learning_rate': 0.018664591976048306}. Best is trial 5 with value: 0.90064133670773.\n",
      "[I 2024-02-13 16:03:02,287] Trial 21 finished with value: 0.8995613596317581 and parameters: {'iterations': 1126, 'depth': 5, 'learning_rate': 0.04505192299635075}. Best is trial 5 with value: 0.90064133670773.\n",
      "[I 2024-02-13 16:03:13,170] Trial 22 finished with value: 0.8999298538008246 and parameters: {'iterations': 910, 'depth': 6, 'learning_rate': 0.0971469281347252}. Best is trial 5 with value: 0.90064133670773.\n",
      "[I 2024-02-13 16:03:24,703] Trial 23 finished with value: 0.8992766818033295 and parameters: {'iterations': 865, 'depth': 5, 'learning_rate': 0.10243287609382833}. Best is trial 5 with value: 0.90064133670773.\n",
      "[I 2024-02-13 16:03:32,901] Trial 24 finished with value: 0.8991294860761154 and parameters: {'iterations': 944, 'depth': 7, 'learning_rate': 0.2634320694023095}. Best is trial 5 with value: 0.90064133670773.\n",
      "[I 2024-02-13 16:03:46,217] Trial 25 finished with value: 0.8982947750568838 and parameters: {'iterations': 781, 'depth': 9, 'learning_rate': 0.15481541532372745}. Best is trial 5 with value: 0.90064133670773.\n",
      "[I 2024-02-13 16:03:57,768] Trial 26 finished with value: 0.9017566777653171 and parameters: {'iterations': 1356, 'depth': 6, 'learning_rate': 0.08254271497282745}. Best is trial 26 with value: 0.9017566777653171.\n",
      "[I 2024-02-13 16:04:14,209] Trial 27 finished with value: 0.8954637355189244 and parameters: {'iterations': 1352, 'depth': 10, 'learning_rate': 0.1393422620765698}. Best is trial 26 with value: 0.9017566777653171.\n",
      "[I 2024-02-13 16:04:28,178] Trial 28 finished with value: 0.8996018659994293 and parameters: {'iterations': 1264, 'depth': 4, 'learning_rate': 0.07741072290831941}. Best is trial 26 with value: 0.9017566777653171.\n",
      "[I 2024-02-13 16:05:03,863] Trial 29 finished with value: 0.8987772424637206 and parameters: {'iterations': 1376, 'depth': 8, 'learning_rate': 0.01127670507898904}. Best is trial 26 with value: 0.9017566777653171.\n",
      "[I 2024-02-13 16:05:44,432] Trial 30 finished with value: 0.8979003142599171 and parameters: {'iterations': 1446, 'depth': 11, 'learning_rate': 0.024644917608985868}. Best is trial 26 with value: 0.9017566777653171.\n",
      "[I 2024-02-13 16:05:52,039] Trial 31 finished with value: 0.8984866439509362 and parameters: {'iterations': 1092, 'depth': 6, 'learning_rate': 0.12901678358134333}. Best is trial 26 with value: 0.9017566777653171.\n",
      "[I 2024-02-13 16:06:03,038] Trial 32 finished with value: 0.8995651102261167 and parameters: {'iterations': 682, 'depth': 4, 'learning_rate': 0.0824862774018046}. Best is trial 26 with value: 0.9017566777653171.\n",
      "[I 2024-02-13 16:06:13,703] Trial 33 finished with value: 0.8977668173496515 and parameters: {'iterations': 1202, 'depth': 6, 'learning_rate': 0.044485215770328324}. Best is trial 26 with value: 0.9017566777653171.\n",
      "[I 2024-02-13 16:06:25,396] Trial 34 finished with value: 0.8994552308546725 and parameters: {'iterations': 1290, 'depth': 7, 'learning_rate': 0.0973615653297954}. Best is trial 26 with value: 0.9017566777653171.\n",
      "[I 2024-02-13 16:06:33,370] Trial 35 finished with value: 0.8976093115342603 and parameters: {'iterations': 519, 'depth': 5, 'learning_rate': 0.19865788062813536}. Best is trial 26 with value: 0.9017566777653171.\n",
      "[I 2024-02-13 16:10:33,052] Trial 36 finished with value: 0.8888451735160929 and parameters: {'iterations': 1208, 'depth': 15, 'learning_rate': 0.06815520517784496}. Best is trial 26 with value: 0.9017566777653171.\n",
      "[I 2024-02-13 16:10:47,445] Trial 37 finished with value: 0.8926669834324499 and parameters: {'iterations': 1102, 'depth': 10, 'learning_rate': 0.36399955979627024}. Best is trial 26 with value: 0.9017566777653171.\n",
      "[I 2024-02-13 16:11:18,600] Trial 38 finished with value: 0.8991500415544181 and parameters: {'iterations': 1389, 'depth': 8, 'learning_rate': 0.014884498198319026}. Best is trial 26 with value: 0.9017566777653171.\n",
      "[I 2024-02-13 16:11:42,687] Trial 39 finished with value: 0.8961519940926769 and parameters: {'iterations': 970, 'depth': 7, 'learning_rate': 0.01028310526152992}. Best is trial 26 with value: 0.9017566777653171.\n",
      "[I 2024-02-13 16:11:54,715] Trial 40 finished with value: 0.8985987063499637 and parameters: {'iterations': 821, 'depth': 3, 'learning_rate': 0.05511823405885629}. Best is trial 26 with value: 0.9017566777653171.\n",
      "[I 2024-02-13 16:12:09,996] Trial 41 finished with value: 0.8989180841351925 and parameters: {'iterations': 1104, 'depth': 6, 'learning_rate': 0.04413369058127851}. Best is trial 26 with value: 0.9017566777653171.\n",
      "[I 2024-02-13 16:12:20,785] Trial 42 finished with value: 0.8982866052646236 and parameters: {'iterations': 1152, 'depth': 6, 'learning_rate': 0.038121330757667646}. Best is trial 26 with value: 0.9017566777653171.\n",
      "[I 2024-02-13 16:12:34,871] Trial 43 finished with value: 0.8996294689676769 and parameters: {'iterations': 1234, 'depth': 5, 'learning_rate': 0.06468888198039348}. Best is trial 26 with value: 0.9017566777653171.\n",
      "[I 2024-02-13 16:12:46,942] Trial 44 finished with value: 0.8989887268422992 and parameters: {'iterations': 1037, 'depth': 4, 'learning_rate': 0.08307377932285252}. Best is trial 26 with value: 0.9017566777653171.\n",
      "[I 2024-02-13 16:12:54,526] Trial 45 finished with value: 0.8974866966087683 and parameters: {'iterations': 1422, 'depth': 7, 'learning_rate': 0.11155027348785367}. Best is trial 26 with value: 0.9017566777653171.\n",
      "[I 2024-02-13 16:13:10,399] Trial 46 finished with value: 0.8981438566641756 and parameters: {'iterations': 1499, 'depth': 8, 'learning_rate': 0.05191559979037833}. Best is trial 26 with value: 0.9017566777653171.\n",
      "[I 2024-02-13 16:13:25,782] Trial 47 finished with value: 0.897450497277803 and parameters: {'iterations': 1182, 'depth': 6, 'learning_rate': 0.025072330108813413}. Best is trial 26 with value: 0.9017566777653171.\n",
      "[I 2024-02-13 16:13:36,476] Trial 48 finished with value: 0.8972497999032246 and parameters: {'iterations': 1301, 'depth': 9, 'learning_rate': 0.1805737816363665}. Best is trial 26 with value: 0.9017566777653171.\n",
      "[I 2024-02-13 16:15:24,797] Trial 49 finished with value: 0.8939181703774354 and parameters: {'iterations': 682, 'depth': 13, 'learning_rate': 0.03535973522567651}. Best is trial 26 with value: 0.9017566777653171.\n",
      "[I 2024-02-13 16:15:26,359] Trial 50 finished with value: 0.8368852546405525 and parameters: {'iterations': 102, 'depth': 4, 'learning_rate': 0.02954979065548848}. Best is trial 26 with value: 0.9017566777653171.\n",
      "[I 2024-02-13 16:15:37,097] Trial 51 finished with value: 0.9004672273001664 and parameters: {'iterations': 1242, 'depth': 5, 'learning_rate': 0.06673969386596275}. Best is trial 26 with value: 0.9017566777653171.\n",
      "[I 2024-02-13 16:15:47,686] Trial 52 finished with value: 0.8992047853248267 and parameters: {'iterations': 1333, 'depth': 5, 'learning_rate': 0.06495645511830184}. Best is trial 26 with value: 0.9017566777653171.\n",
      "[I 2024-02-13 16:16:04,827] Trial 53 finished with value: 0.9004687486785167 and parameters: {'iterations': 1241, 'depth': 6, 'learning_rate': 0.07572807083407568}. Best is trial 26 with value: 0.9017566777653171.\n",
      "[I 2024-02-13 16:16:12,073] Trial 54 finished with value: 0.8992009201724533 and parameters: {'iterations': 1407, 'depth': 5, 'learning_rate': 0.12174115060780677}. Best is trial 26 with value: 0.9017566777653171.\n",
      "[I 2024-02-13 16:16:21,260] Trial 55 finished with value: 0.898874852148502 and parameters: {'iterations': 1254, 'depth': 7, 'learning_rate': 0.09088709789514053}. Best is trial 26 with value: 0.9017566777653171.\n",
      "[I 2024-02-13 16:16:34,965] Trial 56 finished with value: 0.8986236256802497 and parameters: {'iterations': 1309, 'depth': 3, 'learning_rate': 0.07442891239153454}. Best is trial 26 with value: 0.9017566777653171.\n",
      "[I 2024-02-13 16:16:49,646] Trial 57 finished with value: 0.8982846979350875 and parameters: {'iterations': 1458, 'depth': 6, 'learning_rate': 0.05619714126705957}. Best is trial 26 with value: 0.9017566777653171.\n",
      "[I 2024-02-13 16:16:59,884] Trial 58 finished with value: 0.89799494563937 and parameters: {'iterations': 982, 'depth': 4, 'learning_rate': 0.09972531108805509}. Best is trial 26 with value: 0.9017566777653171.\n",
      "[I 2024-02-13 16:17:09,874] Trial 59 finished with value: 0.8996380465161334 and parameters: {'iterations': 1379, 'depth': 8, 'learning_rate': 0.15813531177891657}. Best is trial 26 with value: 0.9017566777653171.\n",
      "[I 2024-02-13 16:17:20,310] Trial 60 finished with value: 0.8995018463574234 and parameters: {'iterations': 1041, 'depth': 7, 'learning_rate': 0.08616815892249978}. Best is trial 26 with value: 0.9017566777653171.\n",
      "[I 2024-02-13 16:17:37,540] Trial 61 finished with value: 0.9002125589470555 and parameters: {'iterations': 1149, 'depth': 5, 'learning_rate': 0.04988907292274215}. Best is trial 26 with value: 0.9017566777653171.\n",
      "[I 2024-02-13 16:17:52,924] Trial 62 finished with value: 0.9001976746261603 and parameters: {'iterations': 920, 'depth': 5, 'learning_rate': 0.04932562142353131}. Best is trial 26 with value: 0.9017566777653171.\n",
      "[I 2024-02-13 16:18:06,767] Trial 63 finished with value: 0.8992476029603621 and parameters: {'iterations': 1162, 'depth': 5, 'learning_rate': 0.05121326434334749}. Best is trial 26 with value: 0.9017566777653171.\n",
      "[I 2024-02-13 16:18:23,563] Trial 64 finished with value: 0.8976841901440418 and parameters: {'iterations': 1227, 'depth': 4, 'learning_rate': 0.03777472666609187}. Best is trial 26 with value: 0.9017566777653171.\n",
      "[I 2024-02-13 16:18:37,835] Trial 65 finished with value: 0.9002062611877545 and parameters: {'iterations': 1334, 'depth': 5, 'learning_rate': 0.049181720473904865}. Best is trial 26 with value: 0.9017566777653171.\n",
      "[I 2024-02-13 16:19:09,406] Trial 66 finished with value: 0.8991758972699186 and parameters: {'iterations': 1343, 'depth': 6, 'learning_rate': 0.020089488498027892}. Best is trial 26 with value: 0.9017566777653171.\n",
      "[I 2024-02-13 16:19:20,204] Trial 67 finished with value: 0.9004909205065511 and parameters: {'iterations': 1280, 'depth': 5, 'learning_rate': 0.07361582617921457}. Best is trial 26 with value: 0.9017566777653171.\n",
      "[I 2024-02-13 16:19:32,505] Trial 68 finished with value: 0.899277837881481 and parameters: {'iterations': 1267, 'depth': 4, 'learning_rate': 0.06215735463843538}. Best is trial 26 with value: 0.9017566777653171.\n",
      "[I 2024-02-13 16:20:12,308] Trial 69 finished with value: 0.8944693716562114 and parameters: {'iterations': 1137, 'depth': 12, 'learning_rate': 0.07341207950085982}. Best is trial 26 with value: 0.9017566777653171.\n",
      "[I 2024-02-13 16:20:33,756] Trial 70 finished with value: 0.896159299121368 and parameters: {'iterations': 1445, 'depth': 5, 'learning_rate': 0.014048775371382384}. Best is trial 26 with value: 0.9017566777653171.\n",
      "[I 2024-02-13 16:20:46,735] Trial 71 finished with value: 0.9014794899848942 and parameters: {'iterations': 1301, 'depth': 6, 'learning_rate': 0.059119254023655275}. Best is trial 26 with value: 0.9017566777653171.\n",
      "[I 2024-02-13 16:21:00,240] Trial 72 finished with value: 0.8998913226450672 and parameters: {'iterations': 1282, 'depth': 6, 'learning_rate': 0.05975425994569735}. Best is trial 26 with value: 0.9017566777653171.\n",
      "[I 2024-02-13 16:21:12,138] Trial 73 finished with value: 0.900087654043034 and parameters: {'iterations': 1078, 'depth': 7, 'learning_rate': 0.07391093504481047}. Best is trial 26 with value: 0.9017566777653171.\n",
      "[I 2024-02-13 16:21:25,407] Trial 74 finished with value: 0.9011902455184804 and parameters: {'iterations': 1201, 'depth': 6, 'learning_rate': 0.06791746294784959}. Best is trial 26 with value: 0.9017566777653171.\n",
      "[I 2024-02-13 16:21:37,604] Trial 75 finished with value: 0.9007654614225185 and parameters: {'iterations': 1202, 'depth': 6, 'learning_rate': 0.06908652167165232}. Best is trial 26 with value: 0.9017566777653171.\n",
      "[I 2024-02-13 16:21:45,380] Trial 76 finished with value: 0.8980401673421783 and parameters: {'iterations': 1191, 'depth': 7, 'learning_rate': 0.11422226038435815}. Best is trial 26 with value: 0.9017566777653171.\n",
      "[I 2024-02-13 16:21:56,252] Trial 77 finished with value: 0.8992284033639923 and parameters: {'iterations': 1372, 'depth': 6, 'learning_rate': 0.08015583425428222}. Best is trial 26 with value: 0.9017566777653171.\n",
      "[I 2024-02-13 16:22:04,715] Trial 78 finished with value: 0.9002888646770537 and parameters: {'iterations': 1499, 'depth': 8, 'learning_rate': 0.1342219100598582}. Best is trial 26 with value: 0.9017566777653171.\n",
      "[I 2024-02-13 16:22:21,413] Trial 79 finished with value: 0.8978495754199709 and parameters: {'iterations': 1307, 'depth': 10, 'learning_rate': 0.09229358432223285}. Best is trial 26 with value: 0.9017566777653171.\n",
      "[I 2024-02-13 16:22:36,646] Trial 80 finished with value: 0.8988423858245445 and parameters: {'iterations': 1418, 'depth': 7, 'learning_rate': 0.04107458873354653}. Best is trial 26 with value: 0.9017566777653171.\n",
      "[I 2024-02-13 16:22:49,672] Trial 81 finished with value: 0.9011897129872832 and parameters: {'iterations': 1229, 'depth': 6, 'learning_rate': 0.07130898380866495}. Best is trial 26 with value: 0.9017566777653171.\n",
      "[I 2024-02-13 16:23:01,798] Trial 82 finished with value: 0.898516859608316 and parameters: {'iterations': 1215, 'depth': 6, 'learning_rate': 0.05955686572135108}. Best is trial 26 with value: 0.9017566777653171.\n",
      "[I 2024-02-13 16:23:16,374] Trial 83 finished with value: 0.8999145214022243 and parameters: {'iterations': 1281, 'depth': 6, 'learning_rate': 0.07093950137146932}. Best is trial 26 with value: 0.9017566777653171.\n",
      "[I 2024-02-13 16:23:24,658] Trial 84 finished with value: 0.8985755293714527 and parameters: {'iterations': 1191, 'depth': 6, 'learning_rate': 0.10204243931457985}. Best is trial 26 with value: 0.9017566777653171.\n",
      "[I 2024-02-13 16:23:34,096] Trial 85 finished with value: 0.8856607949359554 and parameters: {'iterations': 350, 'depth': 7, 'learning_rate': 0.011912398028495778}. Best is trial 26 with value: 0.9017566777653171.\n",
      "[I 2024-02-13 16:23:59,240] Trial 86 finished with value: 0.8974512121229401 and parameters: {'iterations': 1361, 'depth': 11, 'learning_rate': 0.08859410862441418}. Best is trial 26 with value: 0.9017566777653171.\n",
      "[I 2024-02-13 16:24:15,046] Trial 87 finished with value: 0.8970637996034423 and parameters: {'iterations': 1066, 'depth': 6, 'learning_rate': 0.0777759921231071}. Best is trial 26 with value: 0.9017566777653171.\n",
      "[I 2024-02-13 16:24:26,782] Trial 88 finished with value: 0.8988202631424284 and parameters: {'iterations': 1119, 'depth': 8, 'learning_rate': 0.06043893826924433}. Best is trial 26 with value: 0.9017566777653171.\n",
      "[I 2024-02-13 16:24:45,436] Trial 89 finished with value: 0.896125127548426 and parameters: {'iterations': 1243, 'depth': 7, 'learning_rate': 0.015883155017146808}. Best is trial 26 with value: 0.9017566777653171.\n",
      "[I 2024-02-13 16:25:10,723] Trial 90 finished with value: 0.899249319713033 and parameters: {'iterations': 1406, 'depth': 6, 'learning_rate': 0.030039472206042563}. Best is trial 26 with value: 0.9017566777653171.\n",
      "[I 2024-02-13 16:25:24,423] Trial 91 finished with value: 0.900180249504912 and parameters: {'iterations': 1317, 'depth': 5, 'learning_rate': 0.06944572274579776}. Best is trial 26 with value: 0.9017566777653171.\n",
      "[I 2024-02-13 16:25:37,338] Trial 92 finished with value: 0.8989241001799569 and parameters: {'iterations': 1243, 'depth': 5, 'learning_rate': 0.055208949387840864}. Best is trial 26 with value: 0.9017566777653171.\n",
      "[I 2024-02-13 16:25:50,793] Trial 93 finished with value: 0.9005747660961021 and parameters: {'iterations': 1211, 'depth': 5, 'learning_rate': 0.0664762691571202}. Best is trial 26 with value: 0.9017566777653171.\n",
      "[I 2024-02-13 16:26:01,485] Trial 94 finished with value: 0.8992920935596989 and parameters: {'iterations': 1172, 'depth': 6, 'learning_rate': 0.08128883809454736}. Best is trial 26 with value: 0.9017566777653171.\n",
      "[I 2024-02-13 16:26:09,974] Trial 95 finished with value: 0.9005040540105983 and parameters: {'iterations': 1213, 'depth': 5, 'learning_rate': 0.10763389271278531}. Best is trial 26 with value: 0.9017566777653171.\n",
      "[I 2024-02-13 16:27:14,419] Trial 96 finished with value: 0.8915738491042643 and parameters: {'iterations': 1211, 'depth': 13, 'learning_rate': 0.11204583069538883}. Best is trial 26 with value: 0.9017566777653171.\n",
      "[I 2024-02-13 16:27:21,826] Trial 97 finished with value: 0.8982453545821757 and parameters: {'iterations': 1011, 'depth': 5, 'learning_rate': 0.1462024376729318}. Best is trial 26 with value: 0.9017566777653171.\n",
      "[I 2024-02-13 16:27:31,782] Trial 98 finished with value: 0.8988580421312836 and parameters: {'iterations': 1282, 'depth': 4, 'learning_rate': 0.12110834471761497}. Best is trial 26 with value: 0.9017566777653171.\n",
      "[I 2024-02-13 16:27:50,367] Trial 99 finished with value: 0.8989985819937518 and parameters: {'iterations': 1436, 'depth': 3, 'learning_rate': 0.06555125390553432}. Best is trial 26 with value: 0.9017566777653171.\n",
      "[I 2024-02-13 16:28:01,084] Trial 100 finished with value: 0.8963881498117541 and parameters: {'iterations': 1113, 'depth': 9, 'learning_rate': 0.36247017006349047}. Best is trial 26 with value: 0.9017566777653171.\n",
      "[I 2024-02-13 16:28:09,869] Trial 101 finished with value: 0.9018228892404868 and parameters: {'iterations': 1354, 'depth': 6, 'learning_rate': 0.0933244870266498}. Best is trial 101 with value: 0.9018228892404868.\n",
      "[I 2024-02-13 16:28:21,560] Trial 102 finished with value: 0.8996151319486837 and parameters: {'iterations': 1355, 'depth': 6, 'learning_rate': 0.08353268918606027}. Best is trial 101 with value: 0.9018228892404868.\n",
      "[I 2024-02-13 16:28:32,490] Trial 103 finished with value: 0.89920214659903 and parameters: {'iterations': 1390, 'depth': 5, 'learning_rate': 0.09509580732571611}. Best is trial 101 with value: 0.9018228892404868.\n",
      "[I 2024-02-13 16:28:42,603] Trial 104 finished with value: 0.8982539117453945 and parameters: {'iterations': 1318, 'depth': 4, 'learning_rate': 0.1032510120701872}. Best is trial 101 with value: 0.9018228892404868.\n",
      "[I 2024-02-13 16:28:56,368] Trial 105 finished with value: 0.8989164663572728 and parameters: {'iterations': 1461, 'depth': 5, 'learning_rate': 0.047102791181191844}. Best is trial 101 with value: 0.9018228892404868.\n",
      "[I 2024-02-13 16:29:09,631] Trial 106 finished with value: 0.9001793350745187 and parameters: {'iterations': 1168, 'depth': 7, 'learning_rate': 0.058359312535972506}. Best is trial 101 with value: 0.9018228892404868.\n",
      "[I 2024-02-13 16:29:21,423] Trial 107 finished with value: 0.90113675728218 and parameters: {'iterations': 1266, 'depth': 6, 'learning_rate': 0.06732200836556196}. Best is trial 101 with value: 0.9018228892404868.\n",
      "[I 2024-02-13 16:29:29,587] Trial 108 finished with value: 0.8979091345791512 and parameters: {'iterations': 735, 'depth': 6, 'learning_rate': 0.08612010175772516}. Best is trial 101 with value: 0.9018228892404868.\n",
      "[I 2024-02-13 16:29:41,903] Trial 109 finished with value: 0.9008239683554642 and parameters: {'iterations': 1259, 'depth': 6, 'learning_rate': 0.06893372919458696}. Best is trial 101 with value: 0.9018228892404868.\n",
      "[I 2024-02-13 16:29:53,393] Trial 110 finished with value: 0.8989724679934998 and parameters: {'iterations': 1137, 'depth': 6, 'learning_rate': 0.10558346070251254}. Best is trial 101 with value: 0.9018228892404868.\n",
      "[I 2024-02-13 16:30:06,486] Trial 111 finished with value: 0.8992477828022165 and parameters: {'iterations': 1260, 'depth': 5, 'learning_rate': 0.06855203326051124}. Best is trial 101 with value: 0.9018228892404868.\n",
      "[I 2024-02-13 16:30:17,281] Trial 112 finished with value: 0.8991706694715053 and parameters: {'iterations': 1208, 'depth': 7, 'learning_rate': 0.07675253561328092}. Best is trial 101 with value: 0.9018228892404868.\n",
      "[I 2024-02-13 16:30:29,638] Trial 113 finished with value: 0.89914743608642 and parameters: {'iterations': 1290, 'depth': 6, 'learning_rate': 0.06282706380967304}. Best is trial 101 with value: 0.9018228892404868.\n",
      "[I 2024-02-13 16:30:39,987] Trial 114 finished with value: 0.8994602816360263 and parameters: {'iterations': 1336, 'depth': 5, 'learning_rate': 0.09492058023401251}. Best is trial 101 with value: 0.9018228892404868.\n",
      "[I 2024-02-13 16:30:55,740] Trial 115 finished with value: 0.8995088425841276 and parameters: {'iterations': 1227, 'depth': 6, 'learning_rate': 0.0707122040418609}. Best is trial 101 with value: 0.9018228892404868.\n",
      "[I 2024-02-13 16:31:07,802] Trial 116 finished with value: 0.899249496641172 and parameters: {'iterations': 1262, 'depth': 4, 'learning_rate': 0.1220078453432766}. Best is trial 101 with value: 0.9018228892404868.\n",
      "[I 2024-02-13 16:31:22,484] Trial 117 finished with value: 0.900132469028583 and parameters: {'iterations': 1185, 'depth': 5, 'learning_rate': 0.05476886390333207}. Best is trial 101 with value: 0.9018228892404868.\n",
      "[I 2024-02-13 16:31:31,019] Trial 118 finished with value: 0.8968845358659829 and parameters: {'iterations': 1314, 'depth': 7, 'learning_rate': 0.08889993375841487}. Best is trial 101 with value: 0.9018228892404868.\n",
      "[I 2024-02-13 16:31:38,423] Trial 119 finished with value: 0.8976314358728285 and parameters: {'iterations': 1292, 'depth': 6, 'learning_rate': 0.06511132779224856}. Best is trial 101 with value: 0.9018228892404868.\n",
      "[I 2024-02-13 16:31:50,322] Trial 120 finished with value: 0.8989690948737661 and parameters: {'iterations': 1075, 'depth': 6, 'learning_rate': 0.08016963162612255}. Best is trial 101 with value: 0.9018228892404868.\n",
      "[I 2024-02-13 16:32:00,314] Trial 121 finished with value: 0.8991965950320802 and parameters: {'iterations': 1386, 'depth': 6, 'learning_rate': 0.07351739555734159}. Best is trial 101 with value: 0.9018228892404868.\n",
      "[I 2024-02-13 16:32:14,250] Trial 122 finished with value: 0.8992457191652516 and parameters: {'iterations': 1361, 'depth': 7, 'learning_rate': 0.05431889627171318}. Best is trial 101 with value: 0.9018228892404868.\n",
      "[I 2024-02-13 16:32:25,226] Trial 123 finished with value: 0.8993075658076306 and parameters: {'iterations': 549, 'depth': 5, 'learning_rate': 0.0626032224094815}. Best is trial 101 with value: 0.9018228892404868.\n",
      "[I 2024-02-13 16:32:38,716] Trial 124 finished with value: 0.9002090293149829 and parameters: {'iterations': 1267, 'depth': 6, 'learning_rate': 0.06921494745674549}. Best is trial 101 with value: 0.9018228892404868.\n",
      "[I 2024-02-13 16:32:52,455] Trial 125 finished with value: 0.8979372655008336 and parameters: {'iterations': 1229, 'depth': 5, 'learning_rate': 0.04353372334942024}. Best is trial 101 with value: 0.9018228892404868.\n",
      "[I 2024-02-13 16:33:05,317] Trial 126 finished with value: 0.8992384522825709 and parameters: {'iterations': 1148, 'depth': 6, 'learning_rate': 0.08863434778465258}. Best is trial 101 with value: 0.9018228892404868.\n",
      "[I 2024-02-13 16:33:12,186] Trial 127 finished with value: 0.8977898858369374 and parameters: {'iterations': 1335, 'depth': 7, 'learning_rate': 0.16736926701203803}. Best is trial 101 with value: 0.9018228892404868.\n",
      "[I 2024-02-13 16:33:26,073] Trial 128 finished with value: 0.8997997334124981 and parameters: {'iterations': 1474, 'depth': 6, 'learning_rate': 0.05818059761088014}. Best is trial 101 with value: 0.9018228892404868.\n",
      "[I 2024-02-13 16:33:45,841] Trial 129 finished with value: 0.8978398724915517 and parameters: {'iterations': 1199, 'depth': 10, 'learning_rate': 0.07670359127084887}. Best is trial 101 with value: 0.9018228892404868.\n",
      "[I 2024-02-13 16:34:02,688] Trial 130 finished with value: 0.900162131936383 and parameters: {'iterations': 1301, 'depth': 5, 'learning_rate': 0.04662751830171626}. Best is trial 101 with value: 0.9018228892404868.\n",
      "[I 2024-02-13 16:34:13,600] Trial 131 finished with value: 0.8995022795292823 and parameters: {'iterations': 1258, 'depth': 6, 'learning_rate': 0.07304063099520594}. Best is trial 101 with value: 0.9018228892404868.\n",
      "[I 2024-02-13 16:34:26,019] Trial 132 finished with value: 0.9012242516253326 and parameters: {'iterations': 1233, 'depth': 6, 'learning_rate': 0.08325716262091697}. Best is trial 101 with value: 0.9018228892404868.\n",
      "[I 2024-02-13 16:34:37,640] Trial 133 finished with value: 0.8991772656903207 and parameters: {'iterations': 1222, 'depth': 6, 'learning_rate': 0.08118173166641618}. Best is trial 101 with value: 0.9018228892404868.\n",
      "[I 2024-02-13 16:34:49,488] Trial 134 finished with value: 0.8996181398680598 and parameters: {'iterations': 1187, 'depth': 5, 'learning_rate': 0.09369034987158234}. Best is trial 101 with value: 0.9018228892404868.\n",
      "[I 2024-02-13 16:35:02,535] Trial 135 finished with value: 0.9007475665418756 and parameters: {'iterations': 1164, 'depth': 7, 'learning_rate': 0.06710530480897671}. Best is trial 101 with value: 0.9018228892404868.\n",
      "[I 2024-02-13 16:35:14,797] Trial 136 finished with value: 0.8987803816780723 and parameters: {'iterations': 1151, 'depth': 7, 'learning_rate': 0.06623980670851129}. Best is trial 101 with value: 0.9018228892404868.\n",
      "[I 2024-02-13 16:35:23,764] Trial 137 finished with value: 0.897242013002876 and parameters: {'iterations': 1097, 'depth': 7, 'learning_rate': 0.1039496127770802}. Best is trial 101 with value: 0.9018228892404868.\n",
      "[I 2024-02-13 16:35:35,631] Trial 138 finished with value: 0.9017517020518789 and parameters: {'iterations': 1170, 'depth': 5, 'learning_rate': 0.08283339026597795}. Best is trial 101 with value: 0.9018228892404868.\n",
      "[I 2024-02-13 16:35:47,727] Trial 139 finished with value: 0.897504423769655 and parameters: {'iterations': 1127, 'depth': 8, 'learning_rate': 0.0883709839392014}. Best is trial 101 with value: 0.9018228892404868.\n",
      "[I 2024-02-13 16:35:58,217] Trial 140 finished with value: 0.8989376627909377 and parameters: {'iterations': 1167, 'depth': 6, 'learning_rate': 0.09638257995741104}. Best is trial 101 with value: 0.9018228892404868.\n",
      "[I 2024-02-13 16:36:12,943] Trial 141 finished with value: 0.9002689064732238 and parameters: {'iterations': 1232, 'depth': 5, 'learning_rate': 0.08083802432468014}. Best is trial 101 with value: 0.9018228892404868.\n",
      "[I 2024-02-13 16:36:24,880] Trial 142 finished with value: 0.8995485165554962 and parameters: {'iterations': 1278, 'depth': 5, 'learning_rate': 0.06943959286177076}. Best is trial 101 with value: 0.9018228892404868.\n",
      "[I 2024-02-13 16:36:37,417] Trial 143 finished with value: 0.9002227238971873 and parameters: {'iterations': 1200, 'depth': 6, 'learning_rate': 0.06122244618946331}. Best is trial 101 with value: 0.9018228892404868.\n",
      "[I 2024-02-13 16:36:49,041] Trial 144 finished with value: 0.8989716470752173 and parameters: {'iterations': 1249, 'depth': 5, 'learning_rate': 0.07653998753688451}. Best is trial 101 with value: 0.9018228892404868.\n",
      "[I 2024-02-13 16:36:59,429] Trial 145 finished with value: 0.8996031951843838 and parameters: {'iterations': 1185, 'depth': 4, 'learning_rate': 0.08590776275464966}. Best is trial 101 with value: 0.9018228892404868.\n",
      "[I 2024-02-13 16:37:08,762] Trial 146 finished with value: 0.8991446475009329 and parameters: {'iterations': 1210, 'depth': 6, 'learning_rate': 0.11477377882450722}. Best is trial 101 with value: 0.9018228892404868.\n",
      "[I 2024-02-13 16:37:25,337] Trial 147 finished with value: 0.9007954826769957 and parameters: {'iterations': 1315, 'depth': 6, 'learning_rate': 0.05169445071008209}. Best is trial 101 with value: 0.9018228892404868.\n",
      "[I 2024-02-13 16:37:40,171] Trial 148 finished with value: 0.8979699496849856 and parameters: {'iterations': 1342, 'depth': 6, 'learning_rate': 0.055963130073145004}. Best is trial 101 with value: 0.9018228892404868.\n",
      "[I 2024-02-13 16:37:54,333] Trial 149 finished with value: 0.9002676902159261 and parameters: {'iterations': 1298, 'depth': 9, 'learning_rate': 0.0648233509553314}. Best is trial 101 with value: 0.9018228892404868.\n",
      "[I 2024-02-13 16:38:09,696] Trial 150 finished with value: 0.8995404346360025 and parameters: {'iterations': 1162, 'depth': 6, 'learning_rate': 0.053006908046566596}. Best is trial 101 with value: 0.9018228892404868.\n",
      "[I 2024-02-13 16:38:17,386] Trial 151 finished with value: 0.8977299197450022 and parameters: {'iterations': 1254, 'depth': 5, 'learning_rate': 0.07045914714705083}. Best is trial 101 with value: 0.9018228892404868.\n",
      "[I 2024-02-13 16:38:51,070] Trial 152 finished with value: 0.8989391153953514 and parameters: {'iterations': 1314, 'depth': 7, 'learning_rate': 0.016938807697161322}. Best is trial 101 with value: 0.9018228892404868.\n",
      "[I 2024-02-13 16:39:04,421] Trial 153 finished with value: 0.8991894482739732 and parameters: {'iterations': 1279, 'depth': 6, 'learning_rate': 0.07500529444635916}. Best is trial 101 with value: 0.9018228892404868.\n",
      "[I 2024-02-13 16:39:18,158] Trial 154 finished with value: 0.8957515439737178 and parameters: {'iterations': 1216, 'depth': 5, 'learning_rate': 0.023242021725960908}. Best is trial 101 with value: 0.9018228892404868.\n",
      "[I 2024-02-13 16:39:32,349] Trial 155 finished with value: 0.9005625293763964 and parameters: {'iterations': 1361, 'depth': 6, 'learning_rate': 0.06034293911426771}. Best is trial 101 with value: 0.9018228892404868.\n",
      "[I 2024-02-13 16:40:00,481] Trial 156 finished with value: 0.8976011737520686 and parameters: {'iterations': 1401, 'depth': 11, 'learning_rate': 0.05158535810098872}. Best is trial 101 with value: 0.9018228892404868.\n",
      "[I 2024-02-13 16:40:13,898] Trial 157 finished with value: 0.9008238703491769 and parameters: {'iterations': 852, 'depth': 6, 'learning_rate': 0.059148023547261105}. Best is trial 101 with value: 0.9018228892404868.\n",
      "[I 2024-02-13 16:40:27,732] Trial 158 finished with value: 0.8993272063002699 and parameters: {'iterations': 629, 'depth': 6, 'learning_rate': 0.05787264567602318}. Best is trial 101 with value: 0.9018228892404868.\n",
      "[I 2024-02-13 16:40:38,471] Trial 159 finished with value: 0.8974293949199167 and parameters: {'iterations': 817, 'depth': 7, 'learning_rate': 0.0403766303162896}. Best is trial 101 with value: 0.9018228892404868.\n",
      "[I 2024-02-13 16:40:47,659] Trial 160 finished with value: 0.8998555946209112 and parameters: {'iterations': 404, 'depth': 6, 'learning_rate': 0.06371874577251137}. Best is trial 101 with value: 0.9018228892404868.\n",
      "[I 2024-02-13 16:40:58,766] Trial 161 finished with value: 0.9007414696289782 and parameters: {'iterations': 1364, 'depth': 6, 'learning_rate': 0.0680156053500968}. Best is trial 101 with value: 0.9018228892404868.\n",
      "[I 2024-02-13 16:41:11,024] Trial 162 finished with value: 0.899917938174384 and parameters: {'iterations': 1366, 'depth': 6, 'learning_rate': 0.05940288580846539}. Best is trial 101 with value: 0.9018228892404868.\n",
      "[I 2024-02-13 16:41:23,513] Trial 163 finished with value: 0.9011147079679875 and parameters: {'iterations': 1347, 'depth': 6, 'learning_rate': 0.06736241875580269}. Best is trial 101 with value: 0.9018228892404868.\n",
      "[I 2024-02-13 16:41:38,274] Trial 164 finished with value: 0.9011787101860654 and parameters: {'iterations': 1418, 'depth': 6, 'learning_rate': 0.0667915957658986}. Best is trial 101 with value: 0.9018228892404868.\n",
      "[I 2024-02-13 16:41:50,391] Trial 165 finished with value: 0.9000577186377638 and parameters: {'iterations': 1426, 'depth': 7, 'learning_rate': 0.0680630351927133}. Best is trial 101 with value: 0.9018228892404868.\n",
      "[I 2024-02-13 16:42:00,452] Trial 166 finished with value: 0.8998677844907186 and parameters: {'iterations': 877, 'depth': 6, 'learning_rate': 0.08250081497693351}. Best is trial 101 with value: 0.9018228892404868.\n",
      "[I 2024-02-13 16:42:09,147] Trial 167 finished with value: 0.8984512708424057 and parameters: {'iterations': 1397, 'depth': 6, 'learning_rate': 0.07212382567105759}. Best is trial 101 with value: 0.9018228892404868.\n",
      "[I 2024-02-13 16:42:35,327] Trial 168 finished with value: 0.8967929412054558 and parameters: {'iterations': 1331, 'depth': 6, 'learning_rate': 0.012978236152640779}. Best is trial 101 with value: 0.9018228892404868.\n",
      "[I 2024-02-13 16:42:45,800] Trial 169 finished with value: 0.8985027434955767 and parameters: {'iterations': 1356, 'depth': 7, 'learning_rate': 0.07874215067299854}. Best is trial 101 with value: 0.9018228892404868.\n",
      "[I 2024-02-13 16:43:00,833] Trial 170 finished with value: 0.8998461499642043 and parameters: {'iterations': 1425, 'depth': 7, 'learning_rate': 0.0481586263794583}. Best is trial 101 with value: 0.9018228892404868.\n",
      "[I 2024-02-13 16:43:12,755] Trial 171 finished with value: 0.9004636467225773 and parameters: {'iterations': 1314, 'depth': 6, 'learning_rate': 0.06681750283071672}. Best is trial 101 with value: 0.9018228892404868.\n",
      "[I 2024-02-13 16:43:24,513] Trial 172 finished with value: 0.8995220274130628 and parameters: {'iterations': 1375, 'depth': 6, 'learning_rate': 0.06538190308992607}. Best is trial 101 with value: 0.9018228892404868.\n",
      "[I 2024-02-13 16:49:23,550] Trial 173 finished with value: 0.8882264813441396 and parameters: {'iterations': 1260, 'depth': 15, 'learning_rate': 0.026833049995438694}. Best is trial 101 with value: 0.9018228892404868.\n",
      "[I 2024-02-13 16:49:37,225] Trial 174 finished with value: 0.8999356419641686 and parameters: {'iterations': 1236, 'depth': 6, 'learning_rate': 0.06183330983979066}. Best is trial 101 with value: 0.9018228892404868.\n",
      "[I 2024-02-13 16:49:48,519] Trial 175 finished with value: 0.8998714467625664 and parameters: {'iterations': 1126, 'depth': 6, 'learning_rate': 0.07328740631357125}. Best is trial 101 with value: 0.9018228892404868.\n",
      "[I 2024-02-13 16:50:01,112] Trial 176 finished with value: 0.9004493503763137 and parameters: {'iterations': 1296, 'depth': 6, 'learning_rate': 0.057266452171888575}. Best is trial 101 with value: 0.9018228892404868.\n",
      "[I 2024-02-13 16:50:19,098] Trial 177 finished with value: 0.8971231056437953 and parameters: {'iterations': 1333, 'depth': 6, 'learning_rate': 0.020242127311883212}. Best is trial 101 with value: 0.9018228892404868.\n",
      "[I 2024-02-13 16:50:29,125] Trial 178 finished with value: 0.9001545599422583 and parameters: {'iterations': 1471, 'depth': 7, 'learning_rate': 0.08349422817888698}. Best is trial 101 with value: 0.9018228892404868.\n",
      "[I 2024-02-13 16:50:42,838] Trial 179 finished with value: 0.9005472163363237 and parameters: {'iterations': 1173, 'depth': 6, 'learning_rate': 0.0669626549805851}. Best is trial 101 with value: 0.9018228892404868.\n",
      "[I 2024-02-13 16:50:57,416] Trial 180 finished with value: 0.9002060169961791 and parameters: {'iterations': 1391, 'depth': 6, 'learning_rate': 0.07642689093525765}. Best is trial 101 with value: 0.9018228892404868.\n",
      "[I 2024-02-13 16:51:15,126] Trial 181 finished with value: 0.9005547726640366 and parameters: {'iterations': 1367, 'depth': 6, 'learning_rate': 0.05967995625234464}. Best is trial 101 with value: 0.9018228892404868.\n",
      "[I 2024-02-13 16:51:29,658] Trial 182 finished with value: 0.8981869732553804 and parameters: {'iterations': 1352, 'depth': 6, 'learning_rate': 0.05283856116425751}. Best is trial 101 with value: 0.9018228892404868.\n",
      "[I 2024-02-13 16:51:43,151] Trial 183 finished with value: 0.900108477029622 and parameters: {'iterations': 1445, 'depth': 6, 'learning_rate': 0.06262349568046108}. Best is trial 101 with value: 0.9018228892404868.\n",
      "[I 2024-02-13 16:51:58,172] Trial 184 finished with value: 0.9001811941892615 and parameters: {'iterations': 1306, 'depth': 5, 'learning_rate': 0.07035566892588165}. Best is trial 101 with value: 0.9018228892404868.\n",
      "[I 2024-02-13 16:52:07,584] Trial 185 finished with value: 0.8993072328651031 and parameters: {'iterations': 1270, 'depth': 6, 'learning_rate': 0.2163884010585767}. Best is trial 101 with value: 0.9018228892404868.\n",
      "[I 2024-02-13 16:52:15,546] Trial 186 finished with value: 0.8995906965084355 and parameters: {'iterations': 1413, 'depth': 7, 'learning_rate': 0.2820572114633038}. Best is trial 101 with value: 0.9018228892404868.\n",
      "[I 2024-02-13 16:52:25,000] Trial 187 finished with value: 0.9005574627382069 and parameters: {'iterations': 1239, 'depth': 6, 'learning_rate': 0.09083467497388067}. Best is trial 101 with value: 0.9018228892404868.\n",
      "[I 2024-02-13 16:52:39,265] Trial 188 finished with value: 0.8990092253383547 and parameters: {'iterations': 1343, 'depth': 6, 'learning_rate': 0.057418629764553634}. Best is trial 101 with value: 0.9018228892404868.\n",
      "[I 2024-02-13 16:52:51,488] Trial 189 finished with value: 0.9007766489799697 and parameters: {'iterations': 747, 'depth': 5, 'learning_rate': 0.07866405867987411}. Best is trial 101 with value: 0.9018228892404868.\n",
      "[I 2024-02-13 16:53:04,274] Trial 190 finished with value: 0.8986349599909307 and parameters: {'iterations': 669, 'depth': 5, 'learning_rate': 0.07955151295934845}. Best is trial 101 with value: 0.9018228892404868.\n",
      "[I 2024-02-13 16:53:18,302] Trial 191 finished with value: 0.9004867060291177 and parameters: {'iterations': 1191, 'depth': 5, 'learning_rate': 0.07055146170362511}. Best is trial 101 with value: 0.9018228892404868.\n",
      "[I 2024-02-13 16:53:34,128] Trial 192 finished with value: 0.9001263590815703 and parameters: {'iterations': 746, 'depth': 5, 'learning_rate': 0.06207007981441704}. Best is trial 101 with value: 0.9018228892404868.\n",
      "[I 2024-02-13 16:53:49,249] Trial 193 finished with value: 0.8995753271832986 and parameters: {'iterations': 715, 'depth': 6, 'learning_rate': 0.07689616335483968}. Best is trial 101 with value: 0.9018228892404868.\n",
      "[I 2024-02-13 16:53:59,412] Trial 194 finished with value: 0.8983946413083761 and parameters: {'iterations': 789, 'depth': 6, 'learning_rate': 0.08475111187016396}. Best is trial 101 with value: 0.9018228892404868.\n",
      "[I 2024-02-13 16:54:11,686] Trial 195 finished with value: 0.8988986578691198 and parameters: {'iterations': 753, 'depth': 5, 'learning_rate': 0.06660066864818472}. Best is trial 101 with value: 0.9018228892404868.\n",
      "[I 2024-02-13 16:54:16,705] Trial 196 finished with value: 0.8984512708424057 and parameters: {'iterations': 215, 'depth': 6, 'learning_rate': 0.07210638209827462}. Best is trial 101 with value: 0.9018228892404868.\n",
      "[I 2024-02-13 16:54:27,176] Trial 197 finished with value: 0.8996099076660912 and parameters: {'iterations': 1282, 'depth': 7, 'learning_rate': 0.09678101770888183}. Best is trial 101 with value: 0.9018228892404868.\n",
      "[I 2024-02-13 16:54:42,048] Trial 198 finished with value: 0.899827836935191 and parameters: {'iterations': 1222, 'depth': 6, 'learning_rate': 0.05355120659887603}. Best is trial 101 with value: 0.9018228892404868.\n",
      "[I 2024-02-13 16:54:59,046] Trial 199 finished with value: 0.8989353711633787 and parameters: {'iterations': 854, 'depth': 5, 'learning_rate': 0.06323475952666133}. Best is trial 101 with value: 0.9018228892404868.\n",
      "[I 2024-02-13 16:55:09,913] Trial 200 finished with value: 0.900165056540185 and parameters: {'iterations': 1323, 'depth': 6, 'learning_rate': 0.07702870085830893}. Best is trial 101 with value: 0.9018228892404868.\n",
      "[I 2024-02-13 16:55:19,992] Trial 201 finished with value: 0.900838710702834 and parameters: {'iterations': 1227, 'depth': 6, 'learning_rate': 0.08891431315065776}. Best is trial 101 with value: 0.9018228892404868.\n",
      "[I 2024-02-13 16:55:28,047] Trial 202 finished with value: 0.8991201270197129 and parameters: {'iterations': 1248, 'depth': 6, 'learning_rate': 0.08694290444443624}. Best is trial 101 with value: 0.9018228892404868.\n",
      "[I 2024-02-13 16:55:40,700] Trial 203 finished with value: 0.9017812364889299 and parameters: {'iterations': 1145, 'depth': 6, 'learning_rate': 0.06817152849162735}. Best is trial 101 with value: 0.9018228892404868.\n",
      "[I 2024-02-13 16:55:52,477] Trial 204 finished with value: 0.9005300964053233 and parameters: {'iterations': 1111, 'depth': 6, 'learning_rate': 0.06824654177484607}. Best is trial 101 with value: 0.9018228892404868.\n",
      "[I 2024-02-13 16:56:01,345] Trial 205 finished with value: 0.8998862508305228 and parameters: {'iterations': 1152, 'depth': 6, 'learning_rate': 0.08153816604259392}. Best is trial 101 with value: 0.9018228892404868.\n",
      "[I 2024-02-13 16:56:10,150] Trial 206 finished with value: 0.9002028474802917 and parameters: {'iterations': 1195, 'depth': 5, 'learning_rate': 0.09165700607225523}. Best is trial 101 with value: 0.9018228892404868.\n",
      "[I 2024-02-13 16:56:20,256] Trial 207 finished with value: 0.899130443700025 and parameters: {'iterations': 1169, 'depth': 7, 'learning_rate': 0.07351961156868365}. Best is trial 101 with value: 0.9018228892404868.\n",
      "[I 2024-02-13 16:56:31,509] Trial 208 finished with value: 0.9001722400280979 and parameters: {'iterations': 1059, 'depth': 6, 'learning_rate': 0.06716313987078644}. Best is trial 101 with value: 0.9018228892404868.\n",
      "[I 2024-02-13 16:56:45,540] Trial 209 finished with value: 0.8993037841321341 and parameters: {'iterations': 1218, 'depth': 5, 'learning_rate': 0.09953451983721522}. Best is trial 101 with value: 0.9018228892404868.\n",
      "[I 2024-02-13 16:56:51,599] Trial 210 finished with value: 0.8953326191810717 and parameters: {'iterations': 1191, 'depth': 6, 'learning_rate': 0.47103186206976655}. Best is trial 101 with value: 0.9018228892404868.\n",
      "[I 2024-02-13 16:57:04,215] Trial 211 finished with value: 0.899802837247668 and parameters: {'iterations': 958, 'depth': 6, 'learning_rate': 0.06040612866416821}. Best is trial 101 with value: 0.9018228892404868.\n",
      "[I 2024-02-13 16:57:19,621] Trial 212 finished with value: 0.9008308915424782 and parameters: {'iterations': 1383, 'depth': 6, 'learning_rate': 0.07189763217815354}. Best is trial 101 with value: 0.9018228892404868.\n",
      "[I 2024-02-13 16:57:29,636] Trial 213 finished with value: 0.8994508932927738 and parameters: {'iterations': 1135, 'depth': 6, 'learning_rate': 0.07849525550284962}. Best is trial 101 with value: 0.9018228892404868.\n",
      "[I 2024-02-13 16:57:45,489] Trial 214 finished with value: 0.9014864114440013 and parameters: {'iterations': 1388, 'depth': 6, 'learning_rate': 0.0716379872685001}. Best is trial 101 with value: 0.9018228892404868.\n",
      "[I 2024-02-13 16:57:52,630] Trial 215 finished with value: 0.8985283804403903 and parameters: {'iterations': 1380, 'depth': 6, 'learning_rate': 0.07231816478352898}. Best is trial 101 with value: 0.9018228892404868.\n",
      "[I 2024-02-13 16:58:01,229] Trial 216 finished with value: 0.8988751428662851 and parameters: {'iterations': 1406, 'depth': 6, 'learning_rate': 0.0856416838633095}. Best is trial 101 with value: 0.9018228892404868.\n",
      "[I 2024-02-13 16:58:11,423] Trial 217 finished with value: 0.8992024197041893 and parameters: {'iterations': 1385, 'depth': 6, 'learning_rate': 0.07395606434006194}. Best is trial 101 with value: 0.9018228892404868.\n",
      "[I 2024-02-13 16:58:19,272] Trial 218 finished with value: 0.8974934465815594 and parameters: {'iterations': 1433, 'depth': 6, 'learning_rate': 0.08156287026067209}. Best is trial 101 with value: 0.9018228892404868.\n",
      "[I 2024-02-13 16:58:26,838] Trial 219 finished with value: 0.8982156498241675 and parameters: {'iterations': 1321, 'depth': 7, 'learning_rate': 0.06610785197475236}. Best is trial 101 with value: 0.9018228892404868.\n",
      "[I 2024-02-13 16:58:36,374] Trial 220 finished with value: 0.9006861506453523 and parameters: {'iterations': 1288, 'depth': 8, 'learning_rate': 0.09091745418671494}. Best is trial 101 with value: 0.9018228892404868.\n",
      "[I 2024-02-13 16:58:44,852] Trial 221 finished with value: 0.899093383202158 and parameters: {'iterations': 1284, 'depth': 8, 'learning_rate': 0.09700951193156027}. Best is trial 101 with value: 0.9018228892404868.\n",
      "[I 2024-02-13 16:58:56,481] Trial 222 finished with value: 0.8996988892625942 and parameters: {'iterations': 1251, 'depth': 9, 'learning_rate': 0.0921401273659517}. Best is trial 101 with value: 0.9018228892404868.\n",
      "[I 2024-02-13 16:59:08,311] Trial 223 finished with value: 0.89810944303227 and parameters: {'iterations': 1333, 'depth': 9, 'learning_rate': 0.07700029779183691}. Best is trial 101 with value: 0.9018228892404868.\n",
      "[I 2024-02-13 16:59:17,757] Trial 224 finished with value: 0.8979674354207657 and parameters: {'iterations': 1296, 'depth': 6, 'learning_rate': 0.08521630710853567}. Best is trial 101 with value: 0.9018228892404868.\n",
      "[I 2024-02-13 16:59:28,411] Trial 225 finished with value: 0.8988802945724722 and parameters: {'iterations': 1349, 'depth': 7, 'learning_rate': 0.07133180144882577}. Best is trial 101 with value: 0.9018228892404868.\n",
      "[I 2024-02-13 16:59:38,593] Trial 226 finished with value: 0.8998256484215463 and parameters: {'iterations': 1236, 'depth': 8, 'learning_rate': 0.06446726258311562}. Best is trial 101 with value: 0.9018228892404868.\n",
      "[I 2024-02-13 16:59:48,507] Trial 227 finished with value: 0.8997125795034442 and parameters: {'iterations': 1270, 'depth': 8, 'learning_rate': 0.06981117805168875}. Best is trial 101 with value: 0.9018228892404868.\n",
      "[I 2024-02-13 16:59:57,315] Trial 228 finished with value: 0.8990423767935627 and parameters: {'iterations': 1384, 'depth': 6, 'learning_rate': 0.08191357571723328}. Best is trial 101 with value: 0.9018228892404868.\n",
      "[I 2024-02-13 17:00:06,996] Trial 229 finished with value: 0.8997868100628349 and parameters: {'iterations': 1304, 'depth': 7, 'learning_rate': 0.10525048480426029}. Best is trial 101 with value: 0.9018228892404868.\n",
      "[I 2024-02-13 17:00:20,141] Trial 230 finished with value: 0.8983654196122299 and parameters: {'iterations': 1357, 'depth': 6, 'learning_rate': 0.08947996703830545}. Best is trial 101 with value: 0.9018228892404868.\n",
      "[I 2024-02-13 17:00:36,855] Trial 231 finished with value: 0.9002018756016196 and parameters: {'iterations': 1193, 'depth': 6, 'learning_rate': 0.06329110063184326}. Best is trial 101 with value: 0.9018228892404868.\n",
      "[I 2024-02-13 17:00:53,051] Trial 232 finished with value: 0.8995712653494478 and parameters: {'iterations': 1228, 'depth': 6, 'learning_rate': 0.057720056875074095}. Best is trial 101 with value: 0.9018228892404868.\n",
      "[I 2024-02-13 17:01:09,477] Trial 233 finished with value: 0.9011029888645606 and parameters: {'iterations': 1160, 'depth': 6, 'learning_rate': 0.06947393391833233}. Best is trial 101 with value: 0.9018228892404868.\n",
      "[I 2024-02-13 17:01:19,596] Trial 234 finished with value: 0.8998496917757576 and parameters: {'iterations': 1160, 'depth': 6, 'learning_rate': 0.07386788892623641}. Best is trial 101 with value: 0.9018228892404868.\n",
      "[I 2024-02-13 17:01:32,326] Trial 235 finished with value: 0.8998832593247953 and parameters: {'iterations': 1133, 'depth': 6, 'learning_rate': 0.06744733230198698}. Best is trial 101 with value: 0.9018228892404868.\n",
      "[I 2024-02-13 17:01:46,120] Trial 236 finished with value: 0.901126987716142 and parameters: {'iterations': 1171, 'depth': 6, 'learning_rate': 0.08034040212146225}. Best is trial 101 with value: 0.9018228892404868.\n",
      "[I 2024-02-13 17:02:01,473] Trial 237 finished with value: 0.8982954190061714 and parameters: {'iterations': 1096, 'depth': 6, 'learning_rate': 0.050352348222998375}. Best is trial 101 with value: 0.9018228892404868.\n",
      "[I 2024-02-13 17:02:11,366] Trial 238 finished with value: 0.8995746950165053 and parameters: {'iterations': 1163, 'depth': 6, 'learning_rate': 0.07767000074043094}. Best is trial 101 with value: 0.9018228892404868.\n",
      "[I 2024-02-13 17:02:22,757] Trial 239 finished with value: 0.9001271638103131 and parameters: {'iterations': 1407, 'depth': 6, 'learning_rate': 0.05748387598185362}. Best is trial 101 with value: 0.9018228892404868.\n",
      "[I 2024-02-13 17:02:34,980] Trial 240 finished with value: 0.901466642961883 and parameters: {'iterations': 1259, 'depth': 6, 'learning_rate': 0.0709767839555621}. Best is trial 101 with value: 0.9018228892404868.\n",
      "[I 2024-02-13 17:02:46,806] Trial 241 finished with value: 0.8998266426516477 and parameters: {'iterations': 1265, 'depth': 6, 'learning_rate': 0.07036335930591832}. Best is trial 101 with value: 0.9018228892404868.\n",
      "[I 2024-02-13 17:02:57,823] Trial 242 finished with value: 0.9002086859799283 and parameters: {'iterations': 1217, 'depth': 6, 'learning_rate': 0.07837795559198288}. Best is trial 101 with value: 0.9018228892404868.\n",
      "[I 2024-02-13 17:03:10,007] Trial 243 finished with value: 0.8998528815578762 and parameters: {'iterations': 1305, 'depth': 6, 'learning_rate': 0.06287496746893158}. Best is trial 101 with value: 0.9018228892404868.\n",
      "[I 2024-02-13 17:03:20,601] Trial 244 finished with value: 0.9007693645813998 and parameters: {'iterations': 703, 'depth': 6, 'learning_rate': 0.07187956233089836}. Best is trial 101 with value: 0.9018228892404868.\n",
      "[I 2024-02-13 17:03:30,394] Trial 245 finished with value: 0.9008458624075881 and parameters: {'iterations': 678, 'depth': 6, 'learning_rate': 0.07109560253172405}. Best is trial 101 with value: 0.9018228892404868.\n",
      "[I 2024-02-13 17:03:38,668] Trial 246 finished with value: 0.9001755369409608 and parameters: {'iterations': 658, 'depth': 6, 'learning_rate': 0.07401543790603173}. Best is trial 101 with value: 0.9018228892404868.\n",
      "[I 2024-02-13 17:03:48,760] Trial 247 finished with value: 0.9007148166855412 and parameters: {'iterations': 612, 'depth': 6, 'learning_rate': 0.07045770006319052}. Best is trial 101 with value: 0.9018228892404868.\n",
      "[I 2024-02-13 17:03:58,547] Trial 248 finished with value: 0.8995889011007591 and parameters: {'iterations': 682, 'depth': 6, 'learning_rate': 0.08183117302159393}. Best is trial 101 with value: 0.9018228892404868.\n",
      "[I 2024-02-13 17:04:12,896] Trial 249 finished with value: 0.900770354447795 and parameters: {'iterations': 722, 'depth': 6, 'learning_rate': 0.06273656453169339}. Best is trial 101 with value: 0.9018228892404868.\n",
      "[I 2024-02-13 17:04:25,486] Trial 250 finished with value: 0.8998149344233902 and parameters: {'iterations': 708, 'depth': 6, 'learning_rate': 0.06019193826143236}. Best is trial 101 with value: 0.9018228892404868.\n",
      "[I 2024-02-13 17:04:34,647] Trial 251 finished with value: 0.900062280329601 and parameters: {'iterations': 722, 'depth': 6, 'learning_rate': 0.07592805031925948}. Best is trial 101 with value: 0.9018228892404868.\n",
      "[I 2024-02-13 17:04:47,947] Trial 252 finished with value: 0.8983019095618089 and parameters: {'iterations': 743, 'depth': 6, 'learning_rate': 0.055433812179146676}. Best is trial 101 with value: 0.9018228892404868.\n",
      "[I 2024-02-13 17:04:55,900] Trial 253 finished with value: 0.8996448084940651 and parameters: {'iterations': 700, 'depth': 6, 'learning_rate': 0.06452925996904066}. Best is trial 101 with value: 0.9018228892404868.\n",
      "[I 2024-02-13 17:05:06,280] Trial 254 finished with value: 0.9013449928056149 and parameters: {'iterations': 688, 'depth': 6, 'learning_rate': 0.07141489829689228}. Best is trial 101 with value: 0.9018228892404868.\n",
      "[I 2024-02-13 17:05:14,184] Trial 255 finished with value: 0.8989246638834978 and parameters: {'iterations': 699, 'depth': 6, 'learning_rate': 0.0834408112906454}. Best is trial 101 with value: 0.9018228892404868.\n",
      "[I 2024-02-13 17:05:25,732] Trial 256 finished with value: 0.8997991795356275 and parameters: {'iterations': 649, 'depth': 6, 'learning_rate': 0.07251782422630827}. Best is trial 101 with value: 0.9018228892404868.\n",
      "[I 2024-02-13 17:05:34,323] Trial 257 finished with value: 0.8994261908798875 and parameters: {'iterations': 587, 'depth': 5, 'learning_rate': 0.062451033458936385}. Best is trial 101 with value: 0.9018228892404868.\n",
      "[I 2024-02-13 17:05:43,923] Trial 258 finished with value: 0.9004728118161758 and parameters: {'iterations': 757, 'depth': 6, 'learning_rate': 0.07722445361340491}. Best is trial 101 with value: 0.9018228892404868.\n",
      "[I 2024-02-13 17:05:54,962] Trial 259 finished with value: 0.9005177763437313 and parameters: {'iterations': 783, 'depth': 6, 'learning_rate': 0.06834939144608616}. Best is trial 101 with value: 0.9018228892404868.\n",
      "[I 2024-02-13 17:06:06,818] Trial 260 finished with value: 0.8995681715424597 and parameters: {'iterations': 666, 'depth': 5, 'learning_rate': 0.08408091272648219}. Best is trial 101 with value: 0.9018228892404868.\n",
      "[I 2024-02-13 17:06:18,899] Trial 261 finished with value: 0.8994553312837276 and parameters: {'iterations': 726, 'depth': 6, 'learning_rate': 0.05403426335106055}. Best is trial 101 with value: 0.9018228892404868.\n",
      "[I 2024-02-13 17:06:29,135] Trial 262 finished with value: 0.8998625141914767 and parameters: {'iterations': 629, 'depth': 6, 'learning_rate': 0.07389277147885616}. Best is trial 101 with value: 0.9018228892404868.\n",
      "[I 2024-02-13 17:06:40,690] Trial 263 finished with value: 0.8982170412200424 and parameters: {'iterations': 727, 'depth': 6, 'learning_rate': 0.06523724632093313}. Best is trial 101 with value: 0.9018228892404868.\n",
      "[I 2024-02-13 17:06:53,352] Trial 264 finished with value: 0.8995750292775171 and parameters: {'iterations': 697, 'depth': 5, 'learning_rate': 0.05914078524754447}. Best is trial 101 with value: 0.9018228892404868.\n",
      "[I 2024-02-13 17:07:01,620] Trial 265 finished with value: 0.8978872363485655 and parameters: {'iterations': 665, 'depth': 6, 'learning_rate': 0.07994314733059389}. Best is trial 101 with value: 0.9018228892404868.\n",
      "[I 2024-02-13 17:07:16,513] Trial 266 finished with value: 0.8998474759104448 and parameters: {'iterations': 769, 'depth': 6, 'learning_rate': 0.08756270066202403}. Best is trial 101 with value: 0.9018228892404868.\n",
      "[I 2024-02-13 17:07:29,511] Trial 267 finished with value: 0.8990955141012946 and parameters: {'iterations': 687, 'depth': 6, 'learning_rate': 0.06901001399505356}. Best is trial 101 with value: 0.9018228892404868.\n",
      "[I 2024-02-13 17:07:44,330] Trial 268 finished with value: 0.8985198062586478 and parameters: {'iterations': 803, 'depth': 7, 'learning_rate': 0.06282665296435153}. Best is trial 101 with value: 0.9018228892404868.\n",
      "[I 2024-02-13 17:07:57,962] Trial 269 finished with value: 0.8992886252773108 and parameters: {'iterations': 1252, 'depth': 5, 'learning_rate': 0.07311938374248989}. Best is trial 101 with value: 0.9018228892404868.\n",
      "[I 2024-02-13 17:08:15,103] Trial 270 finished with value: 0.8985346972691617 and parameters: {'iterations': 759, 'depth': 6, 'learning_rate': 0.07853478402935116}. Best is trial 101 with value: 0.9018228892404868.\n",
      "[I 2024-02-13 17:08:27,101] Trial 271 finished with value: 0.9008196464918936 and parameters: {'iterations': 850, 'depth': 6, 'learning_rate': 0.06751625426025325}. Best is trial 101 with value: 0.9018228892404868.\n",
      "[I 2024-02-13 17:08:48,591] Trial 272 finished with value: 0.8989560802945149 and parameters: {'iterations': 804, 'depth': 6, 'learning_rate': 0.04947904891461779}. Best is trial 101 with value: 0.9018228892404868.\n",
      "[I 2024-02-13 17:09:03,976] Trial 273 finished with value: 0.8982352364157956 and parameters: {'iterations': 925, 'depth': 7, 'learning_rate': 0.057720814563395624}. Best is trial 101 with value: 0.9018228892404868.\n",
      "[I 2024-02-13 17:09:18,443] Trial 274 finished with value: 0.8998839638264441 and parameters: {'iterations': 905, 'depth': 6, 'learning_rate': 0.06440551274206}. Best is trial 101 with value: 0.9018228892404868.\n",
      "[I 2024-02-13 17:09:26,525] Trial 275 finished with value: 0.9002092002173199 and parameters: {'iterations': 443, 'depth': 4, 'learning_rate': 0.09336866581692604}. Best is trial 101 with value: 0.9018228892404868.\n",
      "[I 2024-02-13 17:09:44,642] Trial 276 finished with value: 0.9002600743566275 and parameters: {'iterations': 1011, 'depth': 6, 'learning_rate': 0.06798989955925931}. Best is trial 101 with value: 0.9018228892404868.\n",
      "[I 2024-02-13 17:09:58,625] Trial 277 finished with value: 0.9000757203722853 and parameters: {'iterations': 1348, 'depth': 7, 'learning_rate': 0.05424671567428175}. Best is trial 101 with value: 0.9018228892404868.\n",
      "[I 2024-02-13 17:10:11,657] Trial 278 finished with value: 0.9014778991968387 and parameters: {'iterations': 820, 'depth': 5, 'learning_rate': 0.05968129385721219}. Best is trial 101 with value: 0.9018228892404868.\n",
      "[I 2024-02-13 17:10:22,927] Trial 279 finished with value: 0.8998777001101663 and parameters: {'iterations': 826, 'depth': 5, 'learning_rate': 0.07769864359751763}. Best is trial 101 with value: 0.9018228892404868.\n",
      "[I 2024-02-13 17:10:33,870] Trial 280 finished with value: 0.8991757904472819 and parameters: {'iterations': 878, 'depth': 5, 'learning_rate': 0.08504683856026965}. Best is trial 101 with value: 0.9018228892404868.\n",
      "[I 2024-02-13 17:10:51,014] Trial 281 finished with value: 0.8989906308491474 and parameters: {'iterations': 1235, 'depth': 3, 'learning_rate': 0.06857992845739902}. Best is trial 101 with value: 0.9018228892404868.\n",
      "[I 2024-02-13 17:11:02,275] Trial 282 finished with value: 0.8992054863910705 and parameters: {'iterations': 838, 'depth': 5, 'learning_rate': 0.09913975045500316}. Best is trial 101 with value: 0.9018228892404868.\n",
      "[I 2024-02-13 17:11:20,562] Trial 283 finished with value: 0.9005471110519977 and parameters: {'iterations': 1452, 'depth': 5, 'learning_rate': 0.045989023872592245}. Best is trial 101 with value: 0.9018228892404868.\n",
      "[I 2024-02-13 17:11:35,720] Trial 284 finished with value: 0.8997972728543145 and parameters: {'iterations': 852, 'depth': 5, 'learning_rate': 0.059227075144130975}. Best is trial 101 with value: 0.9018228892404868.\n",
      "[I 2024-02-13 17:11:47,509] Trial 285 finished with value: 0.8998864827243359 and parameters: {'iterations': 1320, 'depth': 6, 'learning_rate': 0.07387090806323321}. Best is trial 101 with value: 0.9018228892404868.\n",
      "[I 2024-02-13 17:11:55,977] Trial 286 finished with value: 0.8994187127709541 and parameters: {'iterations': 892, 'depth': 6, 'learning_rate': 0.08105169035671339}. Best is trial 101 with value: 0.9018228892404868.\n",
      "[I 2024-02-13 17:12:08,338] Trial 287 finished with value: 0.9008097133162557 and parameters: {'iterations': 1202, 'depth': 5, 'learning_rate': 0.06646438734125247}. Best is trial 101 with value: 0.9018228892404868.\n",
      "[I 2024-02-13 17:12:23,449] Trial 288 finished with value: 0.8995791709632596 and parameters: {'iterations': 1190, 'depth': 6, 'learning_rate': 0.055042099182159104}. Best is trial 101 with value: 0.9018228892404868.\n",
      "[I 2024-02-13 17:12:38,639] Trial 289 finished with value: 0.9008375096744133 and parameters: {'iterations': 1215, 'depth': 6, 'learning_rate': 0.06133092108566627}. Best is trial 101 with value: 0.9018228892404868.\n",
      "[I 2024-02-13 17:12:51,192] Trial 290 finished with value: 0.8982303362249431 and parameters: {'iterations': 1208, 'depth': 7, 'learning_rate': 0.06065639007730923}. Best is trial 101 with value: 0.9018228892404868.\n",
      "[I 2024-02-13 17:13:05,456] Trial 291 finished with value: 0.8982170412200424 and parameters: {'iterations': 1173, 'depth': 6, 'learning_rate': 0.06524146174204466}. Best is trial 101 with value: 0.9018228892404868.\n",
      "[I 2024-02-13 17:13:21,850] Trial 292 finished with value: 0.900871215429949 and parameters: {'iterations': 1212, 'depth': 6, 'learning_rate': 0.06822326813334893}. Best is trial 101 with value: 0.9018228892404868.\n",
      "[I 2024-02-13 17:13:35,927] Trial 293 finished with value: 0.9002081918768208 and parameters: {'iterations': 1253, 'depth': 6, 'learning_rate': 0.06953042412647924}. Best is trial 101 with value: 0.9018228892404868.\n",
      "[I 2024-02-13 17:13:50,132] Trial 294 finished with value: 0.899856556678725 and parameters: {'iterations': 574, 'depth': 6, 'learning_rate': 0.06060692777332755}. Best is trial 101 with value: 0.9018228892404868.\n",
      "[I 2024-02-13 17:14:02,295] Trial 295 finished with value: 0.8995022795292823 and parameters: {'iterations': 1224, 'depth': 6, 'learning_rate': 0.07304749206182751}. Best is trial 101 with value: 0.9018228892404868.\n",
      "[I 2024-02-13 17:14:15,573] Trial 296 finished with value: 0.9007414696289782 and parameters: {'iterations': 1141, 'depth': 6, 'learning_rate': 0.06802528297400229}. Best is trial 101 with value: 0.9018228892404868.\n",
      "[I 2024-02-13 17:14:30,001] Trial 297 finished with value: 0.8988322431433913 and parameters: {'iterations': 1269, 'depth': 7, 'learning_rate': 0.0626206134670049}. Best is trial 101 with value: 0.9018228892404868.\n",
      "[I 2024-02-13 17:14:38,542] Trial 298 finished with value: 0.8989107702857931 and parameters: {'iterations': 848, 'depth': 6, 'learning_rate': 0.08920508136324684}. Best is trial 101 with value: 0.9018228892404868.\n",
      "[I 2024-02-13 17:14:53,314] Trial 299 finished with value: 0.8997930974757576 and parameters: {'iterations': 1242, 'depth': 6, 'learning_rate': 0.05729609350623384}. Best is trial 101 with value: 0.9018228892404868.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of finished trials: 300\n",
      "Best trial: {'iterations': 1354, 'depth': 6, 'learning_rate': 0.0933244870266498}\n"
     ]
    }
   ],
   "source": [
    "# model hyperparams tuning.\n",
    "\n",
    "study = optuna.create_study(direction='maximize', study_name='Catboost_study')\n",
    "study.optimize(objective, n_trials=300)\n",
    "print('Number of finished trials:', len(study.trials))\n",
    "print('Best trial:', study.best_trial.params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Submission to csv."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mapping from label to source values from train target.\n",
    "\n",
    "classes = {0: 'Insufficient_Weight',\n",
    " 1: 'Normal_Weight',\n",
    " 2: 'Obesity_Type_I',\n",
    " 3: 'Obesity_Type_II',\n",
    " 4: 'Obesity_Type_III',\n",
    " 5: 'Overweight_Level_I',\n",
    " 6: 'Overweight_Level_II'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "def submission(model: object, test_data: pd.DataFrame, classes: dict):\n",
    "    model.fit(train, target)\n",
    "    predictions = model.predict(test_data.drop(columns=['id'], axis=1))\n",
    "    submission = pd.DataFrame({'id': test_data['id'], \n",
    "                               'NObeyesdad': [classes[pred[0]] for pred in predictions]})\n",
    "    submission.to_csv('submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\tlearn: 1.6379868\ttotal: 30.9ms\tremaining: 41.9s\n",
      "1:\tlearn: 1.4559435\ttotal: 56.5ms\tremaining: 38.2s\n",
      "2:\tlearn: 1.3190852\ttotal: 83.2ms\tremaining: 37.5s\n",
      "3:\tlearn: 1.1976402\ttotal: 111ms\tremaining: 37.4s\n",
      "4:\tlearn: 1.1111888\ttotal: 138ms\tremaining: 37.3s\n",
      "5:\tlearn: 1.0322470\ttotal: 164ms\tremaining: 36.8s\n",
      "6:\tlearn: 0.9682852\ttotal: 188ms\tremaining: 36.1s\n",
      "7:\tlearn: 0.9102198\ttotal: 210ms\tremaining: 35.4s\n",
      "8:\tlearn: 0.8579997\ttotal: 230ms\tremaining: 34.4s\n",
      "9:\tlearn: 0.8159344\ttotal: 250ms\tremaining: 33.6s\n",
      "10:\tlearn: 0.7789825\ttotal: 276ms\tremaining: 33.7s\n",
      "11:\tlearn: 0.7456689\ttotal: 388ms\tremaining: 43.4s\n",
      "12:\tlearn: 0.7152925\ttotal: 415ms\tremaining: 42.8s\n",
      "13:\tlearn: 0.6869570\ttotal: 451ms\tremaining: 43.1s\n",
      "14:\tlearn: 0.6628208\ttotal: 472ms\tremaining: 42.2s\n",
      "15:\tlearn: 0.6395644\ttotal: 495ms\tremaining: 41.4s\n",
      "16:\tlearn: 0.6170516\ttotal: 520ms\tremaining: 40.9s\n",
      "17:\tlearn: 0.5982516\ttotal: 540ms\tremaining: 40s\n",
      "18:\tlearn: 0.5802437\ttotal: 561ms\tremaining: 39.4s\n",
      "19:\tlearn: 0.5650778\ttotal: 586ms\tremaining: 39.1s\n",
      "20:\tlearn: 0.5499539\ttotal: 613ms\tremaining: 38.9s\n",
      "21:\tlearn: 0.5359235\ttotal: 639ms\tremaining: 38.7s\n",
      "22:\tlearn: 0.5247137\ttotal: 662ms\tremaining: 38.3s\n",
      "23:\tlearn: 0.5129437\ttotal: 688ms\tremaining: 38.1s\n",
      "24:\tlearn: 0.5029160\ttotal: 708ms\tremaining: 37.6s\n",
      "25:\tlearn: 0.4934164\ttotal: 728ms\tremaining: 37.2s\n",
      "26:\tlearn: 0.4847617\ttotal: 747ms\tremaining: 36.7s\n",
      "27:\tlearn: 0.4750893\ttotal: 768ms\tremaining: 36.4s\n",
      "28:\tlearn: 0.4680066\ttotal: 790ms\tremaining: 36.1s\n",
      "29:\tlearn: 0.4614566\ttotal: 810ms\tremaining: 35.8s\n",
      "30:\tlearn: 0.4541241\ttotal: 829ms\tremaining: 35.4s\n",
      "31:\tlearn: 0.4484805\ttotal: 849ms\tremaining: 35.1s\n",
      "32:\tlearn: 0.4433773\ttotal: 867ms\tremaining: 34.7s\n",
      "33:\tlearn: 0.4375772\ttotal: 892ms\tremaining: 34.6s\n",
      "34:\tlearn: 0.4319666\ttotal: 919ms\tremaining: 34.6s\n",
      "35:\tlearn: 0.4273716\ttotal: 945ms\tremaining: 34.6s\n",
      "36:\tlearn: 0.4224956\ttotal: 968ms\tremaining: 34.5s\n",
      "37:\tlearn: 0.4177877\ttotal: 990ms\tremaining: 34.3s\n",
      "38:\tlearn: 0.4132977\ttotal: 1.01s\tremaining: 34.2s\n",
      "39:\tlearn: 0.4093107\ttotal: 1.03s\tremaining: 33.9s\n",
      "40:\tlearn: 0.4064298\ttotal: 1.05s\tremaining: 33.5s\n",
      "41:\tlearn: 0.4030619\ttotal: 1.06s\tremaining: 33.2s\n",
      "42:\tlearn: 0.3990276\ttotal: 1.08s\tremaining: 32.9s\n",
      "43:\tlearn: 0.3959618\ttotal: 1.09s\tremaining: 32.6s\n",
      "44:\tlearn: 0.3931051\ttotal: 1.11s\tremaining: 32.4s\n",
      "45:\tlearn: 0.3891376\ttotal: 1.13s\tremaining: 32.2s\n",
      "46:\tlearn: 0.3854622\ttotal: 1.15s\tremaining: 32s\n",
      "47:\tlearn: 0.3828509\ttotal: 1.17s\tremaining: 31.9s\n",
      "48:\tlearn: 0.3804455\ttotal: 1.19s\tremaining: 31.6s\n",
      "49:\tlearn: 0.3780428\ttotal: 1.2s\tremaining: 31.4s\n",
      "50:\tlearn: 0.3756769\ttotal: 1.22s\tremaining: 31.3s\n",
      "51:\tlearn: 0.3731502\ttotal: 1.25s\tremaining: 31.2s\n",
      "52:\tlearn: 0.3716433\ttotal: 1.26s\tremaining: 31s\n",
      "53:\tlearn: 0.3698076\ttotal: 1.28s\tremaining: 30.8s\n",
      "54:\tlearn: 0.3679143\ttotal: 1.29s\tremaining: 30.6s\n",
      "55:\tlearn: 0.3659951\ttotal: 1.31s\tremaining: 30.4s\n",
      "56:\tlearn: 0.3648775\ttotal: 1.33s\tremaining: 30.2s\n",
      "57:\tlearn: 0.3627640\ttotal: 1.34s\tremaining: 30s\n",
      "58:\tlearn: 0.3607748\ttotal: 1.36s\tremaining: 29.9s\n",
      "59:\tlearn: 0.3585449\ttotal: 1.38s\tremaining: 29.8s\n",
      "60:\tlearn: 0.3568774\ttotal: 1.4s\tremaining: 29.7s\n",
      "61:\tlearn: 0.3553043\ttotal: 1.42s\tremaining: 29.6s\n",
      "62:\tlearn: 0.3530664\ttotal: 1.44s\tremaining: 29.4s\n",
      "63:\tlearn: 0.3512322\ttotal: 1.45s\tremaining: 29.3s\n",
      "64:\tlearn: 0.3491872\ttotal: 1.47s\tremaining: 29.2s\n",
      "65:\tlearn: 0.3471830\ttotal: 1.49s\tremaining: 29.1s\n",
      "66:\tlearn: 0.3454646\ttotal: 1.51s\tremaining: 29s\n",
      "67:\tlearn: 0.3443230\ttotal: 1.53s\tremaining: 28.9s\n",
      "68:\tlearn: 0.3429900\ttotal: 1.54s\tremaining: 28.8s\n",
      "69:\tlearn: 0.3416555\ttotal: 1.56s\tremaining: 28.6s\n",
      "70:\tlearn: 0.3405046\ttotal: 1.58s\tremaining: 28.5s\n",
      "71:\tlearn: 0.3391794\ttotal: 1.6s\tremaining: 28.4s\n",
      "72:\tlearn: 0.3379532\ttotal: 1.62s\tremaining: 28.4s\n",
      "73:\tlearn: 0.3370561\ttotal: 1.64s\tremaining: 28.3s\n",
      "74:\tlearn: 0.3358991\ttotal: 1.66s\tremaining: 28.3s\n",
      "75:\tlearn: 0.3346298\ttotal: 1.68s\tremaining: 28.2s\n",
      "76:\tlearn: 0.3336066\ttotal: 1.69s\tremaining: 28.1s\n",
      "77:\tlearn: 0.3326891\ttotal: 1.71s\tremaining: 28s\n",
      "78:\tlearn: 0.3312250\ttotal: 1.73s\tremaining: 27.9s\n",
      "79:\tlearn: 0.3300458\ttotal: 1.75s\tremaining: 27.8s\n",
      "80:\tlearn: 0.3289124\ttotal: 1.76s\tremaining: 27.7s\n",
      "81:\tlearn: 0.3282367\ttotal: 1.78s\tremaining: 27.6s\n",
      "82:\tlearn: 0.3272445\ttotal: 1.8s\tremaining: 27.6s\n",
      "83:\tlearn: 0.3263102\ttotal: 1.82s\tremaining: 27.5s\n",
      "84:\tlearn: 0.3256243\ttotal: 1.84s\tremaining: 27.4s\n",
      "85:\tlearn: 0.3244281\ttotal: 1.86s\tremaining: 27.4s\n",
      "86:\tlearn: 0.3236575\ttotal: 1.88s\tremaining: 27.4s\n",
      "87:\tlearn: 0.3225367\ttotal: 1.9s\tremaining: 27.4s\n",
      "88:\tlearn: 0.3211976\ttotal: 1.92s\tremaining: 27.3s\n",
      "89:\tlearn: 0.3205501\ttotal: 1.94s\tremaining: 27.3s\n",
      "90:\tlearn: 0.3198528\ttotal: 1.96s\tremaining: 27.2s\n",
      "91:\tlearn: 0.3189624\ttotal: 1.98s\tremaining: 27.2s\n",
      "92:\tlearn: 0.3181425\ttotal: 2s\tremaining: 27.2s\n",
      "93:\tlearn: 0.3170706\ttotal: 2.03s\tremaining: 27.2s\n",
      "94:\tlearn: 0.3161841\ttotal: 2.05s\tremaining: 27.2s\n",
      "95:\tlearn: 0.3152720\ttotal: 2.07s\tremaining: 27.1s\n",
      "96:\tlearn: 0.3144285\ttotal: 2.09s\tremaining: 27s\n",
      "97:\tlearn: 0.3138123\ttotal: 2.1s\tremaining: 27s\n",
      "98:\tlearn: 0.3128158\ttotal: 2.12s\tremaining: 26.9s\n",
      "99:\tlearn: 0.3121638\ttotal: 2.14s\tremaining: 26.8s\n",
      "100:\tlearn: 0.3115522\ttotal: 2.16s\tremaining: 26.8s\n",
      "101:\tlearn: 0.3104818\ttotal: 2.17s\tremaining: 26.7s\n",
      "102:\tlearn: 0.3097163\ttotal: 2.19s\tremaining: 26.6s\n",
      "103:\tlearn: 0.3092702\ttotal: 2.21s\tremaining: 26.5s\n",
      "104:\tlearn: 0.3086188\ttotal: 2.23s\tremaining: 26.5s\n",
      "105:\tlearn: 0.3081482\ttotal: 2.24s\tremaining: 26.4s\n",
      "106:\tlearn: 0.3072099\ttotal: 2.26s\tremaining: 26.3s\n",
      "107:\tlearn: 0.3066862\ttotal: 2.28s\tremaining: 26.3s\n",
      "108:\tlearn: 0.3061298\ttotal: 2.29s\tremaining: 26.2s\n",
      "109:\tlearn: 0.3056353\ttotal: 2.31s\tremaining: 26.1s\n",
      "110:\tlearn: 0.3051080\ttotal: 2.33s\tremaining: 26.1s\n",
      "111:\tlearn: 0.3044918\ttotal: 2.34s\tremaining: 26s\n",
      "112:\tlearn: 0.3037851\ttotal: 2.36s\tremaining: 25.9s\n",
      "113:\tlearn: 0.3030210\ttotal: 2.38s\tremaining: 25.9s\n",
      "114:\tlearn: 0.3024410\ttotal: 2.39s\tremaining: 25.8s\n",
      "115:\tlearn: 0.3018413\ttotal: 2.41s\tremaining: 25.8s\n",
      "116:\tlearn: 0.3012189\ttotal: 2.43s\tremaining: 25.7s\n",
      "117:\tlearn: 0.3006603\ttotal: 2.45s\tremaining: 25.7s\n",
      "118:\tlearn: 0.3000862\ttotal: 2.47s\tremaining: 25.7s\n",
      "119:\tlearn: 0.2994780\ttotal: 2.49s\tremaining: 25.6s\n",
      "120:\tlearn: 0.2991440\ttotal: 2.51s\tremaining: 25.6s\n",
      "121:\tlearn: 0.2986693\ttotal: 2.53s\tremaining: 25.5s\n",
      "122:\tlearn: 0.2979966\ttotal: 2.54s\tremaining: 25.5s\n",
      "123:\tlearn: 0.2973717\ttotal: 2.56s\tremaining: 25.4s\n",
      "124:\tlearn: 0.2968614\ttotal: 2.58s\tremaining: 25.4s\n",
      "125:\tlearn: 0.2963273\ttotal: 2.6s\tremaining: 25.3s\n",
      "126:\tlearn: 0.2956678\ttotal: 2.62s\tremaining: 25.3s\n",
      "127:\tlearn: 0.2952603\ttotal: 2.64s\tremaining: 25.2s\n",
      "128:\tlearn: 0.2947676\ttotal: 2.65s\tremaining: 25.2s\n",
      "129:\tlearn: 0.2942784\ttotal: 2.68s\tremaining: 25.2s\n",
      "130:\tlearn: 0.2940664\ttotal: 2.69s\tremaining: 25.1s\n",
      "131:\tlearn: 0.2937627\ttotal: 2.71s\tremaining: 25.1s\n",
      "132:\tlearn: 0.2933526\ttotal: 2.73s\tremaining: 25s\n",
      "133:\tlearn: 0.2926738\ttotal: 2.74s\tremaining: 25s\n",
      "134:\tlearn: 0.2922040\ttotal: 2.76s\tremaining: 25s\n",
      "135:\tlearn: 0.2919270\ttotal: 2.78s\tremaining: 24.9s\n",
      "136:\tlearn: 0.2914331\ttotal: 2.8s\tremaining: 24.9s\n",
      "137:\tlearn: 0.2908495\ttotal: 2.82s\tremaining: 24.8s\n",
      "138:\tlearn: 0.2903447\ttotal: 2.84s\tremaining: 24.8s\n",
      "139:\tlearn: 0.2899040\ttotal: 2.86s\tremaining: 24.8s\n",
      "140:\tlearn: 0.2893942\ttotal: 2.89s\tremaining: 24.9s\n",
      "141:\tlearn: 0.2890290\ttotal: 2.92s\tremaining: 24.9s\n",
      "142:\tlearn: 0.2885860\ttotal: 2.94s\tremaining: 24.9s\n",
      "143:\tlearn: 0.2882178\ttotal: 2.96s\tremaining: 24.9s\n",
      "144:\tlearn: 0.2875184\ttotal: 2.99s\tremaining: 24.9s\n",
      "145:\tlearn: 0.2867732\ttotal: 3.01s\tremaining: 24.9s\n",
      "146:\tlearn: 0.2860735\ttotal: 3.02s\tremaining: 24.8s\n",
      "147:\tlearn: 0.2856419\ttotal: 3.04s\tremaining: 24.8s\n",
      "148:\tlearn: 0.2850004\ttotal: 3.06s\tremaining: 24.8s\n",
      "149:\tlearn: 0.2847357\ttotal: 3.08s\tremaining: 24.7s\n",
      "150:\tlearn: 0.2842855\ttotal: 3.1s\tremaining: 24.7s\n",
      "151:\tlearn: 0.2835717\ttotal: 3.12s\tremaining: 24.7s\n",
      "152:\tlearn: 0.2833074\ttotal: 3.14s\tremaining: 24.6s\n",
      "153:\tlearn: 0.2829680\ttotal: 3.16s\tremaining: 24.6s\n",
      "154:\tlearn: 0.2825965\ttotal: 3.17s\tremaining: 24.6s\n",
      "155:\tlearn: 0.2822811\ttotal: 3.19s\tremaining: 24.5s\n",
      "156:\tlearn: 0.2818285\ttotal: 3.21s\tremaining: 24.5s\n",
      "157:\tlearn: 0.2815584\ttotal: 3.23s\tremaining: 24.4s\n",
      "158:\tlearn: 0.2812478\ttotal: 3.24s\tremaining: 24.4s\n",
      "159:\tlearn: 0.2810803\ttotal: 3.25s\tremaining: 24.3s\n",
      "160:\tlearn: 0.2806017\ttotal: 3.27s\tremaining: 24.2s\n",
      "161:\tlearn: 0.2801471\ttotal: 3.29s\tremaining: 24.2s\n",
      "162:\tlearn: 0.2798700\ttotal: 3.31s\tremaining: 24.2s\n",
      "163:\tlearn: 0.2794759\ttotal: 3.33s\tremaining: 24.1s\n",
      "164:\tlearn: 0.2790879\ttotal: 3.35s\tremaining: 24.1s\n",
      "165:\tlearn: 0.2785891\ttotal: 3.37s\tremaining: 24.1s\n",
      "166:\tlearn: 0.2782517\ttotal: 3.39s\tremaining: 24.1s\n",
      "167:\tlearn: 0.2779214\ttotal: 3.42s\tremaining: 24.2s\n",
      "168:\tlearn: 0.2774035\ttotal: 3.46s\tremaining: 24.3s\n",
      "169:\tlearn: 0.2769761\ttotal: 3.5s\tremaining: 24.4s\n",
      "170:\tlearn: 0.2766975\ttotal: 3.53s\tremaining: 24.4s\n",
      "171:\tlearn: 0.2762462\ttotal: 3.55s\tremaining: 24.4s\n",
      "172:\tlearn: 0.2758349\ttotal: 3.57s\tremaining: 24.4s\n",
      "173:\tlearn: 0.2751829\ttotal: 3.59s\tremaining: 24.3s\n",
      "174:\tlearn: 0.2749177\ttotal: 3.61s\tremaining: 24.3s\n",
      "175:\tlearn: 0.2745200\ttotal: 3.63s\tremaining: 24.3s\n",
      "176:\tlearn: 0.2742131\ttotal: 3.66s\tremaining: 24.3s\n",
      "177:\tlearn: 0.2740004\ttotal: 3.68s\tremaining: 24.3s\n",
      "178:\tlearn: 0.2736755\ttotal: 3.7s\tremaining: 24.3s\n",
      "179:\tlearn: 0.2732856\ttotal: 3.72s\tremaining: 24.2s\n",
      "180:\tlearn: 0.2727594\ttotal: 3.74s\tremaining: 24.2s\n",
      "181:\tlearn: 0.2722971\ttotal: 3.75s\tremaining: 24.2s\n",
      "182:\tlearn: 0.2720620\ttotal: 3.77s\tremaining: 24.2s\n",
      "183:\tlearn: 0.2718069\ttotal: 3.79s\tremaining: 24.1s\n",
      "184:\tlearn: 0.2715055\ttotal: 3.81s\tremaining: 24.1s\n",
      "185:\tlearn: 0.2712453\ttotal: 3.83s\tremaining: 24s\n",
      "186:\tlearn: 0.2710047\ttotal: 3.84s\tremaining: 24s\n",
      "187:\tlearn: 0.2706461\ttotal: 3.86s\tremaining: 24s\n",
      "188:\tlearn: 0.2701731\ttotal: 3.88s\tremaining: 23.9s\n",
      "189:\tlearn: 0.2697878\ttotal: 3.9s\tremaining: 23.9s\n",
      "190:\tlearn: 0.2694775\ttotal: 3.91s\tremaining: 23.8s\n",
      "191:\tlearn: 0.2691447\ttotal: 3.93s\tremaining: 23.8s\n",
      "192:\tlearn: 0.2688803\ttotal: 3.95s\tremaining: 23.7s\n",
      "193:\tlearn: 0.2686704\ttotal: 3.96s\tremaining: 23.7s\n",
      "194:\tlearn: 0.2683089\ttotal: 3.98s\tremaining: 23.7s\n",
      "195:\tlearn: 0.2679841\ttotal: 4s\tremaining: 23.7s\n",
      "196:\tlearn: 0.2676545\ttotal: 4.02s\tremaining: 23.6s\n",
      "197:\tlearn: 0.2673421\ttotal: 4.04s\tremaining: 23.6s\n",
      "198:\tlearn: 0.2671074\ttotal: 4.06s\tremaining: 23.6s\n",
      "199:\tlearn: 0.2668164\ttotal: 4.09s\tremaining: 23.6s\n",
      "200:\tlearn: 0.2665801\ttotal: 4.11s\tremaining: 23.6s\n",
      "201:\tlearn: 0.2662785\ttotal: 4.14s\tremaining: 23.6s\n",
      "202:\tlearn: 0.2659151\ttotal: 4.16s\tremaining: 23.6s\n",
      "203:\tlearn: 0.2656873\ttotal: 4.18s\tremaining: 23.5s\n",
      "204:\tlearn: 0.2654273\ttotal: 4.2s\tremaining: 23.5s\n",
      "205:\tlearn: 0.2651725\ttotal: 4.22s\tremaining: 23.5s\n",
      "206:\tlearn: 0.2648855\ttotal: 4.25s\tremaining: 23.5s\n",
      "207:\tlearn: 0.2646626\ttotal: 4.27s\tremaining: 23.5s\n",
      "208:\tlearn: 0.2644712\ttotal: 4.29s\tremaining: 23.5s\n",
      "209:\tlearn: 0.2641183\ttotal: 4.3s\tremaining: 23.4s\n",
      "210:\tlearn: 0.2639410\ttotal: 4.33s\tremaining: 23.4s\n",
      "211:\tlearn: 0.2635405\ttotal: 4.34s\tremaining: 23.4s\n",
      "212:\tlearn: 0.2632801\ttotal: 4.37s\tremaining: 23.4s\n",
      "213:\tlearn: 0.2629892\ttotal: 4.38s\tremaining: 23.4s\n",
      "214:\tlearn: 0.2626711\ttotal: 4.42s\tremaining: 23.4s\n",
      "215:\tlearn: 0.2624216\ttotal: 4.45s\tremaining: 23.5s\n",
      "216:\tlearn: 0.2621617\ttotal: 4.49s\tremaining: 23.5s\n",
      "217:\tlearn: 0.2619258\ttotal: 4.51s\tremaining: 23.5s\n",
      "218:\tlearn: 0.2616638\ttotal: 4.52s\tremaining: 23.4s\n",
      "219:\tlearn: 0.2612658\ttotal: 4.54s\tremaining: 23.4s\n",
      "220:\tlearn: 0.2609630\ttotal: 4.56s\tremaining: 23.4s\n",
      "221:\tlearn: 0.2607581\ttotal: 4.58s\tremaining: 23.4s\n",
      "222:\tlearn: 0.2604742\ttotal: 4.6s\tremaining: 23.3s\n",
      "223:\tlearn: 0.2601002\ttotal: 4.63s\tremaining: 23.3s\n",
      "224:\tlearn: 0.2599616\ttotal: 4.64s\tremaining: 23.3s\n",
      "225:\tlearn: 0.2596256\ttotal: 4.67s\tremaining: 23.3s\n",
      "226:\tlearn: 0.2592927\ttotal: 4.68s\tremaining: 23.3s\n",
      "227:\tlearn: 0.2591592\ttotal: 4.7s\tremaining: 23.2s\n",
      "228:\tlearn: 0.2589955\ttotal: 4.72s\tremaining: 23.2s\n",
      "229:\tlearn: 0.2587848\ttotal: 4.74s\tremaining: 23.2s\n",
      "230:\tlearn: 0.2585535\ttotal: 4.75s\tremaining: 23.1s\n",
      "231:\tlearn: 0.2581366\ttotal: 4.78s\tremaining: 23.1s\n",
      "232:\tlearn: 0.2579494\ttotal: 4.79s\tremaining: 23.1s\n",
      "233:\tlearn: 0.2575819\ttotal: 4.82s\tremaining: 23.1s\n",
      "234:\tlearn: 0.2572582\ttotal: 4.84s\tremaining: 23s\n",
      "235:\tlearn: 0.2569448\ttotal: 4.86s\tremaining: 23s\n",
      "236:\tlearn: 0.2566743\ttotal: 4.89s\tremaining: 23.1s\n",
      "237:\tlearn: 0.2564682\ttotal: 4.93s\tremaining: 23.1s\n",
      "238:\tlearn: 0.2561996\ttotal: 4.96s\tremaining: 23.1s\n",
      "239:\tlearn: 0.2559252\ttotal: 4.98s\tremaining: 23.1s\n",
      "240:\tlearn: 0.2557034\ttotal: 5s\tremaining: 23.1s\n",
      "241:\tlearn: 0.2554376\ttotal: 5.03s\tremaining: 23.1s\n",
      "242:\tlearn: 0.2552226\ttotal: 5.06s\tremaining: 23.1s\n",
      "243:\tlearn: 0.2550078\ttotal: 5.08s\tremaining: 23.1s\n",
      "244:\tlearn: 0.2547609\ttotal: 5.12s\tremaining: 23.2s\n",
      "245:\tlearn: 0.2545460\ttotal: 5.14s\tremaining: 23.2s\n",
      "246:\tlearn: 0.2541930\ttotal: 5.17s\tremaining: 23.2s\n",
      "247:\tlearn: 0.2539532\ttotal: 5.2s\tremaining: 23.2s\n",
      "248:\tlearn: 0.2538189\ttotal: 5.22s\tremaining: 23.2s\n",
      "249:\tlearn: 0.2536138\ttotal: 5.25s\tremaining: 23.2s\n",
      "250:\tlearn: 0.2534524\ttotal: 5.29s\tremaining: 23.2s\n",
      "251:\tlearn: 0.2532702\ttotal: 5.31s\tremaining: 23.2s\n",
      "252:\tlearn: 0.2529865\ttotal: 5.34s\tremaining: 23.2s\n",
      "253:\tlearn: 0.2527007\ttotal: 5.36s\tremaining: 23.2s\n",
      "254:\tlearn: 0.2524684\ttotal: 5.39s\tremaining: 23.2s\n",
      "255:\tlearn: 0.2523168\ttotal: 5.41s\tremaining: 23.2s\n",
      "256:\tlearn: 0.2521481\ttotal: 5.44s\tremaining: 23.2s\n",
      "257:\tlearn: 0.2517598\ttotal: 5.46s\tremaining: 23.2s\n",
      "258:\tlearn: 0.2516092\ttotal: 5.48s\tremaining: 23.2s\n",
      "259:\tlearn: 0.2514089\ttotal: 5.51s\tremaining: 23.2s\n",
      "260:\tlearn: 0.2512610\ttotal: 5.53s\tremaining: 23.2s\n",
      "261:\tlearn: 0.2510353\ttotal: 5.56s\tremaining: 23.2s\n",
      "262:\tlearn: 0.2507562\ttotal: 5.58s\tremaining: 23.2s\n",
      "263:\tlearn: 0.2505046\ttotal: 5.61s\tremaining: 23.2s\n",
      "264:\tlearn: 0.2503856\ttotal: 5.63s\tremaining: 23.1s\n",
      "265:\tlearn: 0.2502190\ttotal: 5.65s\tremaining: 23.1s\n",
      "266:\tlearn: 0.2501159\ttotal: 5.67s\tremaining: 23.1s\n",
      "267:\tlearn: 0.2499632\ttotal: 5.7s\tremaining: 23.1s\n",
      "268:\tlearn: 0.2497253\ttotal: 5.71s\tremaining: 23.1s\n",
      "269:\tlearn: 0.2493895\ttotal: 5.74s\tremaining: 23s\n",
      "270:\tlearn: 0.2491577\ttotal: 5.75s\tremaining: 23s\n",
      "271:\tlearn: 0.2489697\ttotal: 5.78s\tremaining: 23s\n",
      "272:\tlearn: 0.2484901\ttotal: 5.8s\tremaining: 23s\n",
      "273:\tlearn: 0.2482509\ttotal: 5.82s\tremaining: 22.9s\n",
      "274:\tlearn: 0.2480674\ttotal: 5.85s\tremaining: 22.9s\n",
      "275:\tlearn: 0.2478718\ttotal: 5.88s\tremaining: 22.9s\n",
      "276:\tlearn: 0.2476895\ttotal: 5.9s\tremaining: 23s\n",
      "277:\tlearn: 0.2473782\ttotal: 5.93s\tremaining: 22.9s\n",
      "278:\tlearn: 0.2469663\ttotal: 5.95s\tremaining: 22.9s\n",
      "279:\tlearn: 0.2465146\ttotal: 5.98s\tremaining: 22.9s\n",
      "280:\tlearn: 0.2461753\ttotal: 6s\tremaining: 22.9s\n",
      "281:\tlearn: 0.2460537\ttotal: 6.02s\tremaining: 22.9s\n",
      "282:\tlearn: 0.2458286\ttotal: 6.04s\tremaining: 22.9s\n",
      "283:\tlearn: 0.2455031\ttotal: 6.06s\tremaining: 22.8s\n",
      "284:\tlearn: 0.2453501\ttotal: 6.08s\tremaining: 22.8s\n",
      "285:\tlearn: 0.2450324\ttotal: 6.11s\tremaining: 22.8s\n",
      "286:\tlearn: 0.2447826\ttotal: 6.14s\tremaining: 22.8s\n",
      "287:\tlearn: 0.2445244\ttotal: 6.16s\tremaining: 22.8s\n",
      "288:\tlearn: 0.2442946\ttotal: 6.19s\tremaining: 22.8s\n",
      "289:\tlearn: 0.2439990\ttotal: 6.21s\tremaining: 22.8s\n",
      "290:\tlearn: 0.2437464\ttotal: 6.24s\tremaining: 22.8s\n",
      "291:\tlearn: 0.2435069\ttotal: 6.27s\tremaining: 22.8s\n",
      "292:\tlearn: 0.2432725\ttotal: 6.31s\tremaining: 22.9s\n",
      "293:\tlearn: 0.2431077\ttotal: 6.36s\tremaining: 22.9s\n",
      "294:\tlearn: 0.2429403\ttotal: 6.39s\tremaining: 22.9s\n",
      "295:\tlearn: 0.2427892\ttotal: 6.43s\tremaining: 23s\n",
      "296:\tlearn: 0.2424761\ttotal: 6.46s\tremaining: 23s\n",
      "297:\tlearn: 0.2423242\ttotal: 6.48s\tremaining: 23s\n",
      "298:\tlearn: 0.2420924\ttotal: 6.51s\tremaining: 23s\n",
      "299:\tlearn: 0.2419688\ttotal: 6.54s\tremaining: 23s\n",
      "300:\tlearn: 0.2417532\ttotal: 6.57s\tremaining: 23s\n",
      "301:\tlearn: 0.2414859\ttotal: 6.6s\tremaining: 23s\n",
      "302:\tlearn: 0.2413345\ttotal: 6.62s\tremaining: 23s\n",
      "303:\tlearn: 0.2411453\ttotal: 6.71s\tremaining: 23.2s\n",
      "304:\tlearn: 0.2408591\ttotal: 6.77s\tremaining: 23.3s\n",
      "305:\tlearn: 0.2406833\ttotal: 6.81s\tremaining: 23.3s\n",
      "306:\tlearn: 0.2404441\ttotal: 6.88s\tremaining: 23.5s\n",
      "307:\tlearn: 0.2401641\ttotal: 6.92s\tremaining: 23.5s\n",
      "308:\tlearn: 0.2398710\ttotal: 6.96s\tremaining: 23.5s\n",
      "309:\tlearn: 0.2397297\ttotal: 6.98s\tremaining: 23.5s\n",
      "310:\tlearn: 0.2395471\ttotal: 7.02s\tremaining: 23.5s\n",
      "311:\tlearn: 0.2393035\ttotal: 7.04s\tremaining: 23.5s\n",
      "312:\tlearn: 0.2391310\ttotal: 7.07s\tremaining: 23.5s\n",
      "313:\tlearn: 0.2388757\ttotal: 7.09s\tremaining: 23.5s\n",
      "314:\tlearn: 0.2387744\ttotal: 7.11s\tremaining: 23.5s\n",
      "315:\tlearn: 0.2384156\ttotal: 7.13s\tremaining: 23.4s\n",
      "316:\tlearn: 0.2382216\ttotal: 7.16s\tremaining: 23.4s\n",
      "317:\tlearn: 0.2379707\ttotal: 7.18s\tremaining: 23.4s\n",
      "318:\tlearn: 0.2377456\ttotal: 7.2s\tremaining: 23.4s\n",
      "319:\tlearn: 0.2374671\ttotal: 7.22s\tremaining: 23.3s\n",
      "320:\tlearn: 0.2373486\ttotal: 7.24s\tremaining: 23.3s\n",
      "321:\tlearn: 0.2370966\ttotal: 7.26s\tremaining: 23.3s\n",
      "322:\tlearn: 0.2369687\ttotal: 7.28s\tremaining: 23.2s\n",
      "323:\tlearn: 0.2368282\ttotal: 7.3s\tremaining: 23.2s\n",
      "324:\tlearn: 0.2366691\ttotal: 7.32s\tremaining: 23.2s\n",
      "325:\tlearn: 0.2365194\ttotal: 7.34s\tremaining: 23.2s\n",
      "326:\tlearn: 0.2363627\ttotal: 7.37s\tremaining: 23.1s\n",
      "327:\tlearn: 0.2361846\ttotal: 7.39s\tremaining: 23.1s\n",
      "328:\tlearn: 0.2358749\ttotal: 7.41s\tremaining: 23.1s\n",
      "329:\tlearn: 0.2357483\ttotal: 7.43s\tremaining: 23s\n",
      "330:\tlearn: 0.2355801\ttotal: 7.45s\tremaining: 23s\n",
      "331:\tlearn: 0.2354443\ttotal: 7.46s\tremaining: 23s\n",
      "332:\tlearn: 0.2351950\ttotal: 7.48s\tremaining: 22.9s\n",
      "333:\tlearn: 0.2349372\ttotal: 7.51s\tremaining: 22.9s\n",
      "334:\tlearn: 0.2347740\ttotal: 7.54s\tremaining: 22.9s\n",
      "335:\tlearn: 0.2346549\ttotal: 7.57s\tremaining: 22.9s\n",
      "336:\tlearn: 0.2345070\ttotal: 7.59s\tremaining: 22.9s\n",
      "337:\tlearn: 0.2342719\ttotal: 7.61s\tremaining: 22.9s\n",
      "338:\tlearn: 0.2341499\ttotal: 7.63s\tremaining: 22.8s\n",
      "339:\tlearn: 0.2339345\ttotal: 7.65s\tremaining: 22.8s\n",
      "340:\tlearn: 0.2337474\ttotal: 7.67s\tremaining: 22.8s\n",
      "341:\tlearn: 0.2334714\ttotal: 7.69s\tremaining: 22.8s\n",
      "342:\tlearn: 0.2333813\ttotal: 7.71s\tremaining: 22.7s\n",
      "343:\tlearn: 0.2333010\ttotal: 7.73s\tremaining: 22.7s\n",
      "344:\tlearn: 0.2329518\ttotal: 7.75s\tremaining: 22.7s\n",
      "345:\tlearn: 0.2327761\ttotal: 7.77s\tremaining: 22.6s\n",
      "346:\tlearn: 0.2326623\ttotal: 7.79s\tremaining: 22.6s\n",
      "347:\tlearn: 0.2324870\ttotal: 7.81s\tremaining: 22.6s\n",
      "348:\tlearn: 0.2323943\ttotal: 7.83s\tremaining: 22.6s\n",
      "349:\tlearn: 0.2322532\ttotal: 7.86s\tremaining: 22.5s\n",
      "350:\tlearn: 0.2321145\ttotal: 7.88s\tremaining: 22.5s\n",
      "351:\tlearn: 0.2319648\ttotal: 7.91s\tremaining: 22.5s\n",
      "352:\tlearn: 0.2318618\ttotal: 7.93s\tremaining: 22.5s\n",
      "353:\tlearn: 0.2316710\ttotal: 7.95s\tremaining: 22.5s\n",
      "354:\tlearn: 0.2315623\ttotal: 7.97s\tremaining: 22.4s\n",
      "355:\tlearn: 0.2314310\ttotal: 8s\tremaining: 22.4s\n",
      "356:\tlearn: 0.2311383\ttotal: 8.02s\tremaining: 22.4s\n",
      "357:\tlearn: 0.2309207\ttotal: 8.04s\tremaining: 22.4s\n",
      "358:\tlearn: 0.2307238\ttotal: 8.06s\tremaining: 22.3s\n",
      "359:\tlearn: 0.2303902\ttotal: 8.08s\tremaining: 22.3s\n",
      "360:\tlearn: 0.2301554\ttotal: 8.1s\tremaining: 22.3s\n",
      "361:\tlearn: 0.2299730\ttotal: 8.12s\tremaining: 22.2s\n",
      "362:\tlearn: 0.2297945\ttotal: 8.13s\tremaining: 22.2s\n",
      "363:\tlearn: 0.2296556\ttotal: 8.15s\tremaining: 22.2s\n",
      "364:\tlearn: 0.2294552\ttotal: 8.17s\tremaining: 22.1s\n",
      "365:\tlearn: 0.2292999\ttotal: 8.19s\tremaining: 22.1s\n",
      "366:\tlearn: 0.2290869\ttotal: 8.21s\tremaining: 22.1s\n",
      "367:\tlearn: 0.2289373\ttotal: 8.22s\tremaining: 22s\n",
      "368:\tlearn: 0.2287271\ttotal: 8.24s\tremaining: 22s\n",
      "369:\tlearn: 0.2285664\ttotal: 8.26s\tremaining: 22s\n",
      "370:\tlearn: 0.2284936\ttotal: 8.28s\tremaining: 21.9s\n",
      "371:\tlearn: 0.2284395\ttotal: 8.3s\tremaining: 21.9s\n",
      "372:\tlearn: 0.2282712\ttotal: 8.32s\tremaining: 21.9s\n",
      "373:\tlearn: 0.2281558\ttotal: 8.34s\tremaining: 21.8s\n",
      "374:\tlearn: 0.2278682\ttotal: 8.36s\tremaining: 21.8s\n",
      "375:\tlearn: 0.2277062\ttotal: 8.38s\tremaining: 21.8s\n",
      "376:\tlearn: 0.2276125\ttotal: 8.39s\tremaining: 21.8s\n",
      "377:\tlearn: 0.2274648\ttotal: 8.41s\tremaining: 21.7s\n",
      "378:\tlearn: 0.2272284\ttotal: 8.43s\tremaining: 21.7s\n",
      "379:\tlearn: 0.2270941\ttotal: 8.45s\tremaining: 21.7s\n",
      "380:\tlearn: 0.2269383\ttotal: 8.47s\tremaining: 21.6s\n",
      "381:\tlearn: 0.2267721\ttotal: 8.49s\tremaining: 21.6s\n",
      "382:\tlearn: 0.2266055\ttotal: 8.51s\tremaining: 21.6s\n",
      "383:\tlearn: 0.2263744\ttotal: 8.53s\tremaining: 21.6s\n",
      "384:\tlearn: 0.2263133\ttotal: 8.55s\tremaining: 21.5s\n",
      "385:\tlearn: 0.2262070\ttotal: 8.57s\tremaining: 21.5s\n",
      "386:\tlearn: 0.2260277\ttotal: 8.59s\tremaining: 21.5s\n",
      "387:\tlearn: 0.2258869\ttotal: 8.61s\tremaining: 21.4s\n",
      "388:\tlearn: 0.2257140\ttotal: 8.63s\tremaining: 21.4s\n",
      "389:\tlearn: 0.2256090\ttotal: 8.65s\tremaining: 21.4s\n",
      "390:\tlearn: 0.2253786\ttotal: 8.67s\tremaining: 21.4s\n",
      "391:\tlearn: 0.2252894\ttotal: 8.69s\tremaining: 21.3s\n",
      "392:\tlearn: 0.2250576\ttotal: 8.72s\tremaining: 21.3s\n",
      "393:\tlearn: 0.2247614\ttotal: 8.75s\tremaining: 21.3s\n",
      "394:\tlearn: 0.2246568\ttotal: 8.78s\tremaining: 21.3s\n",
      "395:\tlearn: 0.2245210\ttotal: 8.8s\tremaining: 21.3s\n",
      "396:\tlearn: 0.2242963\ttotal: 8.82s\tremaining: 21.3s\n",
      "397:\tlearn: 0.2240675\ttotal: 8.84s\tremaining: 21.2s\n",
      "398:\tlearn: 0.2238465\ttotal: 8.87s\tremaining: 21.2s\n",
      "399:\tlearn: 0.2237024\ttotal: 8.89s\tremaining: 21.2s\n",
      "400:\tlearn: 0.2235383\ttotal: 8.92s\tremaining: 21.2s\n",
      "401:\tlearn: 0.2233066\ttotal: 8.94s\tremaining: 21.2s\n",
      "402:\tlearn: 0.2231430\ttotal: 8.96s\tremaining: 21.1s\n",
      "403:\tlearn: 0.2229575\ttotal: 8.98s\tremaining: 21.1s\n",
      "404:\tlearn: 0.2227735\ttotal: 9s\tremaining: 21.1s\n",
      "405:\tlearn: 0.2224961\ttotal: 9.02s\tremaining: 21.1s\n",
      "406:\tlearn: 0.2223394\ttotal: 9.04s\tremaining: 21s\n",
      "407:\tlearn: 0.2222193\ttotal: 9.06s\tremaining: 21s\n",
      "408:\tlearn: 0.2221655\ttotal: 9.07s\tremaining: 21s\n",
      "409:\tlearn: 0.2220033\ttotal: 9.09s\tremaining: 20.9s\n",
      "410:\tlearn: 0.2218284\ttotal: 9.11s\tremaining: 20.9s\n",
      "411:\tlearn: 0.2217216\ttotal: 9.12s\tremaining: 20.9s\n",
      "412:\tlearn: 0.2216112\ttotal: 9.14s\tremaining: 20.8s\n",
      "413:\tlearn: 0.2214049\ttotal: 9.16s\tremaining: 20.8s\n",
      "414:\tlearn: 0.2212397\ttotal: 9.18s\tremaining: 20.8s\n",
      "415:\tlearn: 0.2211525\ttotal: 9.2s\tremaining: 20.7s\n",
      "416:\tlearn: 0.2209884\ttotal: 9.22s\tremaining: 20.7s\n",
      "417:\tlearn: 0.2208847\ttotal: 9.23s\tremaining: 20.7s\n",
      "418:\tlearn: 0.2207322\ttotal: 9.25s\tremaining: 20.6s\n",
      "419:\tlearn: 0.2205557\ttotal: 9.27s\tremaining: 20.6s\n",
      "420:\tlearn: 0.2203918\ttotal: 9.29s\tremaining: 20.6s\n",
      "421:\tlearn: 0.2201403\ttotal: 9.31s\tremaining: 20.6s\n",
      "422:\tlearn: 0.2200184\ttotal: 9.33s\tremaining: 20.5s\n",
      "423:\tlearn: 0.2199187\ttotal: 9.35s\tremaining: 20.5s\n",
      "424:\tlearn: 0.2196579\ttotal: 9.37s\tremaining: 20.5s\n",
      "425:\tlearn: 0.2194848\ttotal: 9.49s\tremaining: 20.7s\n",
      "426:\tlearn: 0.2192810\ttotal: 9.52s\tremaining: 20.7s\n",
      "427:\tlearn: 0.2191166\ttotal: 9.56s\tremaining: 20.7s\n",
      "428:\tlearn: 0.2189864\ttotal: 9.58s\tremaining: 20.7s\n",
      "429:\tlearn: 0.2187415\ttotal: 9.6s\tremaining: 20.6s\n",
      "430:\tlearn: 0.2185543\ttotal: 9.62s\tremaining: 20.6s\n",
      "431:\tlearn: 0.2184653\ttotal: 9.64s\tremaining: 20.6s\n",
      "432:\tlearn: 0.2183456\ttotal: 9.66s\tremaining: 20.5s\n",
      "433:\tlearn: 0.2181690\ttotal: 9.68s\tremaining: 20.5s\n",
      "434:\tlearn: 0.2179845\ttotal: 9.7s\tremaining: 20.5s\n",
      "435:\tlearn: 0.2178408\ttotal: 9.72s\tremaining: 20.5s\n",
      "436:\tlearn: 0.2176947\ttotal: 9.74s\tremaining: 20.4s\n",
      "437:\tlearn: 0.2175286\ttotal: 9.77s\tremaining: 20.4s\n",
      "438:\tlearn: 0.2174292\ttotal: 9.79s\tremaining: 20.4s\n",
      "439:\tlearn: 0.2172266\ttotal: 9.81s\tremaining: 20.4s\n",
      "440:\tlearn: 0.2170111\ttotal: 9.83s\tremaining: 20.4s\n",
      "441:\tlearn: 0.2169566\ttotal: 9.85s\tremaining: 20.3s\n",
      "442:\tlearn: 0.2168306\ttotal: 9.87s\tremaining: 20.3s\n",
      "443:\tlearn: 0.2166642\ttotal: 9.89s\tremaining: 20.3s\n",
      "444:\tlearn: 0.2165089\ttotal: 9.91s\tremaining: 20.2s\n",
      "445:\tlearn: 0.2163772\ttotal: 9.93s\tremaining: 20.2s\n",
      "446:\tlearn: 0.2162256\ttotal: 9.95s\tremaining: 20.2s\n",
      "447:\tlearn: 0.2160467\ttotal: 9.97s\tremaining: 20.2s\n",
      "448:\tlearn: 0.2159052\ttotal: 9.99s\tremaining: 20.1s\n",
      "449:\tlearn: 0.2156385\ttotal: 10s\tremaining: 20.1s\n",
      "450:\tlearn: 0.2154796\ttotal: 10s\tremaining: 20.1s\n",
      "451:\tlearn: 0.2153243\ttotal: 10s\tremaining: 20.1s\n",
      "452:\tlearn: 0.2151815\ttotal: 10.1s\tremaining: 20s\n",
      "453:\tlearn: 0.2149950\ttotal: 10.1s\tremaining: 20s\n",
      "454:\tlearn: 0.2148312\ttotal: 10.1s\tremaining: 20s\n",
      "455:\tlearn: 0.2147050\ttotal: 10.1s\tremaining: 19.9s\n",
      "456:\tlearn: 0.2146060\ttotal: 10.1s\tremaining: 19.9s\n",
      "457:\tlearn: 0.2144173\ttotal: 10.2s\tremaining: 19.9s\n",
      "458:\tlearn: 0.2142642\ttotal: 10.2s\tremaining: 19.8s\n",
      "459:\tlearn: 0.2141608\ttotal: 10.2s\tremaining: 19.8s\n",
      "460:\tlearn: 0.2140001\ttotal: 10.2s\tremaining: 19.8s\n",
      "461:\tlearn: 0.2138924\ttotal: 10.2s\tremaining: 19.8s\n",
      "462:\tlearn: 0.2137611\ttotal: 10.3s\tremaining: 19.7s\n",
      "463:\tlearn: 0.2136031\ttotal: 10.3s\tremaining: 19.7s\n",
      "464:\tlearn: 0.2134228\ttotal: 10.3s\tremaining: 19.7s\n",
      "465:\tlearn: 0.2133139\ttotal: 10.3s\tremaining: 19.6s\n",
      "466:\tlearn: 0.2131658\ttotal: 10.3s\tremaining: 19.6s\n",
      "467:\tlearn: 0.2129826\ttotal: 10.3s\tremaining: 19.6s\n",
      "468:\tlearn: 0.2128789\ttotal: 10.4s\tremaining: 19.6s\n",
      "469:\tlearn: 0.2127467\ttotal: 10.4s\tremaining: 19.5s\n",
      "470:\tlearn: 0.2126254\ttotal: 10.4s\tremaining: 19.5s\n",
      "471:\tlearn: 0.2124731\ttotal: 10.4s\tremaining: 19.5s\n",
      "472:\tlearn: 0.2122746\ttotal: 10.4s\tremaining: 19.5s\n",
      "473:\tlearn: 0.2121870\ttotal: 10.5s\tremaining: 19.4s\n",
      "474:\tlearn: 0.2120498\ttotal: 10.5s\tremaining: 19.4s\n",
      "475:\tlearn: 0.2119243\ttotal: 10.5s\tremaining: 19.4s\n",
      "476:\tlearn: 0.2116936\ttotal: 10.5s\tremaining: 19.3s\n",
      "477:\tlearn: 0.2115387\ttotal: 10.5s\tremaining: 19.3s\n",
      "478:\tlearn: 0.2113483\ttotal: 10.5s\tremaining: 19.3s\n",
      "479:\tlearn: 0.2111201\ttotal: 10.6s\tremaining: 19.2s\n",
      "480:\tlearn: 0.2110550\ttotal: 10.6s\tremaining: 19.2s\n",
      "481:\tlearn: 0.2108447\ttotal: 10.6s\tremaining: 19.2s\n",
      "482:\tlearn: 0.2107222\ttotal: 10.6s\tremaining: 19.2s\n",
      "483:\tlearn: 0.2106053\ttotal: 10.6s\tremaining: 19.1s\n",
      "484:\tlearn: 0.2105034\ttotal: 10.7s\tremaining: 19.1s\n",
      "485:\tlearn: 0.2103781\ttotal: 10.7s\tremaining: 19.1s\n",
      "486:\tlearn: 0.2102687\ttotal: 10.7s\tremaining: 19.1s\n",
      "487:\tlearn: 0.2100702\ttotal: 10.7s\tremaining: 19s\n",
      "488:\tlearn: 0.2098717\ttotal: 10.7s\tremaining: 19s\n",
      "489:\tlearn: 0.2098085\ttotal: 10.8s\tremaining: 19s\n",
      "490:\tlearn: 0.2096763\ttotal: 10.8s\tremaining: 18.9s\n",
      "491:\tlearn: 0.2094160\ttotal: 10.8s\tremaining: 18.9s\n",
      "492:\tlearn: 0.2092582\ttotal: 10.8s\tremaining: 18.9s\n",
      "493:\tlearn: 0.2091430\ttotal: 10.8s\tremaining: 18.9s\n",
      "494:\tlearn: 0.2089069\ttotal: 10.9s\tremaining: 18.8s\n",
      "495:\tlearn: 0.2087286\ttotal: 10.9s\tremaining: 18.8s\n",
      "496:\tlearn: 0.2086344\ttotal: 10.9s\tremaining: 18.8s\n",
      "497:\tlearn: 0.2084954\ttotal: 10.9s\tremaining: 18.8s\n",
      "498:\tlearn: 0.2083939\ttotal: 10.9s\tremaining: 18.7s\n",
      "499:\tlearn: 0.2082561\ttotal: 11s\tremaining: 18.7s\n",
      "500:\tlearn: 0.2081344\ttotal: 11s\tremaining: 18.7s\n",
      "501:\tlearn: 0.2079680\ttotal: 11s\tremaining: 18.7s\n",
      "502:\tlearn: 0.2077856\ttotal: 11s\tremaining: 18.7s\n",
      "503:\tlearn: 0.2076416\ttotal: 11s\tremaining: 18.6s\n",
      "504:\tlearn: 0.2075034\ttotal: 11.1s\tremaining: 18.6s\n",
      "505:\tlearn: 0.2072681\ttotal: 11.1s\tremaining: 18.6s\n",
      "506:\tlearn: 0.2071389\ttotal: 11.1s\tremaining: 18.6s\n",
      "507:\tlearn: 0.2070197\ttotal: 11.1s\tremaining: 18.6s\n",
      "508:\tlearn: 0.2069159\ttotal: 11.2s\tremaining: 18.5s\n",
      "509:\tlearn: 0.2068145\ttotal: 11.2s\tremaining: 18.5s\n",
      "510:\tlearn: 0.2067123\ttotal: 11.2s\tremaining: 18.5s\n",
      "511:\tlearn: 0.2064806\ttotal: 11.2s\tremaining: 18.5s\n",
      "512:\tlearn: 0.2063922\ttotal: 11.2s\tremaining: 18.4s\n",
      "513:\tlearn: 0.2063282\ttotal: 11.3s\tremaining: 18.4s\n",
      "514:\tlearn: 0.2062171\ttotal: 11.3s\tremaining: 18.4s\n",
      "515:\tlearn: 0.2061032\ttotal: 11.3s\tremaining: 18.3s\n",
      "516:\tlearn: 0.2059533\ttotal: 11.3s\tremaining: 18.3s\n",
      "517:\tlearn: 0.2057349\ttotal: 11.3s\tremaining: 18.3s\n",
      "518:\tlearn: 0.2056420\ttotal: 11.3s\tremaining: 18.3s\n",
      "519:\tlearn: 0.2054331\ttotal: 11.4s\tremaining: 18.2s\n",
      "520:\tlearn: 0.2051587\ttotal: 11.4s\tremaining: 18.2s\n",
      "521:\tlearn: 0.2050105\ttotal: 11.4s\tremaining: 18.2s\n",
      "522:\tlearn: 0.2049066\ttotal: 11.4s\tremaining: 18.2s\n",
      "523:\tlearn: 0.2048111\ttotal: 11.4s\tremaining: 18.1s\n",
      "524:\tlearn: 0.2047119\ttotal: 11.5s\tremaining: 18.1s\n",
      "525:\tlearn: 0.2046143\ttotal: 11.5s\tremaining: 18.1s\n",
      "526:\tlearn: 0.2044537\ttotal: 11.5s\tremaining: 18.1s\n",
      "527:\tlearn: 0.2043892\ttotal: 11.5s\tremaining: 18s\n",
      "528:\tlearn: 0.2042899\ttotal: 11.5s\tremaining: 18s\n",
      "529:\tlearn: 0.2041972\ttotal: 11.6s\tremaining: 18s\n",
      "530:\tlearn: 0.2041059\ttotal: 11.6s\tremaining: 18s\n",
      "531:\tlearn: 0.2040502\ttotal: 11.6s\tremaining: 17.9s\n",
      "532:\tlearn: 0.2038881\ttotal: 11.6s\tremaining: 17.9s\n",
      "533:\tlearn: 0.2037642\ttotal: 11.6s\tremaining: 17.9s\n",
      "534:\tlearn: 0.2036757\ttotal: 11.7s\tremaining: 17.8s\n",
      "535:\tlearn: 0.2034992\ttotal: 11.7s\tremaining: 17.8s\n",
      "536:\tlearn: 0.2033197\ttotal: 11.7s\tremaining: 17.8s\n",
      "537:\tlearn: 0.2031807\ttotal: 11.7s\tremaining: 17.8s\n",
      "538:\tlearn: 0.2029371\ttotal: 11.7s\tremaining: 17.7s\n",
      "539:\tlearn: 0.2028312\ttotal: 11.7s\tremaining: 17.7s\n",
      "540:\tlearn: 0.2027176\ttotal: 11.8s\tremaining: 17.7s\n",
      "541:\tlearn: 0.2025547\ttotal: 11.8s\tremaining: 17.7s\n",
      "542:\tlearn: 0.2024356\ttotal: 11.8s\tremaining: 17.6s\n",
      "543:\tlearn: 0.2023590\ttotal: 11.8s\tremaining: 17.6s\n",
      "544:\tlearn: 0.2022577\ttotal: 11.8s\tremaining: 17.6s\n",
      "545:\tlearn: 0.2020410\ttotal: 11.9s\tremaining: 17.6s\n",
      "546:\tlearn: 0.2019060\ttotal: 11.9s\tremaining: 17.5s\n",
      "547:\tlearn: 0.2017220\ttotal: 11.9s\tremaining: 17.5s\n",
      "548:\tlearn: 0.2016696\ttotal: 11.9s\tremaining: 17.5s\n",
      "549:\tlearn: 0.2015591\ttotal: 11.9s\tremaining: 17.5s\n",
      "550:\tlearn: 0.2014886\ttotal: 12s\tremaining: 17.4s\n",
      "551:\tlearn: 0.2013866\ttotal: 12s\tremaining: 17.4s\n",
      "552:\tlearn: 0.2012542\ttotal: 12s\tremaining: 17.4s\n",
      "553:\tlearn: 0.2011607\ttotal: 12s\tremaining: 17.4s\n",
      "554:\tlearn: 0.2010910\ttotal: 12s\tremaining: 17.3s\n",
      "555:\tlearn: 0.2009618\ttotal: 12.1s\tremaining: 17.3s\n",
      "556:\tlearn: 0.2008691\ttotal: 12.1s\tremaining: 17.3s\n",
      "557:\tlearn: 0.2007424\ttotal: 12.1s\tremaining: 17.3s\n",
      "558:\tlearn: 0.2006247\ttotal: 12.1s\tremaining: 17.2s\n",
      "559:\tlearn: 0.2004925\ttotal: 12.1s\tremaining: 17.2s\n",
      "560:\tlearn: 0.2004035\ttotal: 12.2s\tremaining: 17.2s\n",
      "561:\tlearn: 0.2002558\ttotal: 12.2s\tremaining: 17.2s\n",
      "562:\tlearn: 0.2001366\ttotal: 12.2s\tremaining: 17.1s\n",
      "563:\tlearn: 0.2000316\ttotal: 12.2s\tremaining: 17.1s\n",
      "564:\tlearn: 0.1998999\ttotal: 12.2s\tremaining: 17.1s\n",
      "565:\tlearn: 0.1997891\ttotal: 12.3s\tremaining: 17.1s\n",
      "566:\tlearn: 0.1997251\ttotal: 12.3s\tremaining: 17s\n",
      "567:\tlearn: 0.1996273\ttotal: 12.3s\tremaining: 17s\n",
      "568:\tlearn: 0.1995129\ttotal: 12.3s\tremaining: 17s\n",
      "569:\tlearn: 0.1993307\ttotal: 12.3s\tremaining: 17s\n",
      "570:\tlearn: 0.1992202\ttotal: 12.3s\tremaining: 16.9s\n",
      "571:\tlearn: 0.1990793\ttotal: 12.4s\tremaining: 16.9s\n",
      "572:\tlearn: 0.1989599\ttotal: 12.4s\tremaining: 16.9s\n",
      "573:\tlearn: 0.1988035\ttotal: 12.4s\tremaining: 16.8s\n",
      "574:\tlearn: 0.1987683\ttotal: 12.4s\tremaining: 16.8s\n",
      "575:\tlearn: 0.1986277\ttotal: 12.4s\tremaining: 16.8s\n",
      "576:\tlearn: 0.1984986\ttotal: 12.5s\tremaining: 16.8s\n",
      "577:\tlearn: 0.1983835\ttotal: 12.5s\tremaining: 16.7s\n",
      "578:\tlearn: 0.1982812\ttotal: 12.5s\tremaining: 16.7s\n",
      "579:\tlearn: 0.1980892\ttotal: 12.5s\tremaining: 16.7s\n",
      "580:\tlearn: 0.1979796\ttotal: 12.5s\tremaining: 16.7s\n",
      "581:\tlearn: 0.1978067\ttotal: 12.5s\tremaining: 16.6s\n",
      "582:\tlearn: 0.1976835\ttotal: 12.6s\tremaining: 16.6s\n",
      "583:\tlearn: 0.1975870\ttotal: 12.6s\tremaining: 16.6s\n",
      "584:\tlearn: 0.1972998\ttotal: 12.6s\tremaining: 16.6s\n",
      "585:\tlearn: 0.1971479\ttotal: 12.6s\tremaining: 16.5s\n",
      "586:\tlearn: 0.1970544\ttotal: 12.6s\tremaining: 16.5s\n",
      "587:\tlearn: 0.1969379\ttotal: 12.7s\tremaining: 16.5s\n",
      "588:\tlearn: 0.1968321\ttotal: 12.7s\tremaining: 16.5s\n",
      "589:\tlearn: 0.1967214\ttotal: 12.7s\tremaining: 16.4s\n",
      "590:\tlearn: 0.1965794\ttotal: 12.7s\tremaining: 16.4s\n",
      "591:\tlearn: 0.1965077\ttotal: 12.7s\tremaining: 16.4s\n",
      "592:\tlearn: 0.1963979\ttotal: 12.8s\tremaining: 16.4s\n",
      "593:\tlearn: 0.1962389\ttotal: 12.8s\tremaining: 16.4s\n",
      "594:\tlearn: 0.1961454\ttotal: 12.8s\tremaining: 16.3s\n",
      "595:\tlearn: 0.1959988\ttotal: 12.8s\tremaining: 16.3s\n",
      "596:\tlearn: 0.1959073\ttotal: 12.8s\tremaining: 16.3s\n",
      "597:\tlearn: 0.1957977\ttotal: 12.9s\tremaining: 16.3s\n",
      "598:\tlearn: 0.1956310\ttotal: 12.9s\tremaining: 16.2s\n",
      "599:\tlearn: 0.1955507\ttotal: 12.9s\tremaining: 16.2s\n",
      "600:\tlearn: 0.1954922\ttotal: 12.9s\tremaining: 16.2s\n",
      "601:\tlearn: 0.1953105\ttotal: 12.9s\tremaining: 16.2s\n",
      "602:\tlearn: 0.1951814\ttotal: 12.9s\tremaining: 16.1s\n",
      "603:\tlearn: 0.1950976\ttotal: 13s\tremaining: 16.1s\n",
      "604:\tlearn: 0.1949174\ttotal: 13s\tremaining: 16.1s\n",
      "605:\tlearn: 0.1948200\ttotal: 13s\tremaining: 16.1s\n",
      "606:\tlearn: 0.1946286\ttotal: 13s\tremaining: 16s\n",
      "607:\tlearn: 0.1945365\ttotal: 13s\tremaining: 16s\n",
      "608:\tlearn: 0.1944528\ttotal: 13.1s\tremaining: 16s\n",
      "609:\tlearn: 0.1943454\ttotal: 13.1s\tremaining: 16s\n",
      "610:\tlearn: 0.1942557\ttotal: 13.1s\tremaining: 15.9s\n",
      "611:\tlearn: 0.1941132\ttotal: 13.1s\tremaining: 15.9s\n",
      "612:\tlearn: 0.1940200\ttotal: 13.1s\tremaining: 15.9s\n",
      "613:\tlearn: 0.1939728\ttotal: 13.2s\tremaining: 15.9s\n",
      "614:\tlearn: 0.1938395\ttotal: 13.2s\tremaining: 15.8s\n",
      "615:\tlearn: 0.1937250\ttotal: 13.2s\tremaining: 15.8s\n",
      "616:\tlearn: 0.1935593\ttotal: 13.2s\tremaining: 15.8s\n",
      "617:\tlearn: 0.1935003\ttotal: 13.2s\tremaining: 15.8s\n",
      "618:\tlearn: 0.1934664\ttotal: 13.3s\tremaining: 15.8s\n",
      "619:\tlearn: 0.1933512\ttotal: 13.3s\tremaining: 15.7s\n",
      "620:\tlearn: 0.1932078\ttotal: 13.3s\tremaining: 15.7s\n",
      "621:\tlearn: 0.1929494\ttotal: 13.3s\tremaining: 15.7s\n",
      "622:\tlearn: 0.1928585\ttotal: 13.3s\tremaining: 15.7s\n",
      "623:\tlearn: 0.1927410\ttotal: 13.4s\tremaining: 15.6s\n",
      "624:\tlearn: 0.1926579\ttotal: 13.4s\tremaining: 15.6s\n",
      "625:\tlearn: 0.1925464\ttotal: 13.4s\tremaining: 15.6s\n",
      "626:\tlearn: 0.1923776\ttotal: 13.4s\tremaining: 15.6s\n",
      "627:\tlearn: 0.1922409\ttotal: 13.5s\tremaining: 15.6s\n",
      "628:\tlearn: 0.1921307\ttotal: 13.5s\tremaining: 15.5s\n",
      "629:\tlearn: 0.1920135\ttotal: 13.5s\tremaining: 15.5s\n",
      "630:\tlearn: 0.1919478\ttotal: 13.5s\tremaining: 15.5s\n",
      "631:\tlearn: 0.1917052\ttotal: 13.5s\tremaining: 15.5s\n",
      "632:\tlearn: 0.1916212\ttotal: 13.6s\tremaining: 15.4s\n",
      "633:\tlearn: 0.1914559\ttotal: 13.6s\tremaining: 15.4s\n",
      "634:\tlearn: 0.1913154\ttotal: 13.6s\tremaining: 15.4s\n",
      "635:\tlearn: 0.1912218\ttotal: 13.6s\tremaining: 15.4s\n",
      "636:\tlearn: 0.1911537\ttotal: 13.6s\tremaining: 15.3s\n",
      "637:\tlearn: 0.1910422\ttotal: 13.6s\tremaining: 15.3s\n",
      "638:\tlearn: 0.1910010\ttotal: 13.7s\tremaining: 15.3s\n",
      "639:\tlearn: 0.1909085\ttotal: 13.7s\tremaining: 15.3s\n",
      "640:\tlearn: 0.1908222\ttotal: 13.7s\tremaining: 15.2s\n",
      "641:\tlearn: 0.1906636\ttotal: 13.7s\tremaining: 15.2s\n",
      "642:\tlearn: 0.1905525\ttotal: 13.7s\tremaining: 15.2s\n",
      "643:\tlearn: 0.1904030\ttotal: 13.8s\tremaining: 15.2s\n",
      "644:\tlearn: 0.1902635\ttotal: 13.8s\tremaining: 15.1s\n",
      "645:\tlearn: 0.1902217\ttotal: 13.8s\tremaining: 15.1s\n",
      "646:\tlearn: 0.1901413\ttotal: 13.8s\tremaining: 15.1s\n",
      "647:\tlearn: 0.1900455\ttotal: 13.8s\tremaining: 15.1s\n",
      "648:\tlearn: 0.1899440\ttotal: 13.9s\tremaining: 15.1s\n",
      "649:\tlearn: 0.1898820\ttotal: 13.9s\tremaining: 15s\n",
      "650:\tlearn: 0.1897606\ttotal: 13.9s\tremaining: 15s\n",
      "651:\tlearn: 0.1895934\ttotal: 13.9s\tremaining: 15s\n",
      "652:\tlearn: 0.1894158\ttotal: 13.9s\tremaining: 15s\n",
      "653:\tlearn: 0.1892672\ttotal: 13.9s\tremaining: 14.9s\n",
      "654:\tlearn: 0.1891579\ttotal: 14s\tremaining: 14.9s\n",
      "655:\tlearn: 0.1889560\ttotal: 14s\tremaining: 14.9s\n",
      "656:\tlearn: 0.1888944\ttotal: 14s\tremaining: 14.9s\n",
      "657:\tlearn: 0.1888041\ttotal: 14s\tremaining: 14.8s\n",
      "658:\tlearn: 0.1886162\ttotal: 14s\tremaining: 14.8s\n",
      "659:\tlearn: 0.1885074\ttotal: 14.1s\tremaining: 14.8s\n",
      "660:\tlearn: 0.1884295\ttotal: 14.1s\tremaining: 14.8s\n",
      "661:\tlearn: 0.1883135\ttotal: 14.1s\tremaining: 14.7s\n",
      "662:\tlearn: 0.1881784\ttotal: 14.1s\tremaining: 14.7s\n",
      "663:\tlearn: 0.1880284\ttotal: 14.1s\tremaining: 14.7s\n",
      "664:\tlearn: 0.1878115\ttotal: 14.2s\tremaining: 14.7s\n",
      "665:\tlearn: 0.1877529\ttotal: 14.2s\tremaining: 14.6s\n",
      "666:\tlearn: 0.1876279\ttotal: 14.2s\tremaining: 14.6s\n",
      "667:\tlearn: 0.1874880\ttotal: 14.2s\tremaining: 14.6s\n",
      "668:\tlearn: 0.1873934\ttotal: 14.2s\tremaining: 14.6s\n",
      "669:\tlearn: 0.1872030\ttotal: 14.3s\tremaining: 14.6s\n",
      "670:\tlearn: 0.1871097\ttotal: 14.3s\tremaining: 14.5s\n",
      "671:\tlearn: 0.1869989\ttotal: 14.3s\tremaining: 14.5s\n",
      "672:\tlearn: 0.1869321\ttotal: 14.3s\tremaining: 14.5s\n",
      "673:\tlearn: 0.1868254\ttotal: 14.3s\tremaining: 14.5s\n",
      "674:\tlearn: 0.1866865\ttotal: 14.4s\tremaining: 14.4s\n",
      "675:\tlearn: 0.1865843\ttotal: 14.4s\tremaining: 14.4s\n",
      "676:\tlearn: 0.1865085\ttotal: 14.4s\tremaining: 14.4s\n",
      "677:\tlearn: 0.1864096\ttotal: 14.4s\tremaining: 14.4s\n",
      "678:\tlearn: 0.1862458\ttotal: 14.4s\tremaining: 14.3s\n",
      "679:\tlearn: 0.1860777\ttotal: 14.4s\tremaining: 14.3s\n",
      "680:\tlearn: 0.1858965\ttotal: 14.5s\tremaining: 14.3s\n",
      "681:\tlearn: 0.1856922\ttotal: 14.5s\tremaining: 14.3s\n",
      "682:\tlearn: 0.1856113\ttotal: 14.5s\tremaining: 14.3s\n",
      "683:\tlearn: 0.1854794\ttotal: 14.5s\tremaining: 14.2s\n",
      "684:\tlearn: 0.1853603\ttotal: 14.5s\tremaining: 14.2s\n",
      "685:\tlearn: 0.1852949\ttotal: 14.6s\tremaining: 14.2s\n",
      "686:\tlearn: 0.1851622\ttotal: 14.6s\tremaining: 14.2s\n",
      "687:\tlearn: 0.1850107\ttotal: 14.6s\tremaining: 14.1s\n",
      "688:\tlearn: 0.1849273\ttotal: 14.6s\tremaining: 14.1s\n",
      "689:\tlearn: 0.1847993\ttotal: 14.6s\tremaining: 14.1s\n",
      "690:\tlearn: 0.1846860\ttotal: 14.7s\tremaining: 14.1s\n",
      "691:\tlearn: 0.1845871\ttotal: 14.7s\tremaining: 14s\n",
      "692:\tlearn: 0.1844964\ttotal: 14.7s\tremaining: 14s\n",
      "693:\tlearn: 0.1843432\ttotal: 14.7s\tremaining: 14s\n",
      "694:\tlearn: 0.1842810\ttotal: 14.7s\tremaining: 14s\n",
      "695:\tlearn: 0.1841780\ttotal: 14.8s\tremaining: 13.9s\n",
      "696:\tlearn: 0.1840413\ttotal: 14.8s\tremaining: 13.9s\n",
      "697:\tlearn: 0.1839556\ttotal: 14.8s\tremaining: 13.9s\n",
      "698:\tlearn: 0.1837885\ttotal: 14.8s\tremaining: 13.9s\n",
      "699:\tlearn: 0.1836817\ttotal: 14.8s\tremaining: 13.8s\n",
      "700:\tlearn: 0.1835959\ttotal: 14.8s\tremaining: 13.8s\n",
      "701:\tlearn: 0.1834399\ttotal: 14.9s\tremaining: 13.8s\n",
      "702:\tlearn: 0.1833261\ttotal: 14.9s\tremaining: 13.8s\n",
      "703:\tlearn: 0.1830566\ttotal: 14.9s\tremaining: 13.8s\n",
      "704:\tlearn: 0.1829150\ttotal: 14.9s\tremaining: 13.7s\n",
      "705:\tlearn: 0.1828421\ttotal: 14.9s\tremaining: 13.7s\n",
      "706:\tlearn: 0.1826905\ttotal: 15s\tremaining: 13.7s\n",
      "707:\tlearn: 0.1826043\ttotal: 15s\tremaining: 13.7s\n",
      "708:\tlearn: 0.1825065\ttotal: 15s\tremaining: 13.6s\n",
      "709:\tlearn: 0.1824200\ttotal: 15s\tremaining: 13.6s\n",
      "710:\tlearn: 0.1822471\ttotal: 15s\tremaining: 13.6s\n",
      "711:\tlearn: 0.1820881\ttotal: 15.1s\tremaining: 13.6s\n",
      "712:\tlearn: 0.1819860\ttotal: 15.1s\tremaining: 13.5s\n",
      "713:\tlearn: 0.1819329\ttotal: 15.1s\tremaining: 13.5s\n",
      "714:\tlearn: 0.1817804\ttotal: 15.1s\tremaining: 13.5s\n",
      "715:\tlearn: 0.1817227\ttotal: 15.1s\tremaining: 13.5s\n",
      "716:\tlearn: 0.1816460\ttotal: 15.2s\tremaining: 13.5s\n",
      "717:\tlearn: 0.1815176\ttotal: 15.2s\tremaining: 13.4s\n",
      "718:\tlearn: 0.1813856\ttotal: 15.2s\tremaining: 13.4s\n",
      "719:\tlearn: 0.1813244\ttotal: 15.2s\tremaining: 13.4s\n",
      "720:\tlearn: 0.1812588\ttotal: 15.2s\tremaining: 13.4s\n",
      "721:\tlearn: 0.1811710\ttotal: 15.2s\tremaining: 13.3s\n",
      "722:\tlearn: 0.1810658\ttotal: 15.3s\tremaining: 13.3s\n",
      "723:\tlearn: 0.1810115\ttotal: 15.3s\tremaining: 13.3s\n",
      "724:\tlearn: 0.1809115\ttotal: 15.3s\tremaining: 13.3s\n",
      "725:\tlearn: 0.1808028\ttotal: 15.3s\tremaining: 13.2s\n",
      "726:\tlearn: 0.1807248\ttotal: 15.3s\tremaining: 13.2s\n",
      "727:\tlearn: 0.1806400\ttotal: 15.3s\tremaining: 13.2s\n",
      "728:\tlearn: 0.1805037\ttotal: 15.4s\tremaining: 13.2s\n",
      "729:\tlearn: 0.1804366\ttotal: 15.4s\tremaining: 13.2s\n",
      "730:\tlearn: 0.1803735\ttotal: 15.4s\tremaining: 13.1s\n",
      "731:\tlearn: 0.1802605\ttotal: 15.4s\tremaining: 13.1s\n",
      "732:\tlearn: 0.1802101\ttotal: 15.4s\tremaining: 13.1s\n",
      "733:\tlearn: 0.1800501\ttotal: 15.5s\tremaining: 13.1s\n",
      "734:\tlearn: 0.1799917\ttotal: 15.5s\tremaining: 13s\n",
      "735:\tlearn: 0.1799179\ttotal: 15.5s\tremaining: 13s\n",
      "736:\tlearn: 0.1798079\ttotal: 15.5s\tremaining: 13s\n",
      "737:\tlearn: 0.1796619\ttotal: 15.6s\tremaining: 13s\n",
      "738:\tlearn: 0.1795638\ttotal: 15.6s\tremaining: 13s\n",
      "739:\tlearn: 0.1794990\ttotal: 15.6s\tremaining: 12.9s\n",
      "740:\tlearn: 0.1794034\ttotal: 15.6s\tremaining: 12.9s\n",
      "741:\tlearn: 0.1793226\ttotal: 15.6s\tremaining: 12.9s\n",
      "742:\tlearn: 0.1792139\ttotal: 15.7s\tremaining: 12.9s\n",
      "743:\tlearn: 0.1791605\ttotal: 15.7s\tremaining: 12.9s\n",
      "744:\tlearn: 0.1789988\ttotal: 15.7s\tremaining: 12.8s\n",
      "745:\tlearn: 0.1789377\ttotal: 15.7s\tremaining: 12.8s\n",
      "746:\tlearn: 0.1788870\ttotal: 15.7s\tremaining: 12.8s\n",
      "747:\tlearn: 0.1787768\ttotal: 15.8s\tremaining: 12.8s\n",
      "748:\tlearn: 0.1787149\ttotal: 15.8s\tremaining: 12.7s\n",
      "749:\tlearn: 0.1786459\ttotal: 15.8s\tremaining: 12.7s\n",
      "750:\tlearn: 0.1785937\ttotal: 15.8s\tremaining: 12.7s\n",
      "751:\tlearn: 0.1785374\ttotal: 15.8s\tremaining: 12.7s\n",
      "752:\tlearn: 0.1784388\ttotal: 15.9s\tremaining: 12.7s\n",
      "753:\tlearn: 0.1783321\ttotal: 15.9s\tremaining: 12.6s\n",
      "754:\tlearn: 0.1781827\ttotal: 15.9s\tremaining: 12.6s\n",
      "755:\tlearn: 0.1781213\ttotal: 15.9s\tremaining: 12.6s\n",
      "756:\tlearn: 0.1780158\ttotal: 15.9s\tremaining: 12.6s\n",
      "757:\tlearn: 0.1779506\ttotal: 15.9s\tremaining: 12.5s\n",
      "758:\tlearn: 0.1778826\ttotal: 16s\tremaining: 12.5s\n",
      "759:\tlearn: 0.1777620\ttotal: 16s\tremaining: 12.5s\n",
      "760:\tlearn: 0.1776189\ttotal: 16s\tremaining: 12.5s\n",
      "761:\tlearn: 0.1774646\ttotal: 16s\tremaining: 12.4s\n",
      "762:\tlearn: 0.1773798\ttotal: 16s\tremaining: 12.4s\n",
      "763:\tlearn: 0.1772943\ttotal: 16.1s\tremaining: 12.4s\n",
      "764:\tlearn: 0.1772360\ttotal: 16.1s\tremaining: 12.4s\n",
      "765:\tlearn: 0.1771527\ttotal: 16.1s\tremaining: 12.4s\n",
      "766:\tlearn: 0.1770465\ttotal: 16.1s\tremaining: 12.3s\n",
      "767:\tlearn: 0.1769751\ttotal: 16.1s\tremaining: 12.3s\n",
      "768:\tlearn: 0.1768754\ttotal: 16.2s\tremaining: 12.3s\n",
      "769:\tlearn: 0.1767729\ttotal: 16.2s\tremaining: 12.3s\n",
      "770:\tlearn: 0.1766738\ttotal: 16.2s\tremaining: 12.2s\n",
      "771:\tlearn: 0.1766059\ttotal: 16.2s\tremaining: 12.2s\n",
      "772:\tlearn: 0.1765372\ttotal: 16.2s\tremaining: 12.2s\n",
      "773:\tlearn: 0.1764989\ttotal: 16.2s\tremaining: 12.2s\n",
      "774:\tlearn: 0.1764005\ttotal: 16.3s\tremaining: 12.1s\n",
      "775:\tlearn: 0.1763384\ttotal: 16.3s\tremaining: 12.1s\n",
      "776:\tlearn: 0.1762405\ttotal: 16.3s\tremaining: 12.1s\n",
      "777:\tlearn: 0.1761634\ttotal: 16.3s\tremaining: 12.1s\n",
      "778:\tlearn: 0.1760536\ttotal: 16.3s\tremaining: 12.1s\n",
      "779:\tlearn: 0.1759437\ttotal: 16.4s\tremaining: 12s\n",
      "780:\tlearn: 0.1758090\ttotal: 16.4s\tremaining: 12s\n",
      "781:\tlearn: 0.1757446\ttotal: 16.4s\tremaining: 12s\n",
      "782:\tlearn: 0.1756630\ttotal: 16.4s\tremaining: 12s\n",
      "783:\tlearn: 0.1755706\ttotal: 16.4s\tremaining: 11.9s\n",
      "784:\tlearn: 0.1754799\ttotal: 16.5s\tremaining: 11.9s\n",
      "785:\tlearn: 0.1754237\ttotal: 16.5s\tremaining: 11.9s\n",
      "786:\tlearn: 0.1753134\ttotal: 16.5s\tremaining: 11.9s\n",
      "787:\tlearn: 0.1752436\ttotal: 16.5s\tremaining: 11.9s\n",
      "788:\tlearn: 0.1751074\ttotal: 16.5s\tremaining: 11.8s\n",
      "789:\tlearn: 0.1750027\ttotal: 16.6s\tremaining: 11.8s\n",
      "790:\tlearn: 0.1749224\ttotal: 16.6s\tremaining: 11.8s\n",
      "791:\tlearn: 0.1748368\ttotal: 16.6s\tremaining: 11.8s\n",
      "792:\tlearn: 0.1747889\ttotal: 16.6s\tremaining: 11.8s\n",
      "793:\tlearn: 0.1746213\ttotal: 16.6s\tremaining: 11.7s\n",
      "794:\tlearn: 0.1744723\ttotal: 16.7s\tremaining: 11.7s\n",
      "795:\tlearn: 0.1743974\ttotal: 16.7s\tremaining: 11.7s\n",
      "796:\tlearn: 0.1742761\ttotal: 16.7s\tremaining: 11.7s\n",
      "797:\tlearn: 0.1742378\ttotal: 16.7s\tremaining: 11.6s\n",
      "798:\tlearn: 0.1741630\ttotal: 16.7s\tremaining: 11.6s\n",
      "799:\tlearn: 0.1740138\ttotal: 16.7s\tremaining: 11.6s\n",
      "800:\tlearn: 0.1739084\ttotal: 16.8s\tremaining: 11.6s\n",
      "801:\tlearn: 0.1738188\ttotal: 16.8s\tremaining: 11.6s\n",
      "802:\tlearn: 0.1737524\ttotal: 16.8s\tremaining: 11.5s\n",
      "803:\tlearn: 0.1736759\ttotal: 16.8s\tremaining: 11.5s\n",
      "804:\tlearn: 0.1736230\ttotal: 16.8s\tremaining: 11.5s\n",
      "805:\tlearn: 0.1735186\ttotal: 16.9s\tremaining: 11.5s\n",
      "806:\tlearn: 0.1734229\ttotal: 16.9s\tremaining: 11.4s\n",
      "807:\tlearn: 0.1732793\ttotal: 16.9s\tremaining: 11.4s\n",
      "808:\tlearn: 0.1731952\ttotal: 16.9s\tremaining: 11.4s\n",
      "809:\tlearn: 0.1731372\ttotal: 16.9s\tremaining: 11.4s\n",
      "810:\tlearn: 0.1730187\ttotal: 17s\tremaining: 11.3s\n",
      "811:\tlearn: 0.1729435\ttotal: 17s\tremaining: 11.3s\n",
      "812:\tlearn: 0.1728684\ttotal: 17s\tremaining: 11.3s\n",
      "813:\tlearn: 0.1727938\ttotal: 17s\tremaining: 11.3s\n",
      "814:\tlearn: 0.1727432\ttotal: 17s\tremaining: 11.3s\n",
      "815:\tlearn: 0.1726449\ttotal: 17s\tremaining: 11.2s\n",
      "816:\tlearn: 0.1725787\ttotal: 17.1s\tremaining: 11.2s\n",
      "817:\tlearn: 0.1724835\ttotal: 17.1s\tremaining: 11.2s\n",
      "818:\tlearn: 0.1724181\ttotal: 17.1s\tremaining: 11.2s\n",
      "819:\tlearn: 0.1723471\ttotal: 17.1s\tremaining: 11.1s\n",
      "820:\tlearn: 0.1722858\ttotal: 17.1s\tremaining: 11.1s\n",
      "821:\tlearn: 0.1721379\ttotal: 17.1s\tremaining: 11.1s\n",
      "822:\tlearn: 0.1721014\ttotal: 17.2s\tremaining: 11.1s\n",
      "823:\tlearn: 0.1720114\ttotal: 17.2s\tremaining: 11.1s\n",
      "824:\tlearn: 0.1719384\ttotal: 17.2s\tremaining: 11s\n",
      "825:\tlearn: 0.1718552\ttotal: 17.2s\tremaining: 11s\n",
      "826:\tlearn: 0.1717478\ttotal: 17.2s\tremaining: 11s\n",
      "827:\tlearn: 0.1716644\ttotal: 17.3s\tremaining: 11s\n",
      "828:\tlearn: 0.1715976\ttotal: 17.3s\tremaining: 10.9s\n",
      "829:\tlearn: 0.1714627\ttotal: 17.3s\tremaining: 10.9s\n",
      "830:\tlearn: 0.1713667\ttotal: 17.3s\tremaining: 10.9s\n",
      "831:\tlearn: 0.1712951\ttotal: 17.3s\tremaining: 10.9s\n",
      "832:\tlearn: 0.1712255\ttotal: 17.3s\tremaining: 10.8s\n",
      "833:\tlearn: 0.1711148\ttotal: 17.4s\tremaining: 10.8s\n",
      "834:\tlearn: 0.1710110\ttotal: 17.4s\tremaining: 10.8s\n",
      "835:\tlearn: 0.1709054\ttotal: 17.4s\tremaining: 10.8s\n",
      "836:\tlearn: 0.1708136\ttotal: 17.4s\tremaining: 10.8s\n",
      "837:\tlearn: 0.1707557\ttotal: 17.4s\tremaining: 10.7s\n",
      "838:\tlearn: 0.1706195\ttotal: 17.5s\tremaining: 10.7s\n",
      "839:\tlearn: 0.1705880\ttotal: 17.5s\tremaining: 10.7s\n",
      "840:\tlearn: 0.1705386\ttotal: 17.5s\tremaining: 10.7s\n",
      "841:\tlearn: 0.1704716\ttotal: 17.5s\tremaining: 10.6s\n",
      "842:\tlearn: 0.1703987\ttotal: 17.5s\tremaining: 10.6s\n",
      "843:\tlearn: 0.1702314\ttotal: 17.5s\tremaining: 10.6s\n",
      "844:\tlearn: 0.1701383\ttotal: 17.6s\tremaining: 10.6s\n",
      "845:\tlearn: 0.1700342\ttotal: 17.6s\tremaining: 10.6s\n",
      "846:\tlearn: 0.1699343\ttotal: 17.6s\tremaining: 10.5s\n",
      "847:\tlearn: 0.1698756\ttotal: 17.6s\tremaining: 10.5s\n",
      "848:\tlearn: 0.1697948\ttotal: 17.6s\tremaining: 10.5s\n",
      "849:\tlearn: 0.1697273\ttotal: 17.7s\tremaining: 10.5s\n",
      "850:\tlearn: 0.1696715\ttotal: 17.7s\tremaining: 10.4s\n",
      "851:\tlearn: 0.1696117\ttotal: 17.7s\tremaining: 10.4s\n",
      "852:\tlearn: 0.1695517\ttotal: 17.7s\tremaining: 10.4s\n",
      "853:\tlearn: 0.1694620\ttotal: 17.7s\tremaining: 10.4s\n",
      "854:\tlearn: 0.1693921\ttotal: 17.8s\tremaining: 10.4s\n",
      "855:\tlearn: 0.1693184\ttotal: 17.8s\tremaining: 10.4s\n",
      "856:\tlearn: 0.1692602\ttotal: 17.8s\tremaining: 10.3s\n",
      "857:\tlearn: 0.1691750\ttotal: 17.8s\tremaining: 10.3s\n",
      "858:\tlearn: 0.1690965\ttotal: 17.9s\tremaining: 10.3s\n",
      "859:\tlearn: 0.1690584\ttotal: 17.9s\tremaining: 10.3s\n",
      "860:\tlearn: 0.1689701\ttotal: 17.9s\tremaining: 10.3s\n",
      "861:\tlearn: 0.1688897\ttotal: 17.9s\tremaining: 10.2s\n",
      "862:\tlearn: 0.1687813\ttotal: 17.9s\tremaining: 10.2s\n",
      "863:\tlearn: 0.1686241\ttotal: 18s\tremaining: 10.2s\n",
      "864:\tlearn: 0.1685015\ttotal: 18s\tremaining: 10.2s\n",
      "865:\tlearn: 0.1684465\ttotal: 18s\tremaining: 10.1s\n",
      "866:\tlearn: 0.1683549\ttotal: 18s\tremaining: 10.1s\n",
      "867:\tlearn: 0.1682615\ttotal: 18s\tremaining: 10.1s\n",
      "868:\tlearn: 0.1681675\ttotal: 18.1s\tremaining: 10.1s\n",
      "869:\tlearn: 0.1680624\ttotal: 18.1s\tremaining: 10.1s\n",
      "870:\tlearn: 0.1679066\ttotal: 18.1s\tremaining: 10s\n",
      "871:\tlearn: 0.1678411\ttotal: 18.1s\tremaining: 10s\n",
      "872:\tlearn: 0.1677828\ttotal: 18.1s\tremaining: 9.99s\n",
      "873:\tlearn: 0.1676855\ttotal: 18.2s\tremaining: 9.97s\n",
      "874:\tlearn: 0.1675909\ttotal: 18.2s\tremaining: 9.95s\n",
      "875:\tlearn: 0.1674943\ttotal: 18.2s\tremaining: 9.93s\n",
      "876:\tlearn: 0.1674632\ttotal: 18.2s\tremaining: 9.91s\n",
      "877:\tlearn: 0.1673247\ttotal: 18.2s\tremaining: 9.88s\n",
      "878:\tlearn: 0.1672745\ttotal: 18.3s\tremaining: 9.86s\n",
      "879:\tlearn: 0.1671638\ttotal: 18.3s\tremaining: 9.84s\n",
      "880:\tlearn: 0.1670628\ttotal: 18.3s\tremaining: 9.82s\n",
      "881:\tlearn: 0.1669974\ttotal: 18.3s\tremaining: 9.79s\n",
      "882:\tlearn: 0.1668566\ttotal: 18.3s\tremaining: 9.77s\n",
      "883:\tlearn: 0.1668149\ttotal: 18.3s\tremaining: 9.75s\n",
      "884:\tlearn: 0.1666735\ttotal: 18.4s\tremaining: 9.73s\n",
      "885:\tlearn: 0.1666019\ttotal: 18.4s\tremaining: 9.71s\n",
      "886:\tlearn: 0.1664927\ttotal: 18.4s\tremaining: 9.69s\n",
      "887:\tlearn: 0.1663467\ttotal: 18.4s\tremaining: 9.66s\n",
      "888:\tlearn: 0.1662971\ttotal: 18.4s\tremaining: 9.64s\n",
      "889:\tlearn: 0.1662025\ttotal: 18.5s\tremaining: 9.62s\n",
      "890:\tlearn: 0.1660733\ttotal: 18.5s\tremaining: 9.6s\n",
      "891:\tlearn: 0.1659828\ttotal: 18.5s\tremaining: 9.58s\n",
      "892:\tlearn: 0.1658392\ttotal: 18.5s\tremaining: 9.55s\n",
      "893:\tlearn: 0.1657861\ttotal: 18.5s\tremaining: 9.53s\n",
      "894:\tlearn: 0.1657391\ttotal: 18.5s\tremaining: 9.51s\n",
      "895:\tlearn: 0.1655811\ttotal: 18.6s\tremaining: 9.49s\n",
      "896:\tlearn: 0.1655006\ttotal: 18.6s\tremaining: 9.47s\n",
      "897:\tlearn: 0.1654291\ttotal: 18.6s\tremaining: 9.45s\n",
      "898:\tlearn: 0.1652871\ttotal: 18.6s\tremaining: 9.42s\n",
      "899:\tlearn: 0.1651998\ttotal: 18.6s\tremaining: 9.4s\n",
      "900:\tlearn: 0.1651014\ttotal: 18.7s\tremaining: 9.38s\n",
      "901:\tlearn: 0.1649976\ttotal: 18.7s\tremaining: 9.36s\n",
      "902:\tlearn: 0.1649262\ttotal: 18.7s\tremaining: 9.34s\n",
      "903:\tlearn: 0.1648565\ttotal: 18.7s\tremaining: 9.32s\n",
      "904:\tlearn: 0.1647482\ttotal: 18.7s\tremaining: 9.3s\n",
      "905:\tlearn: 0.1645797\ttotal: 18.8s\tremaining: 9.28s\n",
      "906:\tlearn: 0.1645182\ttotal: 18.8s\tremaining: 9.26s\n",
      "907:\tlearn: 0.1644116\ttotal: 18.8s\tremaining: 9.24s\n",
      "908:\tlearn: 0.1643644\ttotal: 18.8s\tremaining: 9.22s\n",
      "909:\tlearn: 0.1643217\ttotal: 18.8s\tremaining: 9.2s\n",
      "910:\tlearn: 0.1641847\ttotal: 18.9s\tremaining: 9.18s\n",
      "911:\tlearn: 0.1641117\ttotal: 18.9s\tremaining: 9.15s\n",
      "912:\tlearn: 0.1639680\ttotal: 18.9s\tremaining: 9.13s\n",
      "913:\tlearn: 0.1638928\ttotal: 18.9s\tremaining: 9.11s\n",
      "914:\tlearn: 0.1637822\ttotal: 18.9s\tremaining: 9.09s\n",
      "915:\tlearn: 0.1637118\ttotal: 19s\tremaining: 9.07s\n",
      "916:\tlearn: 0.1636120\ttotal: 19s\tremaining: 9.05s\n",
      "917:\tlearn: 0.1635328\ttotal: 19s\tremaining: 9.03s\n",
      "918:\tlearn: 0.1634102\ttotal: 19s\tremaining: 9s\n",
      "919:\tlearn: 0.1632608\ttotal: 19s\tremaining: 8.98s\n",
      "920:\tlearn: 0.1632074\ttotal: 19.1s\tremaining: 8.96s\n",
      "921:\tlearn: 0.1631386\ttotal: 19.1s\tremaining: 8.94s\n",
      "922:\tlearn: 0.1630594\ttotal: 19.1s\tremaining: 8.92s\n",
      "923:\tlearn: 0.1629653\ttotal: 19.1s\tremaining: 8.89s\n",
      "924:\tlearn: 0.1628373\ttotal: 19.1s\tremaining: 8.87s\n",
      "925:\tlearn: 0.1627773\ttotal: 19.2s\tremaining: 8.85s\n",
      "926:\tlearn: 0.1626963\ttotal: 19.2s\tremaining: 8.83s\n",
      "927:\tlearn: 0.1626283\ttotal: 19.2s\tremaining: 8.81s\n",
      "928:\tlearn: 0.1624888\ttotal: 19.2s\tremaining: 8.79s\n",
      "929:\tlearn: 0.1624129\ttotal: 19.2s\tremaining: 8.77s\n",
      "930:\tlearn: 0.1623826\ttotal: 19.2s\tremaining: 8.75s\n",
      "931:\tlearn: 0.1623178\ttotal: 19.3s\tremaining: 8.72s\n",
      "932:\tlearn: 0.1622354\ttotal: 19.3s\tremaining: 8.7s\n",
      "933:\tlearn: 0.1621932\ttotal: 19.3s\tremaining: 8.68s\n",
      "934:\tlearn: 0.1621635\ttotal: 19.3s\tremaining: 8.66s\n",
      "935:\tlearn: 0.1620487\ttotal: 19.3s\tremaining: 8.64s\n",
      "936:\tlearn: 0.1619704\ttotal: 19.4s\tremaining: 8.61s\n",
      "937:\tlearn: 0.1618808\ttotal: 19.4s\tremaining: 8.59s\n",
      "938:\tlearn: 0.1617672\ttotal: 19.4s\tremaining: 8.57s\n",
      "939:\tlearn: 0.1617002\ttotal: 19.4s\tremaining: 8.55s\n",
      "940:\tlearn: 0.1616095\ttotal: 19.4s\tremaining: 8.53s\n",
      "941:\tlearn: 0.1615500\ttotal: 19.5s\tremaining: 8.51s\n",
      "942:\tlearn: 0.1614644\ttotal: 19.5s\tremaining: 8.49s\n",
      "943:\tlearn: 0.1613864\ttotal: 19.5s\tremaining: 8.47s\n",
      "944:\tlearn: 0.1613278\ttotal: 19.5s\tremaining: 8.45s\n",
      "945:\tlearn: 0.1612252\ttotal: 19.5s\tremaining: 8.42s\n",
      "946:\tlearn: 0.1611519\ttotal: 19.5s\tremaining: 8.4s\n",
      "947:\tlearn: 0.1610427\ttotal: 19.6s\tremaining: 8.38s\n",
      "948:\tlearn: 0.1609866\ttotal: 19.6s\tremaining: 8.36s\n",
      "949:\tlearn: 0.1609130\ttotal: 19.6s\tremaining: 8.34s\n",
      "950:\tlearn: 0.1608412\ttotal: 19.6s\tremaining: 8.32s\n",
      "951:\tlearn: 0.1607437\ttotal: 19.6s\tremaining: 8.29s\n",
      "952:\tlearn: 0.1606183\ttotal: 19.7s\tremaining: 8.27s\n",
      "953:\tlearn: 0.1605547\ttotal: 19.7s\tremaining: 8.25s\n",
      "954:\tlearn: 0.1605226\ttotal: 19.7s\tremaining: 8.23s\n",
      "955:\tlearn: 0.1603917\ttotal: 19.7s\tremaining: 8.21s\n",
      "956:\tlearn: 0.1603133\ttotal: 19.7s\tremaining: 8.19s\n",
      "957:\tlearn: 0.1601992\ttotal: 19.8s\tremaining: 8.17s\n",
      "958:\tlearn: 0.1600744\ttotal: 19.8s\tremaining: 8.15s\n",
      "959:\tlearn: 0.1600210\ttotal: 19.8s\tremaining: 8.13s\n",
      "960:\tlearn: 0.1599493\ttotal: 19.8s\tremaining: 8.11s\n",
      "961:\tlearn: 0.1598491\ttotal: 19.8s\tremaining: 8.08s\n",
      "962:\tlearn: 0.1597762\ttotal: 19.9s\tremaining: 8.06s\n",
      "963:\tlearn: 0.1597296\ttotal: 19.9s\tremaining: 8.04s\n",
      "964:\tlearn: 0.1596252\ttotal: 19.9s\tremaining: 8.02s\n",
      "965:\tlearn: 0.1595234\ttotal: 19.9s\tremaining: 8s\n",
      "966:\tlearn: 0.1594945\ttotal: 19.9s\tremaining: 7.98s\n",
      "967:\tlearn: 0.1594070\ttotal: 20s\tremaining: 7.96s\n",
      "968:\tlearn: 0.1593001\ttotal: 20s\tremaining: 7.94s\n",
      "969:\tlearn: 0.1592069\ttotal: 20s\tremaining: 7.92s\n",
      "970:\tlearn: 0.1591799\ttotal: 20s\tremaining: 7.9s\n",
      "971:\tlearn: 0.1591029\ttotal: 20.1s\tremaining: 7.88s\n",
      "972:\tlearn: 0.1590338\ttotal: 20.1s\tremaining: 7.86s\n",
      "973:\tlearn: 0.1589085\ttotal: 20.1s\tremaining: 7.84s\n",
      "974:\tlearn: 0.1588369\ttotal: 20.1s\tremaining: 7.82s\n",
      "975:\tlearn: 0.1587677\ttotal: 20.1s\tremaining: 7.8s\n",
      "976:\tlearn: 0.1587229\ttotal: 20.2s\tremaining: 7.78s\n",
      "977:\tlearn: 0.1586805\ttotal: 20.2s\tremaining: 7.76s\n",
      "978:\tlearn: 0.1585772\ttotal: 20.2s\tremaining: 7.74s\n",
      "979:\tlearn: 0.1585142\ttotal: 20.2s\tremaining: 7.72s\n",
      "980:\tlearn: 0.1584095\ttotal: 20.2s\tremaining: 7.7s\n",
      "981:\tlearn: 0.1583328\ttotal: 20.3s\tremaining: 7.68s\n",
      "982:\tlearn: 0.1582394\ttotal: 20.3s\tremaining: 7.65s\n",
      "983:\tlearn: 0.1581426\ttotal: 20.3s\tremaining: 7.63s\n",
      "984:\tlearn: 0.1580637\ttotal: 20.3s\tremaining: 7.61s\n",
      "985:\tlearn: 0.1580272\ttotal: 20.3s\tremaining: 7.59s\n",
      "986:\tlearn: 0.1579582\ttotal: 20.4s\tremaining: 7.57s\n",
      "987:\tlearn: 0.1578638\ttotal: 20.4s\tremaining: 7.55s\n",
      "988:\tlearn: 0.1577634\ttotal: 20.4s\tremaining: 7.53s\n",
      "989:\tlearn: 0.1576775\ttotal: 20.4s\tremaining: 7.51s\n",
      "990:\tlearn: 0.1576003\ttotal: 20.4s\tremaining: 7.48s\n",
      "991:\tlearn: 0.1575551\ttotal: 20.5s\tremaining: 7.46s\n",
      "992:\tlearn: 0.1575047\ttotal: 20.5s\tremaining: 7.44s\n",
      "993:\tlearn: 0.1574505\ttotal: 20.5s\tremaining: 7.42s\n",
      "994:\tlearn: 0.1574091\ttotal: 20.5s\tremaining: 7.4s\n",
      "995:\tlearn: 0.1572929\ttotal: 20.5s\tremaining: 7.38s\n",
      "996:\tlearn: 0.1572256\ttotal: 20.5s\tremaining: 7.35s\n",
      "997:\tlearn: 0.1572087\ttotal: 20.6s\tremaining: 7.33s\n",
      "998:\tlearn: 0.1571344\ttotal: 20.6s\tremaining: 7.31s\n",
      "999:\tlearn: 0.1569924\ttotal: 20.6s\tremaining: 7.29s\n",
      "1000:\tlearn: 0.1569141\ttotal: 20.6s\tremaining: 7.27s\n",
      "1001:\tlearn: 0.1568843\ttotal: 20.6s\tremaining: 7.25s\n",
      "1002:\tlearn: 0.1568097\ttotal: 20.7s\tremaining: 7.23s\n",
      "1003:\tlearn: 0.1567742\ttotal: 20.7s\tremaining: 7.21s\n",
      "1004:\tlearn: 0.1566231\ttotal: 20.7s\tremaining: 7.19s\n",
      "1005:\tlearn: 0.1565200\ttotal: 20.7s\tremaining: 7.17s\n",
      "1006:\tlearn: 0.1564290\ttotal: 20.7s\tremaining: 7.15s\n",
      "1007:\tlearn: 0.1563578\ttotal: 20.8s\tremaining: 7.13s\n",
      "1008:\tlearn: 0.1563244\ttotal: 20.8s\tremaining: 7.11s\n",
      "1009:\tlearn: 0.1562820\ttotal: 20.8s\tremaining: 7.09s\n",
      "1010:\tlearn: 0.1561921\ttotal: 20.8s\tremaining: 7.07s\n",
      "1011:\tlearn: 0.1561332\ttotal: 20.9s\tremaining: 7.05s\n",
      "1012:\tlearn: 0.1560264\ttotal: 20.9s\tremaining: 7.03s\n",
      "1013:\tlearn: 0.1558908\ttotal: 20.9s\tremaining: 7s\n",
      "1014:\tlearn: 0.1558000\ttotal: 20.9s\tremaining: 6.98s\n",
      "1015:\tlearn: 0.1557266\ttotal: 20.9s\tremaining: 6.96s\n",
      "1016:\tlearn: 0.1556897\ttotal: 20.9s\tremaining: 6.94s\n",
      "1017:\tlearn: 0.1556482\ttotal: 21s\tremaining: 6.92s\n",
      "1018:\tlearn: 0.1555969\ttotal: 21s\tremaining: 6.9s\n",
      "1019:\tlearn: 0.1554981\ttotal: 21s\tremaining: 6.88s\n",
      "1020:\tlearn: 0.1553931\ttotal: 21s\tremaining: 6.85s\n",
      "1021:\tlearn: 0.1553415\ttotal: 21s\tremaining: 6.83s\n",
      "1022:\tlearn: 0.1553020\ttotal: 21.1s\tremaining: 6.81s\n",
      "1023:\tlearn: 0.1552547\ttotal: 21.1s\tremaining: 6.79s\n",
      "1024:\tlearn: 0.1552016\ttotal: 21.1s\tremaining: 6.77s\n",
      "1025:\tlearn: 0.1551276\ttotal: 21.1s\tremaining: 6.75s\n",
      "1026:\tlearn: 0.1550758\ttotal: 21.1s\tremaining: 6.72s\n",
      "1027:\tlearn: 0.1550229\ttotal: 21.1s\tremaining: 6.7s\n",
      "1028:\tlearn: 0.1549763\ttotal: 21.2s\tremaining: 6.68s\n",
      "1029:\tlearn: 0.1549233\ttotal: 21.2s\tremaining: 6.66s\n",
      "1030:\tlearn: 0.1548105\ttotal: 21.2s\tremaining: 6.64s\n",
      "1031:\tlearn: 0.1547023\ttotal: 21.2s\tremaining: 6.62s\n",
      "1032:\tlearn: 0.1546757\ttotal: 21.2s\tremaining: 6.6s\n",
      "1033:\tlearn: 0.1546325\ttotal: 21.3s\tremaining: 6.58s\n",
      "1034:\tlearn: 0.1545652\ttotal: 21.3s\tremaining: 6.56s\n",
      "1035:\tlearn: 0.1544502\ttotal: 21.3s\tremaining: 6.54s\n",
      "1036:\tlearn: 0.1543529\ttotal: 21.3s\tremaining: 6.51s\n",
      "1037:\tlearn: 0.1543027\ttotal: 21.3s\tremaining: 6.49s\n",
      "1038:\tlearn: 0.1542296\ttotal: 21.3s\tremaining: 6.47s\n",
      "1039:\tlearn: 0.1541447\ttotal: 21.4s\tremaining: 6.45s\n",
      "1040:\tlearn: 0.1540992\ttotal: 21.4s\tremaining: 6.43s\n",
      "1041:\tlearn: 0.1539855\ttotal: 21.4s\tremaining: 6.41s\n",
      "1042:\tlearn: 0.1538586\ttotal: 21.4s\tremaining: 6.39s\n",
      "1043:\tlearn: 0.1538129\ttotal: 21.4s\tremaining: 6.37s\n",
      "1044:\tlearn: 0.1537327\ttotal: 21.5s\tremaining: 6.34s\n",
      "1045:\tlearn: 0.1536491\ttotal: 21.5s\tremaining: 6.32s\n",
      "1046:\tlearn: 0.1535607\ttotal: 21.5s\tremaining: 6.3s\n",
      "1047:\tlearn: 0.1535117\ttotal: 21.5s\tremaining: 6.28s\n",
      "1048:\tlearn: 0.1534614\ttotal: 21.5s\tremaining: 6.26s\n",
      "1049:\tlearn: 0.1533780\ttotal: 21.5s\tremaining: 6.24s\n",
      "1050:\tlearn: 0.1533120\ttotal: 21.6s\tremaining: 6.22s\n",
      "1051:\tlearn: 0.1532615\ttotal: 21.6s\tremaining: 6.2s\n",
      "1052:\tlearn: 0.1531807\ttotal: 21.6s\tremaining: 6.17s\n",
      "1053:\tlearn: 0.1531232\ttotal: 21.6s\tremaining: 6.15s\n",
      "1054:\tlearn: 0.1530188\ttotal: 21.6s\tremaining: 6.13s\n",
      "1055:\tlearn: 0.1529451\ttotal: 21.7s\tremaining: 6.11s\n",
      "1056:\tlearn: 0.1528840\ttotal: 21.7s\tremaining: 6.09s\n",
      "1057:\tlearn: 0.1527820\ttotal: 21.7s\tremaining: 6.07s\n",
      "1058:\tlearn: 0.1527196\ttotal: 21.7s\tremaining: 6.05s\n",
      "1059:\tlearn: 0.1526511\ttotal: 21.7s\tremaining: 6.03s\n",
      "1060:\tlearn: 0.1525438\ttotal: 21.7s\tremaining: 6s\n",
      "1061:\tlearn: 0.1524828\ttotal: 21.8s\tremaining: 5.98s\n",
      "1062:\tlearn: 0.1524171\ttotal: 21.8s\tremaining: 5.96s\n",
      "1063:\tlearn: 0.1523080\ttotal: 21.8s\tremaining: 5.94s\n",
      "1064:\tlearn: 0.1522690\ttotal: 21.8s\tremaining: 5.92s\n",
      "1065:\tlearn: 0.1521606\ttotal: 21.8s\tremaining: 5.9s\n",
      "1066:\tlearn: 0.1520897\ttotal: 21.9s\tremaining: 5.88s\n",
      "1067:\tlearn: 0.1520091\ttotal: 21.9s\tremaining: 5.86s\n",
      "1068:\tlearn: 0.1519560\ttotal: 21.9s\tremaining: 5.84s\n",
      "1069:\tlearn: 0.1518776\ttotal: 21.9s\tremaining: 5.82s\n",
      "1070:\tlearn: 0.1518369\ttotal: 21.9s\tremaining: 5.8s\n",
      "1071:\tlearn: 0.1517504\ttotal: 22s\tremaining: 5.78s\n",
      "1072:\tlearn: 0.1516823\ttotal: 22s\tremaining: 5.76s\n",
      "1073:\tlearn: 0.1516364\ttotal: 22s\tremaining: 5.74s\n",
      "1074:\tlearn: 0.1515467\ttotal: 22s\tremaining: 5.71s\n",
      "1075:\tlearn: 0.1514914\ttotal: 22s\tremaining: 5.69s\n",
      "1076:\tlearn: 0.1514377\ttotal: 22.1s\tremaining: 5.67s\n",
      "1077:\tlearn: 0.1513741\ttotal: 22.1s\tremaining: 5.65s\n",
      "1078:\tlearn: 0.1513091\ttotal: 22.1s\tremaining: 5.63s\n",
      "1079:\tlearn: 0.1512184\ttotal: 22.1s\tremaining: 5.61s\n",
      "1080:\tlearn: 0.1510951\ttotal: 22.1s\tremaining: 5.59s\n",
      "1081:\tlearn: 0.1510277\ttotal: 22.2s\tremaining: 5.57s\n",
      "1082:\tlearn: 0.1509753\ttotal: 22.2s\tremaining: 5.55s\n",
      "1083:\tlearn: 0.1509274\ttotal: 22.2s\tremaining: 5.53s\n",
      "1084:\tlearn: 0.1508436\ttotal: 22.2s\tremaining: 5.51s\n",
      "1085:\tlearn: 0.1507582\ttotal: 22.2s\tremaining: 5.49s\n",
      "1086:\tlearn: 0.1507015\ttotal: 22.3s\tremaining: 5.47s\n",
      "1087:\tlearn: 0.1506666\ttotal: 22.3s\tremaining: 5.45s\n",
      "1088:\tlearn: 0.1506223\ttotal: 22.3s\tremaining: 5.43s\n",
      "1089:\tlearn: 0.1505535\ttotal: 22.3s\tremaining: 5.41s\n",
      "1090:\tlearn: 0.1504856\ttotal: 22.4s\tremaining: 5.39s\n",
      "1091:\tlearn: 0.1504321\ttotal: 22.4s\tremaining: 5.37s\n",
      "1092:\tlearn: 0.1503309\ttotal: 22.4s\tremaining: 5.35s\n",
      "1093:\tlearn: 0.1502407\ttotal: 22.4s\tremaining: 5.33s\n",
      "1094:\tlearn: 0.1501725\ttotal: 22.4s\tremaining: 5.31s\n",
      "1095:\tlearn: 0.1501315\ttotal: 22.5s\tremaining: 5.29s\n",
      "1096:\tlearn: 0.1500576\ttotal: 22.5s\tremaining: 5.27s\n",
      "1097:\tlearn: 0.1500105\ttotal: 22.5s\tremaining: 5.25s\n",
      "1098:\tlearn: 0.1499491\ttotal: 22.5s\tremaining: 5.23s\n",
      "1099:\tlearn: 0.1498556\ttotal: 22.5s\tremaining: 5.21s\n",
      "1100:\tlearn: 0.1498352\ttotal: 22.6s\tremaining: 5.18s\n",
      "1101:\tlearn: 0.1497725\ttotal: 22.6s\tremaining: 5.16s\n",
      "1102:\tlearn: 0.1497243\ttotal: 22.6s\tremaining: 5.14s\n",
      "1103:\tlearn: 0.1496152\ttotal: 22.6s\tremaining: 5.12s\n",
      "1104:\tlearn: 0.1495631\ttotal: 22.6s\tremaining: 5.1s\n",
      "1105:\tlearn: 0.1494772\ttotal: 22.7s\tremaining: 5.08s\n",
      "1106:\tlearn: 0.1493572\ttotal: 22.7s\tremaining: 5.06s\n",
      "1107:\tlearn: 0.1492423\ttotal: 22.7s\tremaining: 5.04s\n",
      "1108:\tlearn: 0.1491334\ttotal: 22.7s\tremaining: 5.02s\n",
      "1109:\tlearn: 0.1490138\ttotal: 22.7s\tremaining: 5s\n",
      "1110:\tlearn: 0.1489611\ttotal: 22.8s\tremaining: 4.98s\n",
      "1111:\tlearn: 0.1488731\ttotal: 22.8s\tremaining: 4.96s\n",
      "1112:\tlearn: 0.1488265\ttotal: 22.8s\tremaining: 4.94s\n",
      "1113:\tlearn: 0.1487443\ttotal: 22.8s\tremaining: 4.92s\n",
      "1114:\tlearn: 0.1486801\ttotal: 22.8s\tremaining: 4.89s\n",
      "1115:\tlearn: 0.1486528\ttotal: 22.9s\tremaining: 4.87s\n",
      "1116:\tlearn: 0.1486091\ttotal: 22.9s\tremaining: 4.85s\n",
      "1117:\tlearn: 0.1484964\ttotal: 22.9s\tremaining: 4.83s\n",
      "1118:\tlearn: 0.1484457\ttotal: 22.9s\tremaining: 4.81s\n",
      "1119:\tlearn: 0.1483321\ttotal: 22.9s\tremaining: 4.79s\n",
      "1120:\tlearn: 0.1482390\ttotal: 22.9s\tremaining: 4.77s\n",
      "1121:\tlearn: 0.1481645\ttotal: 23s\tremaining: 4.75s\n",
      "1122:\tlearn: 0.1481028\ttotal: 23s\tremaining: 4.73s\n",
      "1123:\tlearn: 0.1480525\ttotal: 23s\tremaining: 4.71s\n",
      "1124:\tlearn: 0.1479502\ttotal: 23s\tremaining: 4.69s\n",
      "1125:\tlearn: 0.1478899\ttotal: 23s\tremaining: 4.67s\n",
      "1126:\tlearn: 0.1478497\ttotal: 23.1s\tremaining: 4.64s\n",
      "1127:\tlearn: 0.1477653\ttotal: 23.1s\tremaining: 4.62s\n",
      "1128:\tlearn: 0.1477234\ttotal: 23.1s\tremaining: 4.6s\n",
      "1129:\tlearn: 0.1476531\ttotal: 23.1s\tremaining: 4.58s\n",
      "1130:\tlearn: 0.1476211\ttotal: 23.1s\tremaining: 4.56s\n",
      "1131:\tlearn: 0.1475651\ttotal: 23.1s\tremaining: 4.54s\n",
      "1132:\tlearn: 0.1474906\ttotal: 23.2s\tremaining: 4.52s\n",
      "1133:\tlearn: 0.1474111\ttotal: 23.2s\tremaining: 4.5s\n",
      "1134:\tlearn: 0.1473213\ttotal: 23.2s\tremaining: 4.48s\n",
      "1135:\tlearn: 0.1472822\ttotal: 23.2s\tremaining: 4.46s\n",
      "1136:\tlearn: 0.1472521\ttotal: 23.3s\tremaining: 4.44s\n",
      "1137:\tlearn: 0.1471846\ttotal: 23.3s\tremaining: 4.42s\n",
      "1138:\tlearn: 0.1470978\ttotal: 23.3s\tremaining: 4.4s\n",
      "1139:\tlearn: 0.1470565\ttotal: 23.3s\tremaining: 4.38s\n",
      "1140:\tlearn: 0.1469788\ttotal: 23.3s\tremaining: 4.36s\n",
      "1141:\tlearn: 0.1469118\ttotal: 23.4s\tremaining: 4.34s\n",
      "1142:\tlearn: 0.1468481\ttotal: 23.4s\tremaining: 4.32s\n",
      "1143:\tlearn: 0.1467965\ttotal: 23.4s\tremaining: 4.29s\n",
      "1144:\tlearn: 0.1467307\ttotal: 23.4s\tremaining: 4.27s\n",
      "1145:\tlearn: 0.1466432\ttotal: 23.4s\tremaining: 4.25s\n",
      "1146:\tlearn: 0.1465698\ttotal: 23.5s\tremaining: 4.23s\n",
      "1147:\tlearn: 0.1464811\ttotal: 23.5s\tremaining: 4.21s\n",
      "1148:\tlearn: 0.1464180\ttotal: 23.5s\tremaining: 4.19s\n",
      "1149:\tlearn: 0.1463728\ttotal: 23.5s\tremaining: 4.17s\n",
      "1150:\tlearn: 0.1462663\ttotal: 23.5s\tremaining: 4.15s\n",
      "1151:\tlearn: 0.1462358\ttotal: 23.5s\tremaining: 4.13s\n",
      "1152:\tlearn: 0.1461881\ttotal: 23.6s\tremaining: 4.11s\n",
      "1153:\tlearn: 0.1461566\ttotal: 23.6s\tremaining: 4.09s\n",
      "1154:\tlearn: 0.1460517\ttotal: 23.6s\tremaining: 4.07s\n",
      "1155:\tlearn: 0.1459868\ttotal: 23.6s\tremaining: 4.04s\n",
      "1156:\tlearn: 0.1459307\ttotal: 23.6s\tremaining: 4.02s\n",
      "1157:\tlearn: 0.1458807\ttotal: 23.7s\tremaining: 4s\n",
      "1158:\tlearn: 0.1457813\ttotal: 23.7s\tremaining: 3.98s\n",
      "1159:\tlearn: 0.1456863\ttotal: 23.7s\tremaining: 3.96s\n",
      "1160:\tlearn: 0.1456324\ttotal: 23.7s\tremaining: 3.94s\n",
      "1161:\tlearn: 0.1455776\ttotal: 23.7s\tremaining: 3.92s\n",
      "1162:\tlearn: 0.1455248\ttotal: 23.7s\tremaining: 3.9s\n",
      "1163:\tlearn: 0.1454703\ttotal: 23.8s\tremaining: 3.88s\n",
      "1164:\tlearn: 0.1453652\ttotal: 23.8s\tremaining: 3.86s\n",
      "1165:\tlearn: 0.1453027\ttotal: 23.8s\tremaining: 3.84s\n",
      "1166:\tlearn: 0.1452120\ttotal: 23.8s\tremaining: 3.82s\n",
      "1167:\tlearn: 0.1451215\ttotal: 23.8s\tremaining: 3.8s\n",
      "1168:\tlearn: 0.1450572\ttotal: 23.9s\tremaining: 3.77s\n",
      "1169:\tlearn: 0.1449480\ttotal: 23.9s\tremaining: 3.75s\n",
      "1170:\tlearn: 0.1448912\ttotal: 23.9s\tremaining: 3.73s\n",
      "1171:\tlearn: 0.1448419\ttotal: 23.9s\tremaining: 3.71s\n",
      "1172:\tlearn: 0.1447774\ttotal: 23.9s\tremaining: 3.69s\n",
      "1173:\tlearn: 0.1446807\ttotal: 24s\tremaining: 3.67s\n",
      "1174:\tlearn: 0.1445963\ttotal: 24s\tremaining: 3.65s\n",
      "1175:\tlearn: 0.1445501\ttotal: 24s\tremaining: 3.63s\n",
      "1176:\tlearn: 0.1445154\ttotal: 24s\tremaining: 3.61s\n",
      "1177:\tlearn: 0.1444191\ttotal: 24.1s\tremaining: 3.59s\n",
      "1178:\tlearn: 0.1443954\ttotal: 24.1s\tremaining: 3.57s\n",
      "1179:\tlearn: 0.1443298\ttotal: 24.1s\tremaining: 3.55s\n",
      "1180:\tlearn: 0.1442512\ttotal: 24.1s\tremaining: 3.53s\n",
      "1181:\tlearn: 0.1442156\ttotal: 24.1s\tremaining: 3.51s\n",
      "1182:\tlearn: 0.1441560\ttotal: 24.2s\tremaining: 3.49s\n",
      "1183:\tlearn: 0.1440916\ttotal: 24.2s\tremaining: 3.47s\n",
      "1184:\tlearn: 0.1440066\ttotal: 24.2s\tremaining: 3.45s\n",
      "1185:\tlearn: 0.1439706\ttotal: 24.2s\tremaining: 3.43s\n",
      "1186:\tlearn: 0.1439030\ttotal: 24.2s\tremaining: 3.41s\n",
      "1187:\tlearn: 0.1438485\ttotal: 24.3s\tremaining: 3.39s\n",
      "1188:\tlearn: 0.1437933\ttotal: 24.3s\tremaining: 3.37s\n",
      "1189:\tlearn: 0.1437550\ttotal: 24.3s\tremaining: 3.35s\n",
      "1190:\tlearn: 0.1436392\ttotal: 24.3s\tremaining: 3.33s\n",
      "1191:\tlearn: 0.1435901\ttotal: 24.3s\tremaining: 3.31s\n",
      "1192:\tlearn: 0.1435553\ttotal: 24.3s\tremaining: 3.29s\n",
      "1193:\tlearn: 0.1435035\ttotal: 24.4s\tremaining: 3.27s\n",
      "1194:\tlearn: 0.1434370\ttotal: 24.4s\tremaining: 3.25s\n",
      "1195:\tlearn: 0.1433731\ttotal: 24.4s\tremaining: 3.23s\n",
      "1196:\tlearn: 0.1432293\ttotal: 24.4s\tremaining: 3.21s\n",
      "1197:\tlearn: 0.1431293\ttotal: 24.5s\tremaining: 3.19s\n",
      "1198:\tlearn: 0.1430221\ttotal: 24.5s\tremaining: 3.17s\n",
      "1199:\tlearn: 0.1429600\ttotal: 24.5s\tremaining: 3.15s\n",
      "1200:\tlearn: 0.1428997\ttotal: 24.5s\tremaining: 3.13s\n",
      "1201:\tlearn: 0.1428552\ttotal: 24.6s\tremaining: 3.1s\n",
      "1202:\tlearn: 0.1427873\ttotal: 24.6s\tremaining: 3.08s\n",
      "1203:\tlearn: 0.1427168\ttotal: 24.6s\tremaining: 3.06s\n",
      "1204:\tlearn: 0.1425955\ttotal: 24.6s\tremaining: 3.04s\n",
      "1205:\tlearn: 0.1425621\ttotal: 24.6s\tremaining: 3.02s\n",
      "1206:\tlearn: 0.1425279\ttotal: 24.7s\tremaining: 3s\n",
      "1207:\tlearn: 0.1424515\ttotal: 24.7s\tremaining: 2.98s\n",
      "1208:\tlearn: 0.1424093\ttotal: 24.7s\tremaining: 2.96s\n",
      "1209:\tlearn: 0.1423592\ttotal: 24.7s\tremaining: 2.94s\n",
      "1210:\tlearn: 0.1422977\ttotal: 24.7s\tremaining: 2.92s\n",
      "1211:\tlearn: 0.1421926\ttotal: 24.8s\tremaining: 2.9s\n",
      "1212:\tlearn: 0.1421387\ttotal: 24.8s\tremaining: 2.88s\n",
      "1213:\tlearn: 0.1420493\ttotal: 24.8s\tremaining: 2.86s\n",
      "1214:\tlearn: 0.1420016\ttotal: 24.8s\tremaining: 2.84s\n",
      "1215:\tlearn: 0.1419556\ttotal: 24.9s\tremaining: 2.82s\n",
      "1216:\tlearn: 0.1418622\ttotal: 24.9s\tremaining: 2.8s\n",
      "1217:\tlearn: 0.1418011\ttotal: 24.9s\tremaining: 2.78s\n",
      "1218:\tlearn: 0.1417746\ttotal: 24.9s\tremaining: 2.76s\n",
      "1219:\tlearn: 0.1417297\ttotal: 24.9s\tremaining: 2.74s\n",
      "1220:\tlearn: 0.1416622\ttotal: 24.9s\tremaining: 2.72s\n",
      "1221:\tlearn: 0.1415616\ttotal: 25s\tremaining: 2.7s\n",
      "1222:\tlearn: 0.1414478\ttotal: 25s\tremaining: 2.68s\n",
      "1223:\tlearn: 0.1414121\ttotal: 25s\tremaining: 2.66s\n",
      "1224:\tlearn: 0.1413546\ttotal: 25s\tremaining: 2.63s\n",
      "1225:\tlearn: 0.1412964\ttotal: 25s\tremaining: 2.61s\n",
      "1226:\tlearn: 0.1412514\ttotal: 25.1s\tremaining: 2.59s\n",
      "1227:\tlearn: 0.1411666\ttotal: 25.1s\tremaining: 2.57s\n",
      "1228:\tlearn: 0.1410981\ttotal: 25.1s\tremaining: 2.55s\n",
      "1229:\tlearn: 0.1410622\ttotal: 25.1s\tremaining: 2.53s\n",
      "1230:\tlearn: 0.1410334\ttotal: 25.1s\tremaining: 2.51s\n",
      "1231:\tlearn: 0.1409512\ttotal: 25.2s\tremaining: 2.49s\n",
      "1232:\tlearn: 0.1409193\ttotal: 25.2s\tremaining: 2.47s\n",
      "1233:\tlearn: 0.1408638\ttotal: 25.2s\tremaining: 2.45s\n",
      "1234:\tlearn: 0.1408225\ttotal: 25.2s\tremaining: 2.43s\n",
      "1235:\tlearn: 0.1407750\ttotal: 25.2s\tremaining: 2.41s\n",
      "1236:\tlearn: 0.1407242\ttotal: 25.3s\tremaining: 2.39s\n",
      "1237:\tlearn: 0.1406458\ttotal: 25.3s\tremaining: 2.37s\n",
      "1238:\tlearn: 0.1405743\ttotal: 25.3s\tremaining: 2.35s\n",
      "1239:\tlearn: 0.1405262\ttotal: 25.3s\tremaining: 2.33s\n",
      "1240:\tlearn: 0.1404211\ttotal: 25.3s\tremaining: 2.31s\n",
      "1241:\tlearn: 0.1403981\ttotal: 25.4s\tremaining: 2.29s\n",
      "1242:\tlearn: 0.1403269\ttotal: 25.4s\tremaining: 2.27s\n",
      "1243:\tlearn: 0.1402783\ttotal: 25.4s\tremaining: 2.25s\n",
      "1244:\tlearn: 0.1402465\ttotal: 25.4s\tremaining: 2.23s\n",
      "1245:\tlearn: 0.1401702\ttotal: 25.4s\tremaining: 2.21s\n",
      "1246:\tlearn: 0.1401423\ttotal: 25.5s\tremaining: 2.18s\n",
      "1247:\tlearn: 0.1400333\ttotal: 25.5s\tremaining: 2.16s\n",
      "1248:\tlearn: 0.1399427\ttotal: 25.5s\tremaining: 2.14s\n",
      "1249:\tlearn: 0.1398625\ttotal: 25.5s\tremaining: 2.12s\n",
      "1250:\tlearn: 0.1397824\ttotal: 25.6s\tremaining: 2.1s\n",
      "1251:\tlearn: 0.1397114\ttotal: 25.6s\tremaining: 2.08s\n",
      "1252:\tlearn: 0.1396913\ttotal: 25.6s\tremaining: 2.06s\n",
      "1253:\tlearn: 0.1396260\ttotal: 25.6s\tremaining: 2.04s\n",
      "1254:\tlearn: 0.1395717\ttotal: 25.6s\tremaining: 2.02s\n",
      "1255:\tlearn: 0.1394973\ttotal: 25.7s\tremaining: 2s\n",
      "1256:\tlearn: 0.1394530\ttotal: 25.7s\tremaining: 1.98s\n",
      "1257:\tlearn: 0.1394193\ttotal: 25.7s\tremaining: 1.96s\n",
      "1258:\tlearn: 0.1393541\ttotal: 25.7s\tremaining: 1.94s\n",
      "1259:\tlearn: 0.1393211\ttotal: 25.7s\tremaining: 1.92s\n",
      "1260:\tlearn: 0.1392791\ttotal: 25.8s\tremaining: 1.9s\n",
      "1261:\tlearn: 0.1392068\ttotal: 25.8s\tremaining: 1.88s\n",
      "1262:\tlearn: 0.1391571\ttotal: 25.8s\tremaining: 1.86s\n",
      "1263:\tlearn: 0.1390691\ttotal: 25.8s\tremaining: 1.84s\n",
      "1264:\tlearn: 0.1390244\ttotal: 25.8s\tremaining: 1.82s\n",
      "1265:\tlearn: 0.1389580\ttotal: 25.8s\tremaining: 1.8s\n",
      "1266:\tlearn: 0.1388284\ttotal: 25.9s\tremaining: 1.78s\n",
      "1267:\tlearn: 0.1387211\ttotal: 25.9s\tremaining: 1.75s\n",
      "1268:\tlearn: 0.1386604\ttotal: 25.9s\tremaining: 1.74s\n",
      "1269:\tlearn: 0.1385985\ttotal: 25.9s\tremaining: 1.71s\n",
      "1270:\tlearn: 0.1385405\ttotal: 26s\tremaining: 1.69s\n",
      "1271:\tlearn: 0.1384411\ttotal: 26s\tremaining: 1.67s\n",
      "1272:\tlearn: 0.1383991\ttotal: 26s\tremaining: 1.65s\n",
      "1273:\tlearn: 0.1383811\ttotal: 26s\tremaining: 1.63s\n",
      "1274:\tlearn: 0.1383339\ttotal: 26s\tremaining: 1.61s\n",
      "1275:\tlearn: 0.1382443\ttotal: 26.1s\tremaining: 1.59s\n",
      "1276:\tlearn: 0.1382107\ttotal: 26.1s\tremaining: 1.57s\n",
      "1277:\tlearn: 0.1381639\ttotal: 26.1s\tremaining: 1.55s\n",
      "1278:\tlearn: 0.1380626\ttotal: 26.1s\tremaining: 1.53s\n",
      "1279:\tlearn: 0.1380370\ttotal: 26.1s\tremaining: 1.51s\n",
      "1280:\tlearn: 0.1379947\ttotal: 26.1s\tremaining: 1.49s\n",
      "1281:\tlearn: 0.1379255\ttotal: 26.2s\tremaining: 1.47s\n",
      "1282:\tlearn: 0.1378844\ttotal: 26.2s\tremaining: 1.45s\n",
      "1283:\tlearn: 0.1378247\ttotal: 26.2s\tremaining: 1.43s\n",
      "1284:\tlearn: 0.1377284\ttotal: 26.2s\tremaining: 1.41s\n",
      "1285:\tlearn: 0.1376725\ttotal: 26.3s\tremaining: 1.39s\n",
      "1286:\tlearn: 0.1375629\ttotal: 26.3s\tremaining: 1.37s\n",
      "1287:\tlearn: 0.1374526\ttotal: 26.3s\tremaining: 1.35s\n",
      "1288:\tlearn: 0.1373913\ttotal: 26.3s\tremaining: 1.33s\n",
      "1289:\tlearn: 0.1373277\ttotal: 26.3s\tremaining: 1.31s\n",
      "1290:\tlearn: 0.1372587\ttotal: 26.4s\tremaining: 1.29s\n",
      "1291:\tlearn: 0.1371997\ttotal: 26.4s\tremaining: 1.26s\n",
      "1292:\tlearn: 0.1371099\ttotal: 26.4s\tremaining: 1.25s\n",
      "1293:\tlearn: 0.1370599\ttotal: 26.4s\tremaining: 1.23s\n",
      "1294:\tlearn: 0.1370147\ttotal: 26.4s\tremaining: 1.2s\n",
      "1295:\tlearn: 0.1369646\ttotal: 26.5s\tremaining: 1.18s\n",
      "1296:\tlearn: 0.1368777\ttotal: 26.5s\tremaining: 1.16s\n",
      "1297:\tlearn: 0.1368423\ttotal: 26.5s\tremaining: 1.14s\n",
      "1298:\tlearn: 0.1368125\ttotal: 26.5s\tremaining: 1.12s\n",
      "1299:\tlearn: 0.1367341\ttotal: 26.5s\tremaining: 1.1s\n",
      "1300:\tlearn: 0.1366319\ttotal: 26.6s\tremaining: 1.08s\n",
      "1301:\tlearn: 0.1365723\ttotal: 26.6s\tremaining: 1.06s\n",
      "1302:\tlearn: 0.1365091\ttotal: 26.6s\tremaining: 1.04s\n",
      "1303:\tlearn: 0.1364140\ttotal: 26.6s\tremaining: 1.02s\n",
      "1304:\tlearn: 0.1363625\ttotal: 26.6s\tremaining: 1s\n",
      "1305:\tlearn: 0.1362710\ttotal: 26.7s\tremaining: 980ms\n",
      "1306:\tlearn: 0.1362482\ttotal: 26.7s\tremaining: 960ms\n",
      "1307:\tlearn: 0.1362149\ttotal: 26.7s\tremaining: 940ms\n",
      "1308:\tlearn: 0.1361655\ttotal: 26.7s\tremaining: 919ms\n",
      "1309:\tlearn: 0.1361322\ttotal: 26.8s\tremaining: 899ms\n",
      "1310:\tlearn: 0.1360574\ttotal: 26.8s\tremaining: 879ms\n",
      "1311:\tlearn: 0.1359966\ttotal: 26.8s\tremaining: 858ms\n",
      "1312:\tlearn: 0.1359777\ttotal: 26.8s\tremaining: 838ms\n",
      "1313:\tlearn: 0.1359133\ttotal: 26.9s\tremaining: 818ms\n",
      "1314:\tlearn: 0.1358719\ttotal: 26.9s\tremaining: 797ms\n",
      "1315:\tlearn: 0.1358364\ttotal: 26.9s\tremaining: 777ms\n",
      "1316:\tlearn: 0.1357902\ttotal: 26.9s\tremaining: 757ms\n",
      "1317:\tlearn: 0.1357366\ttotal: 26.9s\tremaining: 736ms\n",
      "1318:\tlearn: 0.1356878\ttotal: 27s\tremaining: 716ms\n",
      "1319:\tlearn: 0.1355679\ttotal: 27s\tremaining: 695ms\n",
      "1320:\tlearn: 0.1355297\ttotal: 27s\tremaining: 675ms\n",
      "1321:\tlearn: 0.1355061\ttotal: 27s\tremaining: 654ms\n",
      "1322:\tlearn: 0.1354710\ttotal: 27s\tremaining: 634ms\n",
      "1323:\tlearn: 0.1354106\ttotal: 27.1s\tremaining: 613ms\n",
      "1324:\tlearn: 0.1353553\ttotal: 27.1s\tremaining: 593ms\n",
      "1325:\tlearn: 0.1352912\ttotal: 27.1s\tremaining: 572ms\n",
      "1326:\tlearn: 0.1352300\ttotal: 27.1s\tremaining: 552ms\n",
      "1327:\tlearn: 0.1351744\ttotal: 27.1s\tremaining: 531ms\n",
      "1328:\tlearn: 0.1351209\ttotal: 27.2s\tremaining: 511ms\n",
      "1329:\tlearn: 0.1350943\ttotal: 27.2s\tremaining: 490ms\n",
      "1330:\tlearn: 0.1350287\ttotal: 27.2s\tremaining: 470ms\n",
      "1331:\tlearn: 0.1349769\ttotal: 27.2s\tremaining: 449ms\n",
      "1332:\tlearn: 0.1349240\ttotal: 27.2s\tremaining: 429ms\n",
      "1333:\tlearn: 0.1348606\ttotal: 27.2s\tremaining: 409ms\n",
      "1334:\tlearn: 0.1348299\ttotal: 27.3s\tremaining: 388ms\n",
      "1335:\tlearn: 0.1347835\ttotal: 27.3s\tremaining: 368ms\n",
      "1336:\tlearn: 0.1347409\ttotal: 27.3s\tremaining: 347ms\n",
      "1337:\tlearn: 0.1346905\ttotal: 27.3s\tremaining: 327ms\n",
      "1338:\tlearn: 0.1346228\ttotal: 27.3s\tremaining: 306ms\n",
      "1339:\tlearn: 0.1345451\ttotal: 27.4s\tremaining: 286ms\n",
      "1340:\tlearn: 0.1345187\ttotal: 27.4s\tremaining: 266ms\n",
      "1341:\tlearn: 0.1344688\ttotal: 27.4s\tremaining: 245ms\n",
      "1342:\tlearn: 0.1343703\ttotal: 27.4s\tremaining: 225ms\n",
      "1343:\tlearn: 0.1343183\ttotal: 27.4s\tremaining: 204ms\n",
      "1344:\tlearn: 0.1342741\ttotal: 27.5s\tremaining: 184ms\n",
      "1345:\tlearn: 0.1342501\ttotal: 27.5s\tremaining: 163ms\n",
      "1346:\tlearn: 0.1341768\ttotal: 27.5s\tremaining: 143ms\n",
      "1347:\tlearn: 0.1340857\ttotal: 27.5s\tremaining: 122ms\n",
      "1348:\tlearn: 0.1340147\ttotal: 27.5s\tremaining: 102ms\n",
      "1349:\tlearn: 0.1339644\ttotal: 27.6s\tremaining: 81.6ms\n",
      "1350:\tlearn: 0.1339043\ttotal: 27.6s\tremaining: 61.2ms\n",
      "1351:\tlearn: 0.1338826\ttotal: 27.6s\tremaining: 40.8ms\n",
      "1352:\tlearn: 0.1338546\ttotal: 27.6s\tremaining: 20.4ms\n",
      "1353:\tlearn: 0.1338036\ttotal: 27.6s\tremaining: 0us\n"
     ]
    }
   ],
   "source": [
    "# Best model fitting and submitting.\n",
    "\n",
    "cat = CatBoostClassifier(**study.best_trial.params)\n",
    "submission(cat, test, classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. Please upvote my notebook if you like it! Thanks and best wishes for your future projects."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
